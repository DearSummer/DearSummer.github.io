<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[游戏AI-行为树]]></title>
    <url>%2Fposts%2Fcd3e3288%2F</url>
    <content type="text"><![CDATA[使用unity实现一个简单的行为树 What Is Bahavior Tree关于游戏的ai，使用行为树是一种比较简单的方式去操作ai行动逻辑的行为手段。 如上图所示，为ue4当中的行为树的表现方式，从根节点出发，自上而下，自左往右进行行为的判断或者操作，当节点的行为进行完毕的时候，就会返回true or false，并将控制权转移到父节点，父节点会根据子节点的执行的结果来判断下一步的执行。 在这一颗树当中，可以看作是一个没有终止条件的Loop，不断的从root节点开始，遍历着这棵树的节点，再由子节点内的内容条件来判断下一步的操作，在层层逻辑的递进之下，形成了ai的一套树形的行为模式。 Tree Node行为树由各个树节点组成，在我看来行为树的节点大致可以分为三类 Composite Node第一类,复杂节点，最主要的作用就是驱动行为树的运行模式，比如，顺序执行子节点，随机执行子节点，顺序执行子节点直到子节点返回失败等等逻辑操作，成为行为树的驱动中心 1234567891011121314151617181920212223242526272829303132333435//顺序调度，直到子节点调用失败为止public class SequenceNode : CompositeNode&#123; public override ProcessResult Process() &#123; foreach (INode node in nodes) &#123; ProcessResult result = node.Process(); if (result == ProcessResult.Failed) return ProcessResult.Failed; if (result == ProcessResult.Running) return result; &#125; return ProcessResult.Success; &#125;&#125;//顺序调度，直到子节点调用成功为止public class SelectorNode : CompositeNode&#123; public override ProcessResult Process() &#123; foreach(INode node in nodes) &#123; ProcessResult result = node.Process(); if (result == ProcessResult.Success) return ProcessResult.Success; if (result == ProcessResult.Running) return result; &#125; return ProcessResult.Failed; &#125;&#125; 上面是两种比较典型的行为树节点，其实复杂节点作为行为树的逻辑驱动推断，可以根据ai的需求不断扩展，不过，个人感觉最终也是和程序运行一样，最终都是以顺序执行,跳转,随机执行,并行之类的方式来进行逻辑的操控 Action Node第二类则是行为节点，在行为树当中，用于执行ai的操作的节点，包括不限于移动到某处，跳跃，是否离目标点距离x米之类的实际的行为判断与行为操作，在行为树当中是只能够作为叶子节点存在的节点。这种节点操作十分丰富，需要根据ai的实际操作需求来进行对应的行为节点的实现 1234567891011121314151617181920212223242526272829303132public delegate ProcessResult ActionFunc(TreeContext context); //行动节点，不允许拥有子节点，为行为树最终需要进行指向的操作，行为树唯一允许成为子节点的节点 public class ActionNode : BaseNode &#123; public ActionNode() &#123; maxChild = NodeChildLimit.NONE; &#125; public override int NodeID &#123; get; set; &#125; public override INode Enter() &#123; return null; &#125; public override ProcessResult Process() &#123; if (func != null) &#123; ProcessResult result = func(this.context); if (result == ProcessResult.Running) this.context.EnterSubtree(this); return result; &#125; return ProcessResult.Failed; &#125; public ActionFunc func &#123; set; private get; &#125; &#125; 在我看来，应该是一种类似这样的结构，对于外部的行为需求，只需要外部传入一个行为func，之后就会在ActionNode当中进行操作与执行。 Decorator Node最后一类则是装饰节点，用于对节点的返回值进行修饰的操作的，比如取反。这类节点的具体用处就如同其名字一样。以便于我们更好的操作行为逻辑，就如同写代码会有出现12if not has_key: do_something() 这种情况那样，更加方便去操作行为树的行为结构 1234567891011121314//对执行结果取反public class OppositeNode : DecoratorNode&#123; public override ProcessResult Process() &#123; ProcessResult result = child.Process(); if (result == ProcessResult.Success) return ProcessResult.Failed; else if (result == ProcessResult.Failed) return ProcessResult.Success; return result; &#125;&#125; 在这三类行为节点的驱动下，就可以简单的对这棵树进行逻辑上的操作了，不断根据复杂节点的驱动形式去驱动这棵树的行为，最终使得ai得到了我们想要操作的样子。 1234567891011121314151617private void DoUpdate(INode node)&#123; while (node != null) &#123; node = node.Enter(); if (node != null) &#123; ProcessResult result = node.Process(); if (result == ProcessResult.Running) &#123; break; &#125; node = node.Leave(); &#125; &#125;&#125; 具体操作的逻辑大概也就是这样了。 行为树的驱动方式按照我上面所写的驱动方式，大概就是行为树当中的Tick-Driven形式了，这是一种最简单的行为树的形式，这种形式需要不断的从行为树的根节点进行出发，在一个（或者几个）Tick的时间内重新执行一遍行为树，当ai的行为进入了比如移动到某处之类的需要长时间停留在某一个状态上的操作的时候，就有可能会出现不断遍历这颗行为树的情况（但是因为无论如何最终都会走到移动到某处这个节点上的） 因此，为了应对这种情况，就出现了一种Even-Driven形式的行为树了，这种行为树需要当事件到达的时候才会对行为树的节点进行下一步的操作，那么就可以避免当行为树在操作一个耗时的行为的时候却进行了无意义的行为树遍历所造成的资源的损耗的问题了 同时，这种结构也需要支持中断操作，就比如当当前行为树执行攻击玩家的操作的时候，玩家闪现跑路了，这个时候就需要中断这个行为了。需要在这个行为的基础之上需要重新唤醒整颗行为树，让其从当前节点（或者从root节点）开始继续进行后续逻辑的判断 在ue4当中就为其提供了patrol与waitEvent节点来进行相对应的操作 简单的行为树Demo 简单的小框架]]></content>
      <tags>
        <tag>unity</tag>
        <tag>game ai</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实现一个@property]]></title>
    <url>%2Fposts%2Fb151bc1%2F</url>
    <content type="text"><![CDATA[正如一开始的图片所示，@property是一件十分之方便的工具，正如c#里面的get与set的语法糖似的，可以帮助我们快速的实现对象的约束，而不需要为其建立麻烦的getter与setter方法。 那么这个@property是一种怎么样的实现方式呢？ 从语法上可以推测其实这是一种方法装饰器，本质上就是对这个方法进行一次加工与包装，使得其能够符合我们的使用意愿去进行操作。但是，其实@property还有一种操作方式那就是 123456789101112class Object(object): def __init__(self): self.x = property(self.__getter,self.__setter,self.__deleter) def __getter(self): return self._x def __setter(self, value): self._x = value def __deleter(self): del self._x 在为property对象分别写入了get，set，del方法之后，x也同样拥有了以上的属性，可以看出，虽然@property利用了装饰器的语法，但是实际上内部的操作并不是如同装饰器一般对函数进行包装的。 @property的实现原理从Python源码来看property的基本结构就是get，set，del三个方法和对应这三个方法的成员变量1234567891011121314151617181920212223242526//property包含了get，set，del三个方法typedef struct &#123; PyObject_HEAD PyObject *prop_get; PyObject *prop_set; PyObject *prop_del; PyObject *prop_doc; int getter_doc;&#125; propertyobject;//成员变量static PyMemberDef property_members[] = &#123; &#123;"fget", T_OBJECT, offsetof(propertyobject, prop_get), READONLY&#125;, &#123;"fset", T_OBJECT, offsetof(propertyobject, prop_set), READONLY&#125;, &#123;"fdel", T_OBJECT, offsetof(propertyobject, prop_del), READONLY&#125;, &#123;"__doc__", T_OBJECT, offsetof(propertyobject, prop_doc), READONLY&#125;, &#123;0&#125;&#125;;//成员函数static PyMethodDef property_methods[] = &#123; &#123;"getter", property_getter, METH_O, getter_doc&#125;, &#123;"setter", property_setter, METH_O, setter_doc&#125;, &#123;"deleter", property_deleter, METH_O, deleter_doc&#125;, &#123;0&#125;&#125;; 然后，根据初始化方法可以看出需要输入get，set，del三个方法的函数指针（默认为None），然后会根据fget，fset，fdel所指向的函数作为改对象的get,set,del方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758static intproperty_init(PyObject *self, PyObject *args, PyObject *kwds)&#123; PyObject *get = NULL, *set = NULL, *del = NULL, *doc = NULL; static char *kwlist[] = &#123;"fget", "fset", "fdel", "doc", 0&#125;; propertyobject *prop = (propertyobject *)self; if (!PyArg_ParseTupleAndKeywords(args, kwds, "|OOOO:property", kwlist, &amp;get, &amp;set, &amp;del, &amp;doc)) return -1; if (get == Py_None) get = NULL; if (set == Py_None) set = NULL; if (del == Py_None) del = NULL; Py_XINCREF(get); Py_XINCREF(set); Py_XINCREF(del); Py_XINCREF(doc); prop-&gt;prop_get = get; prop-&gt;prop_set = set; prop-&gt;prop_del = del; prop-&gt;prop_doc = doc; prop-&gt;getter_doc = 0; /* if no docstring given and the getter has one, use that one */ if ((doc == NULL || doc == Py_None) &amp;&amp; get != NULL) &#123; PyObject *get_doc = PyObject_GetAttrString(get, "__doc__"); if (get_doc) &#123; if (Py_TYPE(self) == &amp;PyProperty_Type) &#123; Py_XSETREF(prop-&gt;prop_doc, get_doc); &#125; else &#123; /* If this is a property subclass, put __doc__ in dict of the subclass instance instead, otherwise it gets shadowed by __doc__ in the class's dict. */ int err = PyObject_SetAttrString(self, "__doc__", get_doc); Py_DECREF(get_doc); if (err &lt; 0) return -1; &#125; prop-&gt;getter_doc = 1; &#125; else if (PyErr_ExceptionMatches(PyExc_Exception)) &#123; PyErr_Clear(); &#125; else &#123; return -1; &#125; &#125; return 0;&#125; 而@property当中的getter，setter，deleter方法则是建立了一个Copy了一个新的@property对象给对应的函数1234567891011121314151617181920// getter方法static PyObject *property_getter(PyObject *self, PyObject *getter)&#123; return property_copy(self, getter, NULL, NULL);&#125;// setter方法static PyObject *property_setter(PyObject *self, PyObject *setter)&#123; return property_copy(self, NULL, setter, NULL);&#125;// deleter方法static PyObject *property_deleter(PyObject *self, PyObject *deleter)&#123; return property_copy(self, NULL, NULL, deleter);&#125; @property的Python实现根据源码的实现可以在python层实现一个@property系统123456789101112131415161718192021222324252627282930class PyProperty(object): def __init__(self, field_get=None, field_set=None, field_del=None): self.field_get_func = field_get self.field_set_func = field_set self.field_del_func = field_del def __set__(self, instance, value): if self.field_set_func is None: raise AttributeError('setter not exist') return self.field_set_func(instance, value) def __get__(self, instance, type=None): if self.field_get_func is None: raise AttributeError('getter not exist') return self.field_get_func(instance) def __delete__(self, instance): if self.field_del_func is None: raise AttributeError('deleteter not exist') return self.field_del_func(instance) def getter(self, get_method): return PyProperty(get_method ,self.field_set_func, self.field_del_func) def setter(self, set_method): return PyProperty(self.field_get_func ,set_method, self.field_del_func) def deleteter(self, del_method): return PyProperty(self.field_get_func ,self.field_set_func, del_method) 在@property里的getter，setter，deleter方法的实质上就是使用装饰的函数重写为了对应对象的get,set,delete方法从而达到了包装属性的神奇的效果，也完成了函数-&gt;成员变量的包装的变化。]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[子集：回溯与枝剪]]></title>
    <url>%2Fposts%2F95fd897%2F</url>
    <content type="text"><![CDATA[在求解子集的过程中，常常需要根据不同的情况进行不同的遍历与回溯。 求子集，实际上就是一种类似遍历一个集合的所有可能的过程。甚至，在一个简单的求子集问题当中，可以说就是一个遍历所有路径的过程。 因此，求子集的问题，一般可以通过画图的方式来解决。 无需枝剪的子集问题首先，是一个最基础的子集问题 给定一组不含重复元素的整数数组 nums，返回该数组所有可能的子集（幂集）。 说明：解集不能包含重复的子集。 比如，集合[1,2,3],所包含的子集就是[[3],[1],[2],[1,2,3],[1,3],[2,3],[1,2],[]],那么，求解的方法很明显就是遍历所有的组合了，这个时候我们可以画图来解决这个问题。 从图中不难看出，从空集出发，不断地根据已选择的元素去递归的选择数组当中的剩余的元素，然后，将每一次的选择的路径保存下来，那么就是子集的内容了。 结合成代码就是这样 123456789101112131415161718vector&lt;vector&lt;int&gt;&gt; subsets(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; vector&lt;int&gt; set; allsubsets(nums,res,set,0); return res; &#125; void allsubsets(vector&lt;int&gt;&amp; nums,vector&lt;vector&lt;int&gt;&gt;&amp; result,vector&lt;int&gt;&amp; set, int k) &#123; result.push_back(set); for(int i = k;i &lt; nums.size();i++) &#123; set.push_back(nums[i]); allsubsets(nums,result,set,i + 1); set.pop_back(); &#125; &#125; 当然，在递归地遍历地时候，要注意，每一次函数返回之后都要将set的值回溯，因为，set里面所保存的是递归遍历时候的路径，当函数弹出之后，路径自然也要回溯回来了。 然后，将路径保存在结果中，最后也自然能够得到答案了。 题目来源(LeetCode)链接：https://leetcode-cn.com/problems/subsets著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。]]></content>
      <tags>
        <tag>leetcode</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[引用计数式智能指针]]></title>
    <url>%2Fposts%2Fdbb7ef5e%2F</url>
    <content type="text"><![CDATA[既然手动内存管理这么麻烦，那么为什么来一个自动的内存管理呢 在c++当中，对于一个new,就要对应一个delete，进行相对应的内存释放。只要成对的出现分配与释放，那自然就不会引起任何内存泄漏的问题。但是，说很简单，但是当做起来的时候就未必了。比如对于一个函数返回的指针，我们需不需要对其进行内存的释放呢？而对于一个传入的指针，我们又需不需要对其进行内存的分配呢？还有，下面这种情况1234char *p = new char[10];char *p1 = p;......p5 = p4 = p3 = p2 = p1 = p 当我们有很多变量都需要p的时候，我们应不应该释放pn？这个时候，我们就需要利用一些东西去让我们自动的管理指针了。 我们面对的问题无非就是怎么样让指针在应该释放的时候释放，不应该释放的时候不会释放，以及一定要指针得到释放。首先，其实我们可以对于每一个内存块都建立一个计数器，一旦有指针指向这个内存块，我们就使得计数器增加，当有一个指针被释放的时候，我们就减少我们的计数器，当计数器为0的时候才真正的去释放这一块的内存。这个方法，就叫做引用计数法。 还有一个问题就是，怎么样才能让指针不再使用的时候就能够得到释放呢？ 其实这个问题，我们可以参考一下栈上的临时变量，当函数调用的时候，栈上的空间被申请，而里面的临时变量都会同时被申请了出来，但是，当执行完函数的时候，临时变量也同样会被析构。因此，我们可以利用这个特点，将指针封装到一个对象上去，那就是智能指针了。 RCObject在实现指针之前，我们有一个东西要处理，那就是计数器。按照我们之前的想法，所有内存都使用一个计数器去管理，因此，我们首先来实现这个计数器。 123456789101112131415161718192021222324class RCObject&#123; public: void addReference(); void removeReference(); void markUnshareable(); bool isShareable() const; bool isShared() const; protected: RCObject(); RCObject(const RCObject&amp; rhs); RCObject&amp; operator=(const RCObject&amp; rhs); virtual ~RCObject() = 0; private: int refCount; bool shareable;&#125;; 当有一个指针进来引用同一块内存的时候，我们就增加计数器，当有指针被销毁的时候减少引用，当然，这些都是智能指针应该去干的事情，这里只是一个计数器。当然，计数器同时也要拥有一个判断当前内存块是不是被共享的方式，至于具体原因之后再说。 12345678910111213141516171819202122RCObject::RCObject() :refCount(0),shareable(true) &#123;&#125; RCObject::RCObject(const RCObject&amp; rhs) :refCount(0),shareable(true) &#123;&#125; RCObject&amp; RCObject::operator=(const RCObject&amp; rhs) &#123; return *this; &#125; //虽然是纯虚函数，但是必须要提供一个实现，因为这是一个析构函数，派生类调用自身的析构的时候一定会调用它的 RCObject::~RCObject()&#123;&#125; void RCObject::addReference()&#123;++refCount;&#125; void RCObject::removeReference()&#123;if(--refCount == 0) delete this;&#125; void RCObject::markUnshareable()&#123;shareable = false;&#125; bool RCObject::isShareable() const &#123; return shareable;&#125; bool RCObject::isShared() const &#123;return refCount &gt; 1;&#125; RCPtr首先，先思考一下这个东西要有什么样的效果。首先能够自动对内存进行管理那当然是必须的。然后，还需要能够兼容指针的操作，换句话说就是像指针一样的使用方式，那么*,-&gt;这些操作符肯定要重载的，还有就是那些指针的判空操作比如if(ptr)，当然，我们可以假如一个isEmpty()的方法，但是，这样不是很够自然，因此我们需要一些能够隐式转换类型的方式，那么说，operator bool()是要去建立的。还有就是感叹号的!，这样也可以去兼容if(!ptr)这种判断方式。 另外还有一个问题就是，当我们对指针进行操作的时候，由于我们都是指向同一个内存的，但是，我的想法肯定不是想要12ptrb = ptra;ptrb-&gt;doSomething(); 之后，就改变了ptra的内容，因此，我们需要在对ptrb进行操作的时候，对其进行写时复制。将指针的复制操作延缓到真的要实际操作的时候才进行复制，这样对于需要引用大量同样的对象却使用比较少的情况有比较少的优化效果。当然，假如你想同时操作两个对象，那么这个就不太适合这种情况了。而之前所说的判断空间是否被分享的作用也就于此。 既然需要实现的内容都清楚了，我们就可以去实现内容了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109template&lt;typename T&gt;class RCPtr&#123;public: RCPtr(T* realPtr = 0) :pointee(realPtr) &#123; init(); &#125; RCPtr(RCPtr&amp; rhs) :pointee(rhs.pointee) &#123; init(); &#125; ~RCPtr()&#123; holder-&gt;removeReference(); &#125; RCPtr&lt;T&gt;&amp; operator=(RCPtr&lt;T&gt;&amp; rhs); //用const与否来判断接下来的对象是否需要用到写时复制 T* operator-&gt;(); T&amp; operator*(); T* operator-&gt;() const; T&amp; operator*() const; bool operator!() const; operator bool();private: T *pointee; void init(); void makeCopy();&#125;;template&lt;typename T&gt;RCPtr&lt;T&gt;::operator bool()&#123; return pointee;&#125;template&lt;typename T&gt;bool RCPtr&lt;T&gt;::operator!() const&#123; return pointee == 0;&#125;template&lt;typename T&gt;T&amp; RCPtr&lt;T&gt;::operator*() const&#123; return *pointee;&#125;template&lt;tyepname T&gt;T* RCPtr&lt;T&gt;::operator-&gt;() const&#123; return pointee;&#125;template&lt;typename T&gt;T* RCPtr&lt;T&gt;::operator-&gt;()&#123; makeCopy(); return pointee;&#125;template&lt;typename T&gt;T&amp; RCPtr&lt;T&gt;::operator*()&#123; makeCopy(); return *pointee;&#125;template&lt;tyepname T&gt; RCPtr&lt;T&gt;&amp; RCPtr&lt;T&gt;::operator=(RCPtr&lt;T&gt;&amp; rhs)&#123; if(pointee != rhs.pointee) &#123; if(pointee) &#123; pointee-&gt;removeReference(); &#125; pointee = rhs.pointee; pointee-&gt;addReference(); &#125;&#125;template&lt;typename T&gt;void RCPtr&lt;T&gt;::makeCopy()&#123; if(pointee-&gt;isShared()) &#123; T *oldValue = pointee; pointee-&gt;removeReference(); pointee = new T(*oldValue); &#125; pointee-&gt;addReference();&#125;template&lt;typename T&gt;void RCPtr&lt;T&gt;::init()&#123; if(pointee == 0) return; if(pointee-&gt;isShareable() == false) &#123; pointee = new T(*pointee); &#125; pointee-&gt;addReference();&#125; 在这里，我们仍然面临着两个问题，首先，就是派生类的问题1234567891011class A;class B:public A;class C:public A:megre(const RCPtr&lt;A&gt;&amp; a1,const RCPtr&lt;A&gt;&amp; a2);RCPtr&lt;B&gt; b;RCPtr&lt;C&gt; c;//错误megre(b,c); 虽然在指针上，这两个拥有派生类的家伙能够用隐式转换的方式进行正确的传递。但是，这个在RCPtr&lt;T&gt;之中就完全不行了，因为，虽然泛型的参数是有继承关系的，但是两个类实际上毫无关联。因此，为了解决这个问题，我们就需要使用类型转换的重载了。 12345template&lt;class newType&gt;operator RCPtr&lt;newType&gt;()&#123; return RCPtr&lt;newType&gt;(pointee);&#125; 虽然，这里使用了泛型重载了类型变换，但是，构造函数的指针赋值操作会为我们检查这个操作是否合法，也就是说只有属于同一条继承链上的人才会得到正确的转换 RCHolder接下来就是一个很重要的问题，那就是，我用这个智能指针还必须要参数对象T要继承RCObject才能操作是不是很不方便？？？ 没错，确实十分不方便，因此，我们现在就来解决这个问题。有句话说过，计算机当中的所有问题都能够通过增加一个层来解决，因此，同样的，我们可以为这个指针增加一个中间层，专门用来处理计数器的 我们现在的情况是这样的。智能指针记录了指针，指针身上有一个计数器，智能指针控制指针身上的计数器，当计数器归零的时候，就会销毁指针。那么，其实可以看出来，计数器对于指针来说并不是一个必须的东西，我们可以在中间加一个holder，变成这样的方式1234 RCObject | | RCPtr&lt;T&gt; --&gt; Holder --&gt; pointee 计数器管理Holder，对智能指针的操作都会反映到holder身上，而holder持有pointee，当计数器归零的时候，holder会销毁，而holder所持有的pointee也会顺势销毁，这样，指针和计数器之间的耦合关系就被解除了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122template&lt;typename T&gt;class RCPtr&#123;public: RCPtr(T* realPtr = 0) :holder(new RCHolder()) &#123; holder-&gt;pointee = realPtr; init(); &#125; RCPtr(RCPtr&amp; rhs) :holder(rhs.holder) &#123; init(); &#125; ~RCPtr()&#123; holder-&gt;removeReference(); &#125; RCPtr&lt;T&gt;&amp; operator=(RCPtr&lt;T&gt;&amp; rhs); T* operator-&gt;(); T&amp; operator*(); T* operator-&gt;() const; T&amp; operator*() const; bool operator!() const; operator bool(); template&lt;class newType&gt; operator RCPtr&lt;newType&gt;();private: struct RCHolder : public RCObject &#123; T *pointee; ~RCHolder()&#123; delete pointee; pointee = 0;&#125; &#125; RCHolder *holder; void init(); void makeCopy();&#125;;template&lt;T&gt;template&lt;newType&gt;RCPtr&lt;T&gt;::operator RCPtr&lt;newType&gt;()&#123; return RCPtr&lt;newType&gt;(holder-&gt;pointee);&#125;template&lt;typename T&gt;RCPtr&lt;T&gt;::operator bool()&#123; return holder-&gt;pointee;&#125;template&lt;typename T&gt;bool RCPtr&lt;T&gt;::operator!() const&#123; return holder-&gt;pointee == 0;&#125;template&lt;typename T&gt;T&amp; RCPtr&lt;T&gt;::operator*() const&#123; return *(holder-&gt;pointee);&#125;template&lt;tyepname T&gt;T* RCPtr&lt;T&gt;::operator-&gt;() const&#123; return holder-&gt;pointee;&#125;template&lt;typename T&gt;T* RCPtr&lt;T&gt;::operator-&gt;()&#123; makeCopy(); return holder-&gt;pointee;&#125;template&lt;typename T&gt;T&amp; RCPtr&lt;T&gt;::operator*()&#123; makeCopy(); return *(holder-&gt;pointee);&#125;template&lt;tyepname T&gt; RCPtr&lt;T&gt;&amp; RCPtr&lt;T&gt;::operator=(RCPtr&lt;T&gt;&amp; rhs)&#123; if(holder != rhs.holder) &#123; holder-&gt;removeReference(); holder = rhs.holder; init(); &#125; return *this;&#125;template&lt;typename T&gt;void RCPtr&lt;T&gt;::makeCopy()&#123; if(holder-&gt;isShared()) &#123; T *oldValue = holder-&gt;pointee; holder-&gt;removeReference(); holder = new RCHolder(); holder-&gt;pointee = new T(*oldValue); holder-&gt;addReference(); &#125;&#125;template&lt;typename T&gt;void RCPtr&lt;T&gt;::init()&#123; if(!holder-&gt;isShareable()) &#123; T *oldValue = holder-&gt;pointee; holder = new RCHolder; holder-&gt;pointee = new T(*oldValue); &#125; holder-&gt;addReference();&#125; 最终就会是这个样子了 与share_ptrstl当中的share_ptr与这个的设计都是使用了引用计数的方式，但是不同的一点在与，share_ptr对于一个被复制的指针保留了原有的指针的效果，也就说不会写时复制，当另一个指针修改了内容之后，这个内存块的位置也会被修改。从设计上来说，感觉share_ptr与原生的指针的操作会更加的相似一些，而我这里的操作会对于每一个指针的持有者都会有独一无二的内存空间，也就没有了共享指针这种操作了。 参考书籍《more effective c++》，这里也是里面的RCPtr的设计]]></content>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[引用计数式的String]]></title>
    <url>%2Fposts%2F93e26237%2F</url>
    <content type="text"><![CDATA[与std::string不一样的string 在std::string当中，虽然提供了很多string的操作，但是，在内存上它的本质也只是一个vector&lt;char&gt;而已，对于以下的状态12std::string str1 = "hello world";std::string str2 = str1; 在实际上是两段完全不同的内存。但是，假如我们变成这样1str5 = str4 = str3 = str2 = str1; 那岂不是对于一个相同的字符串却申请了五段的内存。这其实是一种浪费。我们完全可以只用一段内存，而其他的strn只需要持有那段内存的指针就可以了。这样，我们就可以减少内存的消耗了。同时，为了防止有人一不小心就将这段内存给销毁，因此，我们可以拿一个计数器去记录一共有多少人在同时持有这段内存。一旦有人delete strn了，就将计数器减一，直到计数器为零的时候才将这段内存给销毁。 12345678String::~String()&#123; removeReferenceCount(); if(referenceCount == 0) delete[] data; &#125; 大概就是着种感觉吧。这种技术就称之为引用计数 不过，现在还有一个问题，那就是既然是多人同时持有一个内存块，那么就会导致一个问题，那就是比如strn[0] = &#39;y&#39;那么，所有人都会受到波及。这明显不是我们想要看到的，因此，我们为了防止这种现象，当需要修改这个strn的时候，我们先将内存块复制一份，然后，strn独自持有这一份的内存。那么，它无论怎么去修改它自己的字符串都不是问题了。 这也是和String的初衷是一样的，那就是不会改变原有的使用方式，每一个str在用户看来都是独立的，即使内存是映射到同一个区域123456789101112//const是不会被改变的const char&amp; String::operator[](int index)const&#123; return data[index];&#125;//假设所有使用非const版本的operator[]都是会修改字符串的char&amp; String::operator[](int index)&#123; makeCopy(); return data[index];&#125; 大概的思路就是这样的。这种技术就叫做写时复制，在操作系统的进程与子进程之间的内存映射也是用到了这种技术哦。 既然大致的思路都已经思考出来了，我们就考虑实现吧。 既然都说到写时复制,那么，我们完全可以使用之前所说的RCPtr去实现这个对于字符串的内存共享的功能。 StringValue立即行动，将String实现。 123456789101112131415161718192021222324class String&#123;public: String (const char *value); const char&amp; operator[](int index) const; char&amp; operator[](int index);private: struct StringValue: public RCObject &#123; char* data; StringValue(const char *initValue); StringValue(const StringValue&amp; rhs); void init(const char *initValue); ~StringValue(); &#125;; RCPtr&lt;StringValue&gt; value;&#125;; 其中里面的StringValue就是用来缓存字符串的，而在外部使用了RCPtr&lt;StringValue&gt;确保了对字符串的内容的正确的缓存 123456789101112131415161718192021void String::StringValue::init(const char* initValue) &#123; data = new char[strlen(initValue) + 1]; strcpy(data,initValue); &#125; String::StringValue::StringValue(const char* initValue) &#123; init(initValue); &#125; String::StringValue::StringValue(const StringValue&amp; rhs) &#123; init(rhs.data); &#125; String::StringValue::~StringValue() &#123; delete[] data; &#125; 当需要新的字符串类型的时候会生成新的StringValue，假如对于字符串的修改没有任何问题的话，那么，就会增加引用计数。不过，这里有一个问题，我们和RCPtr里面的设计是一样的，假设const char&amp; operator[](int i) const为不改变字符串的方式而char&amp; operator[](int i)为改变字符串的方式。但实际上，我们对于调用哪一个函数并不取决于是否会发生改变，而仅仅是因为类型匹配而已，假如发生了这种事情。123String s = "hello";std::cout &lt;&lt; s[0] &lt;&lt; std::endl;s[1] = 'y'; 我们可以认为，第三行的操作会影响到字符串而第二行的操作却没有。但是，我们调用的很可能是同一个operator[]，因为，这个并不取决于是否发生了改变。因此，我们需要一种方式去更加的准确的预测是否会引起字符串的改变的操作。 CharProxy我们需要一个代理类。代理类的作用其实只是为我们争取到时间，争取到我们确切的操作字符的时候我们才确认我们的操作到底是应该怎么去做。 123456789101112131415161718struct CharProxy &#123; CharProxy(String&amp; s,int index); CharProxy&amp; operator=(const CharProxy&amp; ths); CharProxy&amp; operator=(char c); operator char() const; char* operator&amp;(); const char *operator&amp;() const; private: String&amp; str; int charIndex; void makeCopy(); &#125;; 首先，我们String返回的operator[]变成了CharProxy。那么，外界持有这个代理类的时候，当使用了赋值操作的时候，那么，就会触发operator=的操作，那么自然而然就会触发写时复制。而假如仅仅是使用这个字符，那么，自然就会隐式转换到char的类型,因为定义了operator char()方法。而这个时候就不会触发写时复制了。也就节省了以此内存拷贝的操作。 同样，因为我们使用了代理类，那么我们有一些操作就会和char的操作不一样。为了消除这种不一致的行为，我们就将一些操作给重载了，这里重载了取地址的运算。因为，其他运算可以通过对char的隐式转换而达成。值得一提的是，因为取了地址就有了潜在的修改的可能，因此，也需要进行写时复制。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130class String&#123;public: String (const char *value); struct CharProxy &#123; CharProxy(String&amp; s,int index); CharProxy&amp; operator=(const CharProxy&amp; ths); CharProxy&amp; operator=(char c); operator char() const; char* operator&amp;(); const char *operator&amp;() const; private: String&amp; str; int charIndex; void makeCopy(); &#125;; const String::CharProxy operator[](int index) const; String::CharProxy operator[](int index); friend std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os,const String&amp; str); friend class CharProxy;private: struct StringValue: public RCObject &#123; char* data; StringValue(const char *initValue); StringValue(const StringValue&amp; rhs); void init(const char *initValue); ~StringValue(); &#125;; RCPtr&lt;StringValue&gt; value;&#125;;String::String(const char *initValue = "") :value(new StringValue(initValue))&#123;&#125;const String::CharProxy String::operator[](int index) const&#123; return String::CharProxy(const_cast&lt;String&amp;&gt;(*this),index);&#125;String::CharProxy String::operator[](int index)&#123; return String::CharProxy(*this,index);&#125;String::CharProxy::CharProxy(String&amp; s,int index) :str(s),charIndex(index)&#123;&#125;String::CharProxy::operator char() const&#123; return str.value-&gt;data[charIndex];&#125;std::ostream&amp; operator&lt;&lt;(std::ostream&amp; os,const String&amp; str)&#123; os &lt;&lt; str.value-&gt;data; return os;&#125;const char *String::CharProxy::operator&amp;() const&#123; return &amp;(str.value-&gt;data[charIndex]);&#125;char * String::CharProxy::operator&amp;()&#123; makeCopy(); str.value-&gt;markUnshareable(); return &amp;(str.value-&gt;data[charIndex]);&#125;String::CharProxy&amp; String::CharProxy::operator=(const String::CharProxy&amp; rhs)&#123; makeCopy(); str.value-&gt;data[charIndex] = rhs.str.value-&gt;data[rhs.charIndex]; return *this;&#125;String::CharProxy&amp; String::CharProxy::operator=(char c)&#123; makeCopy(); str.value-&gt;data[charIndex] = c; return *this;&#125;void String::CharProxy::makeCopy()&#123; if(str.value-&gt;isShared()) &#123; RCPtr&lt;StringValue&gt; rcptr(new StringValue(str.value-&gt;data)); str.value = rcptr; &#125;&#125;void String::StringValue::init(const char* initValue)&#123; data = new char[strlen(initValue) + 1]; strcpy(data,initValue);&#125;String::StringValue::StringValue(const char* initValue)&#123; init(initValue);&#125;String::StringValue::StringValue(const StringValue&amp; rhs)&#123; init(rhs.data);&#125;String::StringValue::~StringValue()&#123; delete[] data;&#125; 使用代理类可以延缓我们的操作，直到真正在使用它的时候才进行操作。这符合了lazy evaluation的优化守则，因此，对于引用多而修改少的时刻会比较有优势。 参考书籍《more effective c++》 这是里面的String的实现方式]]></content>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[stl:copy/copy_backward]]></title>
    <url>%2Fposts%2Ffffcaacd%2F</url>
    <content type="text"><![CDATA[copy(first,last,result)copy_backward(first,last,result); copy在stl当中，copy是从前往后拷贝的，也就是说12for(;first != last;++first) *result = *first; 大致是这种形式的，因此，当result的头部区域处于[first,last)之间的时候，就会有可能出现拷贝出错的情况。比如12340 1 2 3 4 5 6 | | | first| last result 这种情况，在first还没遍历到3之前，3已经作为result被修改了，因此，会出现拷贝出错的情况。但是，之所以说是可能出现出错的情况，是因为，copy进行了大量的泛化，特化与强化的工作，因此，也有可能不会有问题。 在copy当中，为了保证效率的最高，它将拷贝的操作分为两种可能，一种是对char*/wchar_t*进行的操作，另一种是非char*/wchar_t*进行的操作。当类型推导推导出这个特化的类型的时候，它就会调用memmove()来进行拷贝，这是一个很快的底层拷贝操作 123456//对于wchar_t*也一样（利用函数的重载的功能）inline char* copy(const char* first,const char* last,const char* result)&#123; memmove(result,first,last - first); return result +(last - first);&#125; 而对于非字符指针之外的操作，就是完全的泛化的操作1234567template&lt;class InputIterator,class OutputIterator&gt;inline OutputIterator copy( InputIterator first,InputIterator last,OutputIterator result)&#123; return __copy_dispatch&lt;InputIterator,OutputIterator&gt;() (first,last,result);&#125; 当然，虽然是泛化的版本，但是，在这里对于不同的Iteraotr也是进行不同的特化的操作的，当迭代器为指针类型，也就是说要对指针进行操作的时候，那就要看这个指针有没有trivial operator=当存在着支持这种原生的指针操作的时候，自然也要使用效率极高的memmove()了。不然，就是用复制的强化版操作，因此，当你自定义了指针赋值操作后，我们是不知道你要怎么对对象进行赋值的，因此，直接拷贝内存这种粗暴的方式自然是不可行的。 假如，迭代器不是指针类型，那就同样要看这个迭代器的类型是怎么样的了，假如这个迭代器是随机访问的迭代器，那就说明能够很简单的求得拷贝区域的长度，因此，也可以使用强化版本，不然，那就只能使用最简单的也是最慢的最泛化的版本了。 12345678910//利用了仿函数进行内容的特化，根据萃取出的不同的iterator来进行不同的操作template&lt;class InputIterator,class OutputIterator&gt;struct __copy_dispath&#123; OutputIterator operator()( InputIterator first,InputIteratorlast,OutputIterator result) &#123; return __copy(first,last,result,iterator_category(first)); &#125;&#125; 首先看看的是泛化的版本，也就是根据不同的iterator来进行强化的copy方式 123456789101112131415161718192021222324252627template&lt;class InputIterator,class OutputIterator&gt;inline OutputIterator __copy( InputIterator first,InputIterator last, OutputIterator result,input_iterator_tag)&#123; for(;first != last;++result,++first) *result = *first; return result;&#125;template&lt;class RandomAccessIterator,class OutputIterator&gt;inline OutputIterator __copy( RandomAccessIterator first,RandomAccessIterator last, OutputIterator result,random_access_iterator_tag)&#123; return __copy_d(first,last,result,distance_type(first));&#125;template&lt;class RandomAccessIterator,class OutputIterator,class Distance&gt;inline OutputIterator __copy_d( RandomAccessIterator first,RandomAccessIterator last, OutputIterator result,Distance *)&#123; for(Distance n = last - first;n &gt; 0;--n,++result,++first) *result = *first; return result;&#125; 而RandomAccessIterator比较快的原因，大致就是因为不用一直对比迭代器，因此就避免了大量访问迭代器的时间。 之后，就是对于指针类型的强化了。 1234567891011121314template&lt;class T&gt;struct __copy_dispath&lt;T*,T*&gt;&#123; T* operator()(T* first,T*,T* result) &#123; typedef typename __type_traits&lt;T&gt;::has_trivial_assignment_operator t; return __copy_t(first,last,result,t()); &#125;&#125;//第一个参数为const的版本template&lt;class T&gt;struct __copy_dispath&lt;const T*,T*&gt;&#123;...&#125; 由于要分为是否有trivial operator=，因此，在调用的时候，就先萃取出了t，来判断有没有原生的指针，然后，根据不同的类型来进行不同的拷贝操作 123456789101112template&lt;class T&gt;inline T* __copy_t(const T* first,const T* last,const T* result,__true_type)&#123; memmove(result,first,sizeof(T) * (last - first)); return first +(last - first);&#125;template&lt;class T&gt;inline T* __copy_t(const T* first,const T* last,const T* result,__false_type)&#123; return __copy_d(first,last,result,(ptrdiff_t*)0);&#125; 在此，copy的所有操作都进行了尽可能的优化了 move_backwardmove_backward的优化方式与copy是完全一样的。而它的拷贝方式则是与copy相反，它是从尾到头开始拷贝的123--last;for(;first != last;--last,--result) *result = *last; 因此，假如拷贝区间的尾部处于[first,last)之间的话，拷贝就有可能出错 12340 1 2 3 4 5 6| | | ||first| lastresult| 假如result的区间是[0,3)，当从last开始拷贝的时候，就已经破坏了[first,last)还未拷贝的地方，因此，有可能会出错 当然，当时用memmove()的时候是不会出错的。 参考资料《stl源码剖析》]]></content>
      <tags>
        <tag>stl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[stl:sort]]></title>
    <url>%2Fposts%2Fbb1dff1a%2F</url>
    <content type="text"><![CDATA[void sort(first,last) 在STL当中的sort的算法，并不是一个简单的单一的算法，是一个复合的算法，里面涵盖了堆排序，快速排序和插入排序 当数据量比较少的时候，快速排序体现不到其优势，而且会因为使用递归带来比较大的额外开销，因此使用的是插入排序 当数据量比较大的时候，就会使用快速排序。但是，快速排序有一个缺点，那就是当数据量大部分有序的时候，就会导致时间复杂度倾向于O(n^2)，因此，当时间复杂度有向O(n^2)倾斜的时候，就会改为使用堆排序，从而将时间复杂度最坏情况控制在O(nlogn) 再者，由于插入排序在大量元素有序的情况下，性能将会十分的好，因此，当快速排序到达”就差一点点就全部有序”的状态的时候，改为使用插入排序对元素进行最终的排序 因此，在stl当中的排序是这样的 123456789template&lt;class RandomAccessIterator&gt;inline void sort(RandomAccessIterator first,RandomAccessIteratorlast)&#123; if(first != last) &#123; __introsort_loop(first,last,value_type(first),__lg(last-first) * 2); __final_insertion_sort(first,last); &#125;&#125; 其中，__introsort_loop就是之前所说的堆，快排，插入排序的复合排序了 首先，我们要知道，想要知道元素要多大才是快排，又要多大才是插入排序，我们就需要一个阈值,这个阈值是一个全局的变量const int __stl_threshold = 16;。首先，对元素进行数量上的检查，根据数量上的差别来判断是否使用快速排序。 第二点就是要检查元素是否是大部分有序的了。这个，我们可以从快排的分割上入手。因此，在理想情况下，快速排序每一次的分割都能很好的对半分层，因此，理论上在最好的情况下就需要分logn层，一旦元素大部分有序，就需要多很多次的分割，因此，我们可以为这个分割设定一个阈值，一旦超过这个阈值，就说明元素的排序并不是很理想，要使用堆排序了，这个阈值就是函数__lg(size)了 1234567template&lt;class Size&gt;inline Size __lg(Size n)&#123; Size k; for(k = 0;n &gt; 1;n &gt;&gt; 1) ++k; return k;&#125; 假设数组元素是40个，那么期望的分层就是5，那么我们对其的最大分割限制就是5*2; 1234567891011121314151617181920212223242526272829303132333435363738394041template&lt;class RandomAccessIterator,class T，class Size&gt;void __introsort_loop(RandomAccessIterator first,RandomAccessIrerator last,T*,Size depth_limit)&#123; //在这里，利用了阈值很巧妙的将排序到"差一点就完成"的状态构建了出来 while(last - first &gt; __stl_threshold) &#123; if(depth_limit == 0) &#123; //这个就是堆排序 partial_sort（first,last,last); return; &#125; --depth_limit; //快排的partition，在这里使用的是三点分割 //意思是，取piovt的时候，取第一个元素，最后一个元素，和中间的元素当中的中值当作piovit RandomAccessIterator cut = __unguarded_partition( first,last, T(__median(*first,*(first + (last - first) / 2),*(last - 1)))); //先对右半边进行递归 __introsort_loop(cut,last,value_type(first),depth_limit); //下一次就是对左半边了 last = cut; &#125;&#125;template&lt;RandomAccessIterator&gt;void __final_insertion_sort(RandomAccessIterator first,RandomAccessIterator last)&#123; //假如元素数量小于阈值，直接插入排序，否则用插入排序为快排收尾 if(last - first&gt; __stl_threshold) &#123; __insertion_sort(first,first + __stl_threshold); __unguarded_insertion_sort(first + __stl_threshold,last); &#125; else __insert_sort(first,last);&#125; 参考资料《stl源码剖析》]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
        <tag>stl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[stl:partial_sort]]></title>
    <url>%2Fposts%2Fb0a82fc8%2F</url>
    <content type="text"><![CDATA[void partial_sort(first,middle,last); 在stl当中，partial_sort(first,middle,last)，是一个局部排序的算法，是从[first,end)的区间中对元素进行排序，最终使得[first,middle)中的元素为[first,last)当中的前k个。 这个问题其实就是从一个数组当中从小到大排序k个元素，与直接排列整个数组的sort不同，当k相较于数组长度n比较小的时候，这个排序将会比直接排序整个数组快很多。 实现这个排序的思路就在于维护一个最大堆 首先，建立一个从[first,middle)之间的元素的最大堆 然后，在[middle,last)区间中进行向后的扫描，当遇见一个比堆顶元素小的元素的时候，弹出堆顶元素并将这个新的元素加入到堆当中 最后，扫描完成后，堆中的元素最大的也是第k大的元素了，因此，对堆进行堆排序，从而实现[first,middle)之间的有序 首先，建立一个堆，以及对堆的插入的操作时间复杂度都是O(logk)的，扫描整个数组，因此是O(nlogk)，然后，要对堆内进行堆排序，因此整个算法的时间复杂度应该是O((n+k)logk),空间复杂度要维护整个堆k个元素，因此是O(k) 123456789101112131415161718template&lt;class RandomAccessIterator&gt;inline void partial_sort(RandomAccessIterator first, RandomAccessIterator middle, RandomAccessIterator last)&#123; __partial_sort(first,middle,last,value_type(first));&#125;template&lt;class RandomAccessIterator,class T&gt;__partial_sort( RandomAccessIterator first, RandomAccessIterator middle, RandomAccessIterator last, T*);&#123; make_heap(first,middle); for(*i &lt; *first) __pop_heap(first,middle,i,T(*i),distance_type(first)); sort_heap(first,middle);&#125; 引用资料《stl源码剖析》]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
        <tag>stl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[莉兹与青鸟]]></title>
    <url>%2Fposts%2F807cefa7%2F</url>
    <content type="text"><![CDATA[谁是谁的莉兹，谁又是谁的青鸟呢？ 《莉兹与青鸟》一改《京吹》两部的风格，用精致的画面，细腻的情感为我们展开了两位少女之间的感人的故事。 “你是不是没有加入任何社团呢？”，“是”，“那要不要加入吹奏部呢？”。在初中，希美如同青鸟一般闯入了内向的少女霙的生活当中，她们一起演奏一起参加比赛，最终，落选，没有成功打入全国比赛，但是，她们约定要在高中一起继续努力，她们的目标：全国大赛。 神经大条的希美不知道，霙的双簧管只为她一人所奏。 时光流逝，她们如愿在北宇治高中加入了吹奏部，但是，在这里，不愿努力的三年级与积极前进的一年级发生了剧烈的冲突，最终导致一年级生大量退部，其中就包括了希美，但是，希美却没有告诉霙她的退出，一如利兹与青鸟的故事当中，在利兹睡下之时，悄然离去的青鸟。 在这之后，发生了许多故事，希美如同青鸟一般在利兹醒来之时回到了利兹的身边，她回到了吹奏部当中，但是，两人的关系，又如同片中开头所描绘一样，如同两条线，不断的靠近，而一旦接近又会立即离开。 童话故事《利兹与青鸟》一直穿插在故事当中，一如霙的内心，她一直认为她是利兹，是她束缚着最求自由翱翔的希美。但是，就如同在演奏利兹与青鸟的时候，她始终无法理解放飞青鸟的利兹是什么感受，“如果我是利兹，我会将青鸟锁在笼子里，让我们永远的在一起”，她不知道为什么要放手所爱之人。直到与老师的交谈当中，换位思考之后才发现，其实她才是青鸟，她才是希美一直所希望展翅高飞的那个人，“在利兹放飞青鸟的时候，青鸟到底是怎么样的感受呢？”，“即使不舍，也要展翅高飞，因为这是利兹所希望的，因为青鸟的一切都只是为了让利兹幸福” 在最后的演奏当中，希美也终于明白，其实她才是利兹，一直束缚着霙的利兹。因为，自己的演奏跟不上更有才华的霙，因此，霙才会一直以来压抑着自己的声音，以此来迎合希美的步伐。“让我觉得最难受的事情是，让我知道了打开鸟笼的方法”，利兹的独白一如希美的内心。 最终，两位少女心与心的碰撞终于将两条不相交的线条重合在了一起，一如片中的将”disjoint”中的”dis”划掉的”joint”一般。但与开头两人无言却默契的走在一起相比，希美与霙多了对话，也更拉近了彼此的距离。 与《京吹》中久美子的爆发般的炽热感情对比，《利兹与青鸟》全片细腻而内敛，一如内向的霙一般。整个剧场版通过大量的细节动作的描绘，很形象的表达了霙内心的那种，“我喜欢你，但是为了你我将会学会自由飞翔，因为这是你所希望的”的充满矛盾的感情。霙的深情告白，没有激烈的言语，只有一曲独奏的《利兹与青鸟》，委婉，含蓄，却能打动人心。]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Implementing a distance vector routing algorithm]]></title>
    <url>%2Fposts%2F5318243%2F</url>
    <content type="text"><![CDATA[Computer Networking:A Top-Down approach chapter 4 lab 这次的实验是要实现一个分布式异步距离向量算法。在实验当中提供了node0,node1,node2,node3来模拟3个节点的dv路由算法的寻路机制 Distance Vector Routing Algorithm首先，我们先看看距离向量算法的思想。在这个算法当中，最核心的思想就是，当我们从节点x到节点y选一条最短的路径，那么，我们首先就要选择离节点y最近的节点z，假设我们已经知道了节点x-&gt;z的最短的路径，那么，x-&gt;y的最短路径就是x-&gt;z-&gt;y。然后，我们的问题就变成了寻找x-&gt;z的最短路径。按照这个思路递归下去，我们就可以只根据邻居节点的距离向量表就可以得知x-&gt;y的最短的距离，从而能够沿着最短的路从x-&gt;y进行行走了。 根据这个思想，我们不难得知，对于一个节点x，他只需要知道自己节点的距离向量(链路cost)，以及邻居节点的距离向量(链路cost)就可以得知整个链路的所有节点的最短距离了。 因此，这个算法是分布式的算法。他只需要从邻居得到数据，然后修改自己的数据，假如修改了自己的距离向量表就向邻居通告自己修改了，直到没有消息能够再传递为止。这个算法也是异步的，因此，他不要求所有节点都一起计算。同时他也是可以自我停止的，当所有节点都找到了最小cost的链路之后，整个网络当中就再无信息交流，从而算法也停止了。 对于dv算法，我们维护以下的信息 对于每一个邻居v,从x到直接相连的邻居v的费用为c(x,v) 对于节点x的距离向量$ D_x=[D_x(y):y\in N] $ 对于节点x的每一个邻居v的距离向量都有$ D_v=[D_v(y):y\in N] $ 同时对于距离向量的计算方式有$D_x(y)=min_v{c(x,v) + D_v(y)}$ 看上去似乎有点抽象，我们就实际出发，从代码实现来看吧。由于四个node的实现其实是基本一样的，因此这里就只以node0为例子 首先就是初始化距离向量表 12345678910111213141516171819202122232425void rtinit0() &#123; for(int i = 0;i &lt; 4;i++) for(int j = 0;j &lt; 4;j++) dt0.costs[i][j] = __MAX_COST__; dt0.costs[0][0] = 0; dt0.costs[0][1] = 1; dt0.costs[0][2] = 3; dt0.costs[0][3] = 7; for(int i = 0;i &lt; 4;i++) &#123; if(dt0.costs[0][i] == 0 || dt0.costs[0][i] == __MAX_COST__) continue; struct rtpkt pkt; pkt.destid = i; pkt.sourceid = 0; memcpy(pkt.mincost,dt0.costs[0],sizeof(int) * 4); tolayer2(pkt); &#125; if(TRACE &gt;= 1) printdt0(&amp;dt0);&#125; 所有不通的路都设为最大的cost，然后，为所有邻居的cost都标记上(这个cost是题目给定的)，然后，由于自己的距离向量表得到了更改，因此，向自己的所有邻居都通告。 之后，初始化就完成了。然后是迭代的操作 123456789101112131415161718192021222324252627282930313233void rtupdate0(rcvdpkt) struct rtpkt *rcvdpkt;&#123; if(rcvdpkt-&gt;destid != 0) return; memcpy(dt0.costs[rcvdpkt-&gt;sourceid],rcvdpkt-&gt;mincost,sizeof(int) * 4); int hasChange = 0; for(int i = 0;i &lt; 4;i++) &#123; if(dt0.costs[0][rcvdpkt-&gt;sourceid] + dt0.costs[rcvdpkt-&gt;sourceid][i] &lt; dt0.costs[0][i]) &#123; hasChange = 1; dt0.costs[0][i] = dt0.costs[0][rcvdpkt-&gt;sourceid] + dt0.costs[rcvdpkt-&gt;sourceid][i]; &#125; &#125; if(hasChange) &#123; for(int i = 0;i &lt; 4;i++) &#123; if(dt0.costs[0][i] == 0 || dt0.costs[0][i] == __MAX_COST__) continue; struct rtpkt pkt; pkt.destid = i; pkt.sourceid = 0; memcpy(pkt.mincost,dt0.costs[0],sizeof(int) * 4); tolayer2(pkt); &#125; &#125; if(TRACE &gt;= 1) printdt0(&amp;dt0);&#125; 然后，就是我们一旦接收到邻居传来的距离向量表的通告，我们就要为我们的距离向量表更新内容了。首先，我们先保存下来邻居的信息，然后，我们试图计算从我们自己的节点到所有其他节点的费用,根据之前的公式我们可以直到，我们的思路就是，比较当前节点到目的节点与当前节点先到邻居节点再到目的节点的路线谁费用比较低，假如，先走邻居节点比直接到达的费用要低，我们就更新我们的距离向量表，并通告所有的邻居 这样一来一去，一来一去的，直到再也没有收到邻居的来信，就说明所有节点都已经收敛到最低费用的情况了。 这个算法的思想和实现都比较简单，但是会有一个问题，那就是这个算法会陷入无穷计数问题(count to infinty)。比如，节点x-&gt;y的费用从1上升到了1000，那么，在这个算法当中，就只能在两个节点之间不断向上试探才能够慢慢收敛到正确的费用上去，这样，大大的耗费了网络的资源。虽然，两个节点之间的无穷计数问题可以由毒性逆转来解决，但是多个节点的话，这个问题也依旧没有解决 现在，回到实验，我们可以看看所有的节点的距离向量表的表现形式 123456789101112131415161718192021222324252627 via D0 | 1 2 3 ----|----------------- 1| 0 1 3dest 2| 1 0 2 3| 3 2 0 via D1 | 0 2 ----|----------- 0| 0 2dest 2| 2 0 3| 1000 1000 via D2 | 0 1 3 ----|----------------- 0| 0 1 4dest 1| 1 0 3 3| 4 3 0 via D3 | 0 2 ----|----------- 0| 0 2dest 1| 1000 1000 2| 2 0 在实验当中，d1与d3不是邻居，自然是不会有其距离向量表信息保存下来的，但是，他们之间依然能够找到它们之间的最短链路1234(0,0):0 (0,1):1 (0,2):2 (0,3):4 (1,0):1 (1,1):0 (1,2):1 (1,3):3 (2,0):2 (2,1):1 (2,2):0 (2,3):2 (3,0):4 (3,1):3 (3,2):2 (3,3):0]]></content>
      <tags>
        <tag>computer network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode:3sum]]></title>
    <url>%2Fposts%2F80fb69f9%2F</url>
    <content type="text"><![CDATA[Given an array nums of n integers, are there elements a, b, c in nums such that a + b + c = 0? Find all unique triplets in the array which gives the sum of zero. Note: The solution set must not contain duplicate triplets. Example:1234567Given array nums = [-1, 0, 1, 2, -1, -4],A solution set is:[ [-1, 0, 1], [-1, -1, 2]] 三数之和，首先，让我们想想，两数之和是怎么做的。 12345678910111213141516vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123; map&lt;int,int&gt; tarMap; vector&lt;int&gt; result; for(int i = 0;i &lt; nums.size();i++) &#123; if(tarMap.count(nums[i]) &gt; 0) &#123; result.push_back(tarMap[nums[i]]); result.push_back(i); return result; &#125; tarMap[target - nums[i]] = i; &#125; return result; &#125; 使用了map，对于每一次的数都将其期望的数记录下来然后，当遍历到某数的时候，先找找有没有人需要这个数，如果有，那就组合成一个组合，不然，就将自己需求的搭档(数的大小)登记起来，方便后来人找搭档。 那么，我们可以从这个思路出发，先找到两数的组合，然后再根据两数的组合去寻找需求的第三个数。不过，这样的话就需要先找到两数之和的组合，再去寻找合适的第三个人，时间复杂度将会最起码变成O(n^2),因此，我们可以从数组本身去找找信息 既然时间复杂度都已经这么高了，我们对数组先进行一下排序也不是什么很慢的事情(sort也就O(nlogn)的时间复杂度) 在得到有序数组之后，我们就可以从数组本身当中去寻找线索了。 首先，还是两数之和的思路，那就是在确定一个数之后，发布其需求的剩下的数，那么，我们怎么去寻找剩下的数呢？首先，我们这个数组是有序的，也就是说nums[left] &lt; nums[right]，那么，当我们确定了一个数num[i]之后，我们就要为其去寻找队友了。而我们的数组是有序的，也就是说我们可以从数组的一左一右去寻找目标12345678int left = i + 1,right = nums.size() - 1;int sum = nums[i] + nums[left] + nums[right];if(sum &lt; 0) left++;else if(sum &gt; 0); right--;else //find it!! 那么，当sum比0大就说明负数的元素比较多了，需要向右调整，反之亦然。当然，即使是找到了这个组合也不能停止计算，因为还有可能有其他的组合的出现。 当然，还有一个问题就是，我们得出的结果不能有重复的元素，换句话说，假设输入的数组是[-1,-1,2,3]，选第一个-1作为nums[i]与选第二个作为nums[i]应该是等价的，因此需要跳过这个阶段。 还有一点就是，因为我们的和是0，而数组是从小到大排序的。因此，当nums[i] &gt; 0的时候，也就没有再去计算下去的必要了。 12345678910111213141516171819202122232425262728293031323334353637vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) &#123; if(nums.empty()) return &#123;&#125;; sort(nums.begin(),nums.end()); vector&lt;vector&lt;int&gt;&gt; result; for(int i = 0;i &lt; nums.size() - 1;i++) &#123; if(nums[i] &gt; 0) break; if(i != 0 &amp;&amp; nums[i - 1] == nums[i]) continue; int left = i + 1,right = nums.size() - 1; while(left &lt; right) &#123; int sum = nums[left] + nums[right] + nums[i]; if(sum &lt; 0) left++; else if(sum &gt; 0) right--; else &#123; result.push_back(&#123;nums[left],nums[right],nums[i]&#125;); while(left &lt; right &amp;&amp; nums[left] == nums[left + 1]) left++; while(left &lt; right &amp;&amp; nums[right - 1] == nums[right]) right--; left++; right--; &#125; &#125; &#125; return result; &#125; 对于四数之和，思路也是一样的 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/3sum著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode:permutations]]></title>
    <url>%2Fposts%2Fb2435380%2F</url>
    <content type="text"><![CDATA[Given a collection of numbers that might contain duplicates, return all possible unique permutations. Example:1234567Input: [1,1,2]Output:[ [1,1,2], [1,2,1], [2,1,1]] 对于全排序，其实，就是对集合元素的所有的排列。那么，我们可以这样看，我们一个一个的将元素构建起来。首先，我们先构建全排序的开头的第一个字符。我们先看看有哪些不同的元素，{1,2},没错，我们能够选择的元素只有两个(虽然集合是{1,1,2}，但是两个1其实是一样的，两个1互换位置对于排序来说没有影响)。那么，我们选择一个元素，比如，选择的是1，那么，我们接下来还能够选择的元素就只剩下{1,2}了。 我们现在再继续选，我们可以从不同的元素当中{1,2}当中随便选一个再去组合这个排序数组，比如这次选的是1，那么下一步，我们就只能选择2了。当我们选择了2之后，我们发现，我们现在的数组长度和集合元素是一样多的，因此，我们这个时候就能够输出一个排序数组了。 在我们构建完一个排序数组之后，我们就要进行回溯(为什么？那当让是因为我们还没有计算出所有的可能啊)。 我们现在已经构成的数组是[1,1,2]，因此，我们向上回退一步，将2还回去，然后，选择之前没有选择的2，然后继续刚才的步骤。 在使用这种方式不断的构建数组的过程，我们就可以得到这个集合的全排序了。 这个方法是不是很眼熟？没错，这就是深度优先的遍历方法。在每一次回溯的时候，都会将之前的变化归还回来，这种方式叫做还原现场，因此，这种算法就叫做深度优先+现场还原的解决方法了 当然，为了不构造因为重复元素而导致的相同的数组的问题，我们这里首先得先对元素进行加工，也就是将不同的元素区分出来，然后再在这的基础上记录相同元素的个数(免得最后构造出来的数组长度不对嘛)。在这里我选择使用map&lt;int,int&gt; key-&gt;元素 value-&gt;个数 1234567891011121314151617181920212223242526272829303132class Solution &#123; map&lt;int,int&gt; map_;public: vector&lt;vector&lt;int&gt;&gt; permuteUnique(vector&lt;int&gt;&amp; nums) &#123; for(int i : nums) ++map_[i]; vector&lt;vector&lt;int&gt;&gt; output; vector&lt;int&gt; v; dfs(map_,0,nums.size(),v,output); return output; &#125; void dfs(map&lt;int,int&gt;&amp; map,int cur,int size,vector&lt;int&gt;&amp; path,vector&lt;vector&lt;int&gt;&gt;&amp; output) &#123; if(cur == size) &#123; output.push_back(path); return; &#125; for(auto&amp; v : map) &#123; if(!v.second) continue; --v.second; path.push_back(v.first); dfs(map,cur + 1,size,path,output); path.pop_back(); ++v.second; &#125; &#125;&#125;; 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/permutations-ii著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode:minesweeper]]></title>
    <url>%2Fposts%2F1205e6ea%2F</url>
    <content type="text"><![CDATA[Let’s play the minesweeper game (online game)! You are given a 2D char matrix representing the game board. ‘M’ represents an unrevealed mine, ‘E’ represents an unrevealed empty square, ‘B’ represents a revealed blank square that has no adjacent (above, below, left, right, and all 4 diagonals) mines, digit (‘1’ to ‘8’) represents how many mines are adjacent to this revealed square, and finally ‘X’ represents a revealed mine. Now given the next click position (row and column indices) among all the unrevealed squares (‘M’ or ‘E’), return the board after revealing this position according to the following rules: If a mine (‘M’) is revealed, then the game is over - change it to ‘X’. If an empty square (‘E’) with no adjacent mines is revealed, then change it to revealed blank (‘B’) and all of its adjacent unrevealed squares should be revealed recursively. If an empty square (‘E’) with at least one adjacent mine is revealed, then change it to a digit (‘1’ to ‘8’) representing the number of adjacent mines. Return the board when no more squares will be revealed. 扫雷的规则，其实同样是dfs/bfs的事。唯一有问题的地方就是，他仅仅是没有地雷的点会递归的展开，一旦附近有地雷就不会展开了，因此，mine_num &gt; 0的点就不用加入到搜索队列里了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455vector&lt;vector&lt;char&gt;&gt; updateBoard(vector&lt;vector&lt;char&gt;&gt;&amp; board, vector&lt;int&gt;&amp; click) &#123; if(board[click[0]][click[1]] == 'M') &#123; board[click[0]][click[1]] = 'X'; return board; &#125; int dir_x[8] = &#123;0,1,0,-1,1,1,-1,-1&#125;; int dir_y[8] = &#123;1,0,-1,0,1,-1,-1,1&#125;; int m = board.size(); int n = board[0].size(); set&lt;vector&lt;int&gt;&gt; visited; stack&lt;vector&lt;int&gt;&gt; s; s.push(click); while(!s.empty()) &#123; vector&lt;int&gt; cur = s.top(); s.pop(); int mine = 0; for(int i = 0;i &lt; 8;i++) &#123; if(cur[0] + dir_x[i] &lt; 0 || cur[0] + dir_x[i] &gt;= m || cur[1] + dir_y[i] &lt; 0 || cur[1] + dir_y[i] &gt;= n) continue; if(board[cur[0] + dir_x[i]][cur[1] + dir_y[i]] == 'M') mine++; &#125; if(mine == 0) &#123; board[cur[0]][cur[1]] = 'B'; for(int i = 0;i &lt; 8;i++) &#123; if(cur[0] + dir_x[i] &lt; 0 || cur[0] + dir_x[i] &gt;= m || cur[1] + dir_y[i] &lt; 0 || cur[1] + dir_y[i] &gt;= n) continue; else if(board[cur[0] + dir_x[i]][cur[1] + dir_y[i]] == 'E' &amp;&amp; visited.count(&#123;cur[0] + dir_x[i],cur[1] + dir_y[i]&#125;) == 0) &#123; s.push(&#123;cur[0] + dir_x[i],cur[1] + dir_y[i]&#125;); &#125; &#125; &#125; else board[cur[0]][cur[1]] = mine + '0'; &#125; return board; &#125; 不过，说起来，无论是推箱子，解数独还是这个扫雷运用的都是bfs/dfs欸。果然是个很厉害的搜索算法 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/minesweeper著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode:game of life]]></title>
    <url>%2Fposts%2Fb0b083f0%2F</url>
    <content type="text"><![CDATA[According to the Wikipedia’s article: “The Game of Life, also known simply as Life, is a cellular automaton devised by the British mathematician John Horton Conway in 1970.” Given a board with m by n cells, each cell has an initial state live (1) or dead (0). Each cell interacts with its eight neighbors (horizontal, vertical, diagonal) using the following four rules (taken from the above Wikipedia article): Any live cell with fewer than two live neighbors dies, as if caused by under-population. Any live cell with two or three live neighbors lives on to the next generation. Any live cell with more than three live neighbors dies, as if by over-population.. Any dead cell with exactly three live neighbors becomes a live cell, as if by reproduction. Write a function to compute the next state (after one update) of the board given its current state. The next state is created by applying the above rules simultaneously to every cell in the current state, where births and deaths occur simultaneously. Follow up: Could you solve it in-place? Remember that the board needs to be updated at the same time: You cannot update some cells first and then use their updated values to update other cells. In this question, we represent the board using a 2D array. In principle, the board is infinite, which would cause problems when the active area encroaches the border of the array. How would you address these problems? 生命游戏，这也是一个很有意思的游戏，在经过大量的迭代之后，里面的生命就会展现出各种各样有趣的形状出来，在数学上，这个规则所对应的参数属于一种叫做“混沌的边界”的状态，多一个和少一个都不能实现这样的效果。另外，这个游戏是图灵完备的，也就是说计算机能够做的事情，这个游戏都能实现。 回到问题本身，生命游戏本身的算法很简单，就是对每一个细胞都进行遍历，查找其邻居存活细胞的数量，然后，根据数量和当前细胞的状态(存活/死亡)来确定下一代这个细胞的状态(存活/死亡/复活)。由于进入下一世代是在一瞬间的，因此，在每一次更新世代的时候，都要小心的保存现场，使其不要被已经确认状态的细胞所影响。 而进阶挑战就是不使用额外的空间来记录这些额外的信息。 首先，我们可以知道，所有的细胞只有两个状态(生存/死亡)，因此，我们可以利用int的高位来存储这些细胞的下一代的状态的信息 1234enum CeilState&#123; ALIVE = 2&#125;; 第二位用来记录是否存活，若下一世代存活则标记为1，否则就标记为0。这样的话，当我们需要读取所记录的标记时，只需要(board[i][j] &gt;&gt; 1) == 1就可以判断这个细胞在下一世代的状态，而只需要(board[i][j] &amp; 0x1) == 1就可以判断这个细胞在这一世代的状态 因此，一个不消耗额外空间的算法实现了 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071class Solution &#123; enum CeilState &#123; ALIVE = 2 &#125;;public: void gameOfLife(vector&lt;vector&lt;int&gt;&gt;&amp; board) &#123; if(board.empty()) return; int m = board.size(); int n = board[0].size(); for(int i = 0;i &lt; m;i++) &#123; for(int j = 0;j &lt; n;j++) &#123; if((board[i][j] &amp; 0x1) == 1) &#123; int alive_ceil_count = 0; for(int x = -1;x &lt;= 1;x++) &#123; for(int y = -1;y &lt;=1;y++) &#123; if(i + x &lt; 0 || i + x &gt;= m || j + y &lt; 0 || j + y &gt;= n || (x == 0 &amp;&amp; y == 0)) continue; if((board[i+x][j+y] &amp; 0x1) == 1) alive_ceil_count++; &#125; &#125; if(alive_ceil_count &lt; 2 || alive_ceil_count &gt; 3); else board[i][j] |= CeilState::ALIVE; &#125; else &#123; int alive_ceil_count = 0; for(int x = -1;x &lt;= 1;x++) &#123; for(int y = -1;y &lt;=1;y++) &#123; if(i + x &lt; 0 || i + x &gt;= m || j + y &lt; 0 || j + y &gt;= n || (x== 0 &amp;&amp; y == 0)) continue; if((board[i+x][j+y] &amp; 0x1) == 1) alive_ceil_count++; &#125; &#125; if(alive_ceil_count != 3); else board[i][j] |= CeilState::ALIVE; &#125; &#125; &#125; for(int i = 0;i &lt; m;i++) &#123; for(int j = 0;j &lt; n;j++) &#123; if((board[i][j] &gt;&gt; 1) == 1) board[i][j] = 1; else board[i][j] = 0; &#125; &#125; &#125;&#125;; 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/game-of-life著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode:Minimum Moves to Move a Box to Their Target Location]]></title>
    <url>%2Fposts%2F98eb3162%2F</url>
    <content type="text"><![CDATA[The game is represented by a grid of size n*m, where each element is a wall, floor, or a box. Your task is move the box ‘B’ to the target position ‘T’ under the following rules: Player is represented by character ‘S’ and can move up, down, left, right in the grid if it is a floor (empy cell). Floor is represented by character ‘.’ that means free cell to walk. Wall is represented by character ‘#’ that means obstacle (impossible to walk there). There is only one box ‘B’ and one target cell ‘T’ in the grid. The box can be moved to an adjacent free cell by standing next to the box and then moving in the direction of the box. This is a push. The player cannot walk through the box. Return the minimum number of pushes to move the box to the target. If there is no way to reach the target, return -1. 推箱子，一个充满着童年回忆的游戏。 在这里，我们要使用一个算法去计算出推到目标位置的箱子所需要的最少步骤。让我们一步步推导到底应该如何去搜索才能得到正确的答案 首先，让我们先看看这个问题的最简单的形式，那就是没有人，箱子自己动的情况(不要求最短)。 这种情况，我们只需要使用BFS就可以找出一条路径了，而每一次BFS我们需要保存的是一个二元组{PlyerX,PlayerY} 然后，让我们来解决人推箱子的情况，那就是，人推箱子到目的地点的路经(不要求最短) 这个时候，其实也就是比一开始的时候要多了一个箱子的信息，那么我们同样可以使用BFS，不过，这一次我们需要保存的信息是一个四元组{PlayerX,PlayerY,BoxX,BoxY} 我们可以，同样以人为核心来进行移动，但是，当人移动到箱子的位置的时候，箱子也要往相同的方向移动一格。这样，我们就可以模拟出人推箱子的情况了。当然，箱子无法移动的时候，人也无法移动，也就是将箱子碰到墙壁的情况也加入到判断是否可移动的列表里了。 最后，让我们解决人推箱子，且箱子走到目的地所用最短步数 BFS有一个问题，那就是虽然能够找到一条通向终点的路径，但是却不能确保这条路径是最短的。因此，我们需要改良一下BFS的迭代方式。首先，让我们先看看，BFS是一条路走到头再开始回溯的，也就是说，在路径上或许已经走了另一条比较短的路了，但是，我也不会去改变我的方向。因此，我们要做的就是，为BFS每一次迭代出来的路径加一个权值。每一次都是从权值小的地方开始搜索，这样，就可以避免了很多无用的操作了(因为，无用的操作肯定会导致权值的上升)。这样，就可以保证能够搜索出最短的路径了 至于怎么做呢？一般来说，BFS使用stack来保存信息，在这里，我们使用priority_queue来保存信息，然后自己定义一个用于对比权值的仿函数传递进去。这样，每一次在优先队列堆顶的元素都是权值最小的元素，自然，就可以使用BFS的方法去遍历出最小的步数了 现在，我们为BFS所保存的信息增加了一个步数的权值，因此，每一次迭代需要保存的元素应该是一个五元组{PlayerX,PlayerY,BoxX,BoxY,Step} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485class Solution &#123; //建立对比权值的仿函数 struct cmp &#123; bool operator()(const vector&lt;int&gt;&amp;a,const vector&lt;int&gt;&amp;b) &#123; return a[4] &gt; b[4]; &#125; &#125;;public: int minPushBox(vector&lt;vector&lt;char&gt;&gt;&amp; grid) &#123; int s_x,s_y,b_x,b_y; int n = grid.size(),m = grid[0].size(); for(int i = 0;i &lt; grid.size();i++) &#123; for(int j = 0;j &lt; grid[i].size();j++) &#123; if(grid[i][j] == 'S') &#123; s_x = i; s_y = j; &#125; if(grid[i][j] == 'B') &#123; b_x = i; b_y = j; &#125; &#125; &#125; priority_queue&lt;vector&lt;int&gt;,vector&lt;vector&lt;int&gt;&gt;,cmp&gt; que; //stack&lt;vector&lt;int&gt;&gt; que; 不使用栈而是使用优先队列保存信息 set&lt;vector&lt;int&gt;&gt; visited; int dir_x[4] = &#123;0,1,0,-1&#125;; int dir_y[4] = &#123;1,0,-1,0&#125;; //&#123;sX,sY,bX,bY,step&#125; 保存一个五元组 que.push(&#123;s_x,s_y,b_x,b_y,0&#125;); visited.insert(&#123;s_x,s_y,b_x,b_y&#125;); while(!que.empty()) &#123; auto v = que.top(); que.pop(); for(int i = 0;i &lt; 4;i++) &#123; vector&lt;int&gt; s_next = &#123;v[0] + dir_x[i],v[1] + dir_y[i]&#125;; if(s_next[0] &lt; 0 || s_next[0] &gt;= n || s_next[1] &lt; 0 || s_next[1] &gt;= m || grid[s_next[0]][s_next[1]] == '#') continue; int step = v[4]; vector&lt;int&gt; b_next = &#123;v[2],v[3]&#125;; if(s_next[0] == v[2] &amp;&amp; s_next[1] == v[3]) &#123; b_next[0] += dir_x[i]; b_next[1] += dir_y[i]; if(b_next[0] &lt; 0 || b_next[0] &gt;= n || b_next[1] &lt; 0 || b_next[1] &gt;= m || grid[b_next[0]][b_next[1]] == '#') continue; //成功推动箱子就步数加1 step++; &#125; //到达目的地就返回步数 if(grid[b_next[0]][b_next[1]] == 'T') return step; //深度优先遍历 if(visited.count(&#123;s_next[0],s_next[1],b_next[0],b_next[1]&#125;) != 0) continue; visited.insert(&#123;s_next[0],s_next[1],b_next[0],b_next[1]&#125;); que.push(&#123;s_next[0],s_next[1],b_next[0],b_next[1],step&#125;); &#125; &#125; return -1; &#125;&#125;; 如此如此，这般这般，我们就能够解出推箱子的路径最优解了 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/minimum-moves-to-move-a-box-to-their-target-location著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sort:让计数排序适用性更广吧]]></title>
    <url>%2Fposts%2F6e41d843%2F</url>
    <content type="text"><![CDATA[计数排序的时间复杂度很低，但是，能够应用的场合就很少了。这个时候，我们就需要对计数排序进行升级 根据计数排序的思想，他对于集合当中的每一个元素都进行标记，最后，按照标记数组的标记数量进行元素的输出就可以达成排序的效果了。但是，这个排序方式有一个比较局限的地方，那就是，一旦集合中的元素拥有浮点数之类的无法被数组下标所量化标记的时候，计数排序就失去其效果了。 这个时候，我们就需要引入一些辅助的手段，那就是桶(bucket)，而这个升级过后的排序方式就叫做桶排序 首先，先来介绍一下什么是桶 每一个桶代表着一个区间范围，比如对于以下的元素12345674.5 0.84 3.25 2.18 0.5bucket: [0.5,1.5) [1.5,2.5) [2.5,3.5) [3.5,4.5) [4.5,4.5] 至于桶具体有多少个，如何确立桶的范围，方法有很多，在这里，桶的区间范围=(最大值-最小值)/(桶的数量-1) 然后，我们将具体的元素都放到对应区间的桶当中 12345bucket: [0.5,1.5) 0.5,0.84 [1.5,2.5) 2.18 [2.5,3.5) 3.25 [3.5,4.5) [4.5,4.5] 4.5 由于，仅仅只是放入桶当中，桶中的元素是没有经过排序的，因为，下一步就是对每个桶里面的元素进行排序 最终，以此输出桶中的元素 123456789101112131415161718192021222324252627 vector&lt;int&gt; sortArray(vector&lt;int&gt;&amp; nums) &#123; if(nums.empty()) return&#123;&#125;; //step1:找出最大值 int max = nums[0],min = nums[0]; for(int i = 1;i &lt; nums.size();i++) &#123; if(max &lt; nums[i]) max = nums[i]; if(min &gt; nums[i]) min = nums[i]; &#125;//step2:建立桶并将元素加入桶中 vector&lt;vector&lt;int&gt;&gt; buckets(max - min + 1); for(int i : nums) buckets[i - min].push_back(i);//step3:对桶内元素进行排序 for(auto&amp; vec : buckets) sort(vec.begin(),vec.end());//step4:按顺序输出桶内的内容 vector&lt;int&gt; res; for(int i = 0;i &lt; buckets.size();i++) for(int j = 0;j &lt; buckets[i].size();j++) res.push_back(buckets[i][j]); return res; &#125; 可见，桶排序的基本思想和计数排序差不多，都是对元素本身的位置进行标记，而不是直接对元素进行交换排序。而再使用了大量的桶的情况下，更加的可以减少排序算法当中需要排序的元素的个数(假如元素在桶中分布比较均匀的时候，基本上是不需要使用到排序算法对桶内元素进行排序的) 桶排序的时间复杂度就比较复杂了，首先要算出最大最小值，需要耗费时间n，然后，要创建空桶m个，遍历数组将元素放入桶中耗时n，然后每一个桶内都得进行排序，为了要快，桶内元素的排序算法应该是O(nlogn)的，因此运算量为m (n/m log(n/m)),最后要输出数组耗时n 总的来说就是3n+m+n(logn-logm),也就是O(n+m+n(logn-logm))而空间复杂度则是O(n+m)，在这里使用的sort其实就是一种快速排序，那么空间就是O(n)了 不过，当元素在桶内比较平均分布的时候，也就是n=m的时候，时间复杂度就变成O(n)了，而假如，大量元素都集中在一个桶当中的时候，时间复杂度将会退化到O(nlogn)，并且，白白浪费了空间去创建大量的桶]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sort:如天下第一武道大会般的排序]]></title>
    <url>%2Fposts%2F1e089afc%2F</url>
    <content type="text"><![CDATA[并归与淘汰赛不得不说的故事 想起童年时期观看的龙珠，天下第一武道大会吸引了世界各地的武术高手前来参赛，而每一个武术高手都需要两两对决，直至16强8强4强，最后才决出冠军。而并归排序于这种淘汰赛有着异曲同工之妙。 并归排序就像是在元素之间举办一场武道大赛，这场大赛分为两个阶段 分组首先，对于一个集合，假设有n个元素，那么我们就对其不断的两两均分。第一层是原数组有n个元素第二层每个组有n/2个元素第三层每个组有n/4个元素第四层则是n/8个元素……直到每一组都只有1个元素为止 合并(merge)在将所有的元素都成功的分组之后，我们就要对元素进行合并了。如同天下第一武道大会的比试一样。不过，不同的在于，天下第一武道大会是比出谁更强，而归并排序仅仅只要小组内比出谁大谁小，然后，每一个小组都会根据大小合并成一个顺序的更大的组 比如1layer n : 1 4 / 2 5 -&gt; layer n-1: 1 2 3 5 在上层会将这些已经排序了的元素进行按顺序合并。最终，所有的元素都会合并成一个有序的集合，这样排序就完成了。 至于怎么将两个有序的集合合并成一个更大的集合呢？我们只需要三步step1建立一个额外的数组用于暂时存储归并的结果step2从左往右逐一比较小集合的元素的大小，从小到到填到临时集合当中step3将有剩余元素的集合复制到临时数组当中step4将临时数组的内容复制到大的集合当中 其实，说到底这样就是两个有序数组合成一个大数组的算法 123456789101112131415161718192021222324252627282930313233343536373839vector&lt;int&gt; sortArray(vector&lt;int&gt;&amp; nums) &#123; sort(nums,0,nums.size()); return nums; &#125; void sort(vector&lt;int&gt;&amp; num,int left,int right) &#123; if(left + 1 &lt; right) &#123; int mid = left + (right - left) / 2; sort(num,left,mid); sort(num,mid,right); merge(num,left,mid,right); &#125; &#125; void merge(vector&lt;int&gt;&amp; num,int left,int mid,int right) &#123; int *arr = new int[right - left]; int lstart = left,rstart = mid,p = 0; while(lstart &lt; mid &amp;&amp; rstart &lt; right) &#123; if(num[lstart] &lt; num[rstart]) arr[p++] = num[lstart++]; else arr[p++] = num[rstart++]; &#125; while(lstart &lt; mid) arr[p++] = num[lstart++]; while(rstart &lt; right) arr[p++] = num[rstart++]; for(int i = 0;i &lt; right - left;i++) num[i + left] = arr[i]; &#125; 由于并归排序需要将数组两两分组，最后再合并，因此时间复杂度为O(nlogn)，而每一次都需要一个辅助数组来辅助合并，因此空间复杂度为O(n)。并且，并归排序是稳定的排序算法]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sort:让我们来提升一下插入排序的性能吧！]]></title>
    <url>%2Fposts%2Fb0cb2387%2F</url>
    <content type="text"><![CDATA[插入排序upupup —&gt; 希尔排序 插入排序是一个平均时间复杂度为O(n^2)的算法，他的效率其实并不算高效，不过，他有两个特点 在大多数元素都是有序的情况下，工作量很少很明显，在大多数元素都是有序的情况下，数组中的元素自然不需要频繁的交换 在元素较少的情况下，插入排序的工作量很少只要n很小，那么工作量自然会很少 要优化插入排序，自然要从这两点出手。 那么，我们怎么才能让一个数组大量元素有序呢？这个时候我们就需要对元素进行一些预处理了。比如，我们可以先将数组的元素两两分组先进行排序。我们首先可以先为元素设立跨度，在这里，元素有8个，那么我们取一半，就每隔4个元素视为一组，这样的话，就可以达成两两分组的目的了123455 8 6 3 9 2 1 7|-------| |-------| |-------| |--------| 首先，先这样进行排序，那么，这一次的排序粗略来说，确实是多次的元素很少的排序，而且，排序出来的结果也是使得数组的元素变得有序起来了，然后，我们在将跨度减少从4变成21235 2 1 3 9 8 6 7|---|---|---| |---|---|---| 首先我们先看看发生了什么，在第二组数据当中，元素就已经是基本有序的状态了，可以看出，在不断的按照分组进行排序的过程当中，元素是趋于有序的，也就是说，虽然，使用的都是插入排序的方法，但是，每一次的排序都充分的或运用了元素少的特点，或运用了大量元素有序的特点，从而从整体上提升了插入排序的效率。 我看看看跨度2排序完的结果11 2 5 3 6 7 9 8 确实，已经是大量有序的情况了。 之后的跨度就是1，也就是普通的插入排序了。 这种希尔排序的方式，叫做朴素的希尔排序，他可以将平均时间复杂度控制在o(n^2)之下 12345678910111213141516171819202122vector&lt;int&gt; sortArray(vector&lt;int&gt;&amp; nums) &#123; int len = nums.size(); while(len &gt; 1) &#123; len /= 2; for(int i = 0;i &lt; len;i++) &#123; for(int j = i + len;j &lt; nums.size();j += len) &#123; int insert = nums[j]; int k; for(k = j - len;k&gt;=0 &amp;&amp; nums[k]&gt;insert;k-=len) &#123; nums[k + len]=nums[k]; &#125; nums[k + len]=insert; &#125; &#125; &#125; return nums; &#125; 当然，在最坏的情况下，希尔排序的时间复杂度甚至可以超过插入排序，比如以下的这个数组12 1 5 3 7 6 9 8 在这个情况下，无论是分割4，2的时候，都是没有办法对数组进行排序的，也就是说预处理就是做了无用功，对于这种情况，就是白白的浪费了性能在预处理之上。 不过，这种情况也是可以避免的，在朴素的方法下，希尔排序的区间增量是等比的，因此，比较容易出现盲区。为了防止这种盲区的出现，希尔排序的每一轮的增量应该是互质的，因此，有很多人提出了很多种增量的方式 比如hibbard增量，他的表达公式是2^k-1，也就是1，3，5，7….的序列。在这个序列下，希尔排序的最坏时间复杂度为O(n^(3/2)) 再比如sedgewick增量，他的表达式是(9 4^k- 9 2^k + 1,4^k - 3 * 2^k + 1),其序列为1,5,19,41,109…..在这种序列下希尔排序的最坏事件复杂度为O(n^(4/3))]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sort:如同整理手牌般的排序]]></title>
    <url>%2Fposts%2F2c2f601e%2F</url>
    <content type="text"><![CDATA[当你在玩扑克之时，庄家发牌的时候，你是怎么处理手上的牌呢？ 假如现在你的手牌是3 5 9 10，这个时候，来了一张8，你会怎么将手牌处理好呢？插入排序？冒泡排序？堆排序？其实，只需要将这张8插入到5和9中间就可以了。 没错，这就是插入排序。和整理手牌的思路是一样的。 首先，我们维护一个有序区，在这个有序区当中，所有的数字都是有序的。然后，我们按顺序从无序区中得到一个数字，然后，查找这个数字应该在的位置，然后，插入的这个位置当中去。 11 4 7 3 比如，☝这个的有序区是1 4 7，那么我们只需要将7和3对比，顺序不对就交换，然后继续对比下一组(3,4)，直到顺序是正确的时候，就能够插入到想要的位置了，同时，有序区的大小也增加了1，等到有序区有整个数组那么大的时候，排序也就结束了。 123456789101112131415vector&lt;int&gt; sortArray(vector&lt;int&gt;&amp; nums) &#123; //一开始，最左边的元素作为有序区，然后不断的进行插入 for(int i = 1;i &lt; nums.size();i++) &#123; int insertValue = nums[i]; int j = i - 1; for(;j &gt;= 0 &amp;&amp; insertValue &lt; nums[j];j--) &#123; nums[j+1] = nums[j]; &#125; nums[j+1] = insertValue; &#125; return nums; &#125; 这个算法的最坏和平均时间复杂度都是O(n^2)，由于是原地排序因此空间复杂度为O(1)。不过，在大量元素有序的情况下，插入排序的性能还是不错的。因为，在大量有序的情况下，有序区的增长是十分的快的，甚至不需要进行插入操作就可以直接扩张有序区了。 因此，插入排序有时候也是快速排序的一种代替手段。]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sort:冒泡的另一种进阶方式]]></title>
    <url>%2Fposts%2F106f3846%2F</url>
    <content type="text"><![CDATA[论插入排序 首先，向我们回顾一下冒泡排序。 13 5 6 7 1 2 9 想要对这个数组进行排序，那么，我们就需要不断的将不符合数组序列要求的元素进行交换，当我们成功的排列了一个数组的时候，将会进行很多很多次的交换，但是，在这么大量的交换下，也就会造成大量的内存读写操作。那么，我们怎么才能避免出现这种情况呢？ 这个时候，我们可以使用精准的交换方式，就比如上面这个数组，我们可以选择最小的一个数1，与3交换，然后，选第二小的2与5交换，那么，每一次的排序，都只会交换一次，这样便可以大大节省了交换元素时所带来的读写内存的操作。 12345678910111213141516171819vector&lt;int&gt; sortArray(vector&lt;int&gt;&amp; nums) &#123; for(int i = 0;i &lt; nums.size();i++) &#123; int min = nums[i]; int index = i; for(int j = i;j &lt; nums.size();j++) &#123; if(min &gt; nums[j]) &#123; min = nums[j]; index = j; &#125; &#125; swap(nums[i],nums[index]); &#125; return nums; &#125; 不过，可惜的一点是。虽然是减少了内存的读写操作，但是时间复杂度是没有任何的变化的，而且，与冒泡排序相比，这是一个不稳定的排序，也就是说，无法确定在自己前面的这个元素在排序之后仍然在自己的前面，比如以下这个数组 15 8 5 3 6 经过第一次排序之后，3和5交换，这个时候，两个5的位置就发生了交换了。而这个在冒泡排序当中是不存在的，第一个5永远会在第二个5的前面，因为他是一个稳定的排序]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sort:排序算法中居然还有此等邪道?]]></title>
    <url>%2Fposts%2Fb7e22b5b%2F</url>
    <content type="text"><![CDATA[其实只是计数排序而已🌶 计数排序是一种很快速的排序方式，其时间复杂度可达到O(n)，可以说是完爆其他算法，当然其缺点也是比较明显。现在，就让我们先看看这个排序到底是怎么操作的吧。 首先，常规的排序手法一般都是对数组当中的元素进行交换与排序，但是，计数排序不同，他是根据数组元素位置的统计来进行排序的，从原理上来说，他并没有对数组当中的任何一个元素进行交换。 就让我们举个例子吧 15 4 4 2 3 我们要如何进行计数排序呢？最简单的方法即使建立一个大小为6的数组，当出现5的时候，下标为5的地方就加一，最终，得到一个关于每一个元素的数量的统计的数组，然后，按照顺序输出这个数组，就可以达成目的了。 123int arr[6];for(int i = 0;i &lt; 5;i++) arr[num[i]]++; 当然，这里有一个问题，那就是比如这个数组的数字十分之大比如192 91 93 94 95 那么，我们的数组就会有大量的空间被浪费，因此，我们可以在进行计数排序之前，先统计数组的最大值与最小值，然后，建立一个合适大小的数组，然后，根据与最小值的偏移量来确定数组的下标，从而得到了一个比较合适的计数数组 12345678910111213141516171819202122232425262728vector&lt;int&gt; sortArray(vector&lt;int&gt;&amp; nums) &#123; int min = INT_MAX,max = -INT_MAX; for(int i = 0;i &lt; nums.size();i++) &#123; if(nums[i] &gt; max) max = nums[i]; if(nums[i] &lt; min) min = nums[i]; &#125; int *arr = new int[max - min + 1]; memset(arr,0, sizeof(int) * (max - min + 1)); for(int i = 0;i &lt; nums.size();i++) &#123; arr[nums[i] - min]++; &#125; vector&lt;int&gt; result(nums.size()); int index= 0; for(int i = 0;i &lt; max- min + 1;i++) &#123; for(int j = 0;j &lt; arr[i];j++) &#123; result[index]= i +min; index++; &#125; &#125; return result; &#125; 计数排序确实很快，但是他的局限性也是很大，首先一旦max 与 min的差距十分之大，那么他的空间消耗将会十分严重，同时，他对于非整型的数就没有办法了，比如浮点数，根本就不知道应该怎么去确立统计数组]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sort:堆排序与优先队列原来是这样的关系？]]></title>
    <url>%2Fposts%2Fe3e8096%2F</url>
    <content type="text"><![CDATA[堆排序，优先队列，算法本质上都是一样的。 二叉堆没错，无论是堆排序还是优先队列，使用的都是二叉堆。 二叉堆其实就是一颗完全二叉树，同时二叉堆也分为两种 最大堆 最小堆 最大堆说的就是，任何一个父节点的大小都是比子结点要大的。最小堆则是恰恰相反，任何一个父节点都要比子结点要小。 举个例子123 1 2 34 5 这就是最小堆☝ 因为最大堆和最小堆的特点，决定了他们的堆顶元素一定是堆中最大的或者是最小的元素。 那么问题来了，我们应该怎么去构建一个堆呢? 对于一个二叉堆来说，应该是有三种操作 插入节点 删除节点 构建二叉堆 那么我们就一个个说明怎么操作的。 插入节点对于一个节点的插入，我们会将其插入到二叉堆的尾部，也就是最后一个元素的后面。因为，我们不知道这个节点的具体应该是属于二叉堆当中的哪个位置，因此，我们需要不断的与其父节点进行对比。我们以最大堆为例，那就是假如插入节点比父节点大的时候，就和父节点交换位置，直到插入节点再也没有父节点或者说插入节点的父节点比插入节点大的时候才停止。我们将这个操作称之为上浮。12while parentNode exist &amp;&amp; newNode &gt; parentNode swap(newNode,parentNode) 删除节点当我们删除一个节点，其实并不是说删除任意一个节点，而是移除堆顶节点(pop)。没错，这个操作其实是和插入操作完全相反的，插入是向尾部，而移除是堆顶。当我们移除了堆顶元素的时候，我们这个时候选择最后一个节点作为新的堆顶元素，当然，这个新的节点一定是不合规矩的，就以最大堆为例，这个节点一定不是最大的。因此，我们就需要对堆进行调整，对这个节点进行下沉 首先，我们先找到这个节点的子节点，然后对两个节点进行对比，选择出其中最大的那个节点，假如目标节点比最大子节点小，就和最大子节点交换位置，这个操作一直到没有子节点或者是最大子节点都比自己小为止，这样，就可以使得这个目标节点回到正确的位置，而堆也恢复了原本的性质 至于为什么不是随便选一个节点，那当然是因为最后一个节点一定是没有叶子节点的，移动他没有什么代价。 12345678910remove topNode;move lastNode to top;while lastNode lchild exist if lastNode has rchild and rchild &gt; lchild targetChild = rchild if targetChild &lt; lastNode break else swap lastNode,targetChild 构建二叉堆一个二叉堆一开始当然是无序的🌶 因此，一开始我们就要构建一个二叉堆。构建这样一个堆，我们可以使用自底向上的方法去实现。首先，我们先从最后一个父节点开始构建，假如，这个父节点比最大的子节点小，那么父节点就需要下沉，这个下沉和删除节点的算法一样(因为是和最大的子节点替换，那么子节点一定就是符合二叉堆规矩的节点了)。然后，我们再去找上一个父节点，就这样，从最后一个父节点不断下沉，直到根节点，这样，一个二叉堆就构建起来了 12345678for node = last node which has leaf node to root while node lchild exist if node has rchild and rchild &gt; lchild targetChild = rchild if targetChild &lt; node break else swap node,targetChild 其实总结起来，二叉堆的算法只有下沉和上浮两种，加入了新节点上浮，构建堆和删除节点就下沉 不过，二叉堆虽然是看作一个完全二叉树，但是，他和一般的树又完全不同，他使用的是树组的形式来存储数据，就是说，他只是一颗逻辑上的完全二叉树，根据完全二叉树的节点的运算我们就可以知道，左孩子与右孩子与父节点的下标关系lchild = parent*2 + 1,rchild = parent*2 + 2 让我们具体来实现一下下沉与上浮以及构建树的算法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546void buildheap(vector&lt;int&gt;&amp; nums)&#123; for(int i = nums.size() / 2;i &gt;= 0;i--) &#123; sink(nums,i,nums.size()); &#125;&#125;void raise(vector&lt;int&gt;&amp; arr,int len)&#123; int child = len - 1; int parent = (child - 1) / 2; int temp = arr[child]; while(parent &gt; 0 &amp;&amp; arr[parent] &gt; temp) &#123; arr[child] = arr[parent]; child = parent; parent = (parent - 1) / 2; &#125; arr[child] = temp;&#125;void sink(vector&lt;int&gt;&amp; arr,int parent,int len)&#123; int temp = arr[parent]; int child = 2 * parent + 1; while(child &lt; len) &#123; int rchild = child + 1; if(rchild &lt; len &amp;&amp; arr[child] &lt; arr[rchild]) child = rchild; if(temp &gt; arr[child]) break; arr[parent] = arr[child]; parent = child; child = child * 2 + 1; &#125; arr[parent] = temp;&#125; 堆排序然后，我们进入我们的第一个正题(?) 既然我们知道了二叉堆有这么一个奇妙的特点，那么我们为什么不利用他来构建一个排序算法呢？毕竟二叉堆的建立以及恢复的时间复杂度只是O(logn) 其实是可以的，假如我们想要建立一个升序排序的数组，那么，我们完全首先先对数组len=N建立一个最大堆，那么这个时候num[0]的元素就是最大的元素了，然后，我们将其与数组最后一个元素交换swap(num[0],num[N-1] 是不是很熟悉？这个就是删除的操作要进行的事。 那么接下来只需要对堆顶元素进行下沉就完事了，而且，由于第一个元素已经脱离了堆，因此堆的长度就只剩下len=N-l，那么以此类推，我们将所有的最大的元素都向堆的末尾交换(如同删除堆顶元素)，那么，最后堆完全被删除之后，剩下的数组不就是有序的嘛。 这个操作因为每一次都要进行下沉操作，一共进行N次，所以时间复杂度为O(nlogn)和快速排序一样的。但是，有一点不同的就是，快速排序的最差时间复杂度是O(n^2),而这个即使是最差的情况也是O(nlogn) 不过，由于这个算法是原地排序的因此是不需要像快速排序一样耗费额外的空间，只需要O(1)的空间复杂度就可以了 1234567891011vector&lt;int&gt; sortArray(vector&lt;int&gt;&amp; nums) &#123; buildheap(nums); for(int i = nums.size() - 1;i &gt; 0;i--) &#123; swap(nums[i],nums[0]); sink(nums,0,i); &#125; return nums;&#125; 优先队列首先，我们先看看队列是啥？没错，队列就是一个先进先出的数据结构，那么优先队列是啥呢？优先队列则是最大(小)的永远是先出的。是不是，这又是二叉堆的操作 没错，实际上优先队列就是一个二叉堆，当push了一个新节点的时候，就是二叉堆的加入新节点，他会将新节点调整到堆合适的位置去，然后当pop元素的时候，就是删除一个堆顶元素，然后就是使用二叉堆的删除操作。 所以，所谓的优先队列其实就是维护着一个最大或者最小堆，然后进行队列的操作。]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sort:简单易懂的快排]]></title>
    <url>%2Fposts%2F1a46f86c%2F</url>
    <content type="text"><![CDATA[其实快排和冒泡有着这样那样的关系哦 快速排序，其实是从冒泡排序演变而来的一种算法，但是比冒泡排序高效的多，因此，就叫做快速排序了。 和冒泡排序的一轮只移动一个元素相比，快速排序使用了分治的思想，在每一轮都挑选一个基准元素，然后将比基准元素大的都放在基准元素的右边，比基准元素小的，都放在其左边，从而把数组分为两个部分。 在分治的思想下，每一轮数组都可以分成两个子数组，直到不可在分的时候，在平均情况下，需要分logn轮，也就是说，快速排序的平均时间复杂度是O(nlogn) 确定基准元素 那么，第一个问题就是基准元素怎么确定，一般来说，都是选择数组的第一个元素，也就是最左边的元素作为基准元素，不过会有以下的这种情况 18 7 6 5 4 3 2 1 那么，当我们每一次都选择最左边的元素作为基准元素的话，每一次都只能分割出L[1],R[N-1]两个数组，换句话说，就是一次只能确定一个元素的位置。这样，就和冒泡排序是一模一样的了，所以，在最坏情况下(逆序)快速排序的时间复杂度为O(n^2)。不过，在大量无序的情况下，这在情形出现的概率实在是太小了，因此，快速排序的平均时间复杂度仍然为O(nlogn) 不过，为了更好的避免这种情况，我们可以从数组当中随机选出一个数来作为基准值。 构建快速排序 按照快排的算法思路，我们可以大致的将快速排序的算法写出来，那么，唯一的问题就是分治是怎么做的了 123456789void quickSort(vector&lt;int&gt;&amp; nums,int left,int right)&#123; if(left &gt;= right) return; int index = partition(nums,left,right); quickSort(num,left,index -1); quickSort(num,index +1,right);&#125; partition首先，在每一次的分治当中，我们就简单的取最左边的元素作为基准值了. 1piovt = num[left]; 挖坑法挖坑法，简单来说就是，对于每一次交换的时候都挖一个坑，下一次交换的时候将这个坑填上。 step1首先，现找到基准元素，并记住其index，这就是一个坑。step2当右指针所指的元素比基准元素大的时候，右指针向左移动。当右指针所指位置比基准元素小的时候，就将右指针的数填入坑当中，并且，右指针所指位置就是新的坑12num[index] = num[right];index = right; step3当左指针所指元素比基准元素小的时候，左指针向右移动。当左指针所指位置比基准元素大的时候，就将左指针的数填入坑中，并且，左指针所在的位置就是新的坑12num[index] = num[left];index = left; step4最后的最后，那么，左右指针就会重叠在一起，这个时候退出循环并将基准值piovt赋予到最后一个坑当中(毕竟第一个坑的指本里就是基准元素的，这个时候要还回来) 这样，简单的快排分治的一轮就完成了。 123456789101112131415161718192021222324252627282930313233343536int partition(vector&lt;int&gt;&amp;num,int left,int right)&#123; int pivot = num[left]; int index = left; while(right &gt; left) &#123; while(right &gt; left) &#123; if(num[right] &lt; pivot) &#123; num[index] = num[right]; index = right; left++; break; &#125; right--; &#125; while(left &lt; right) &#123; if(num[left] &gt; pivot) &#123; num[index] = num[left]; index = left; right--; break; &#125; left++; &#125; &#125; num[index] = pivot; return index;&#125; 指针交换法指针交换法和挖坑法相比，就更加的直观暴力了，那就是，找到不符合要求的左边的元素和右边的元素，然后使其交换位置，直到两个指针重叠位置，这个时候，将基准元素赋予给这个中间位置。 step1首先，现找到基准元素，并记住其值pivotstep2当右指针所指的元素比基准元素大的时候，右指针向左移动。当右指针所指位置比基准元素小的时候，就停下来12while(left &lt; right &amp;&amp; num[right] &gt; pivot) right--; step3当左指针所指元素比基准元素小的时候，左指针向右移动。当左指针所指位置比基准元素大的时候，也停下来12while(left &lt; right &amp;&amp; num[left] &lt; piovt) left++; step4之后由于此时两边的指针都是指向不符合要求的元素，因此，交换其位置1swap(num[left],num[right]); step5最后，两个指针重叠在一起了，就将基准元素赋予给他1swap(num[left],num[pivotIndex]); 指针交换法就完成了123456789101112131415161718192021int partition(vector&lt;int&gt;&amp; num,int left,int right)&#123; int pivot = num[left]; int startPoint = left; while(left != right) &#123; while(left &lt; right &amp;&amp; num[right] &gt;= pivot) right--; while(left &lt; right &amp;&amp; num[left] &lt;= pivot) left++; if(left != right) &#123; swap(num[left],num[right]); &#125; &#125; swap(num[left],num[startPoint]); return left;&#125; 快速排序这种分而治之的思想其实和BST十分的相似，不过，说到底，BST和快排的模式其实就是一样的，思路都是比基准小的放在左边，大的放在右边。平均时间复杂度和最坏时间复杂度都是一样的。]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sort:冒泡排序不得不说的秘密?]]></title>
    <url>%2Fposts%2Fb446b6c0%2F</url>
    <content type="text"><![CDATA[你知道冒泡排序有几种写…咳咳…优化方法吗 冒泡冒泡冒从数组头到为，每一对(n,n+1)的元素，若位置不对，就交换之，重复n遍，元素会慢慢漂浮到正确的位置，如同碳酸饮料中的气泡一样。顾名思义，冒泡排序 普通的冒泡排序 这个就是很常规的方式🌶 1234for(int i = 0;i &lt; nums.size();i++) for(int j = 0;j &lt; nums.size() - 1;j++) if(nums[j] &gt; nums[j+1]) swap(nums[j],nums[j+1]; 虽然说，冒泡排序是一个平均时间复杂度为O(n^2)的算法，不过他的最好时间复杂度是O(n)。在面对大量有序的情况下，他还是比较快的。 那么，首先就是第一步，假如有这么一个序列 12 1 3 4 5 6 7 8 实际上，只要进行一次交换(2,1)交换，就能够得到一个有序的数组了，但是，按照常规的方式，却还是要跑完全程才能解决。而剩下的循环是不必须的，因此，我们可以让他尽早的跳出循环(当数组有序的时候，就结束循环) 1234567891011121314bool sorted;for(int i = 0;i &lt; nums.size();i++)&#123; sorted = true; for(int j = 0;j &lt; nums.size() - 1;j++) if(nums[j] &gt; nums[j+1]) &#123; swap(nums[j],nums[j+1]; sort = false; &#125; if(sorted) break;&#125; 添加一个标志位，从而使其能够早早跳出不必要的循环 ver1的确确实实优化了冒泡排序，虽然还是O(n^2)是改不了的。 然后我们再看看以下这个情况 14 3 2 1 5 6 7 8 在这个序列当中，5…8明显是不需要排序的，但是，我们还是要去对他进行对比，这也是一些不必要的操作，既然这样，我们为何不优化他呢？让我们看看冒泡排序ver2 123456789101112131415161718bool sorted;int unorderBorder = nums.size() - 1;for(int i = 0;i &lt; nums.size();i++)&#123; sorted = true; int lastExchange = 0; for(int j = 0;j &lt; unorderBorder;j++) if(nums[j] &gt; nums[j+1]) &#123; swap(nums[j],nums[j+1]; sort = false; lastExchange = j; &#125; unorderBorder = lastExchange; if(sorted) break;&#125; 我们使用一个变量去确认未排序边界到底在哪里，那么最后一个被交换的元素的位置，自然就是最后一个无序元素的地址了，这样我们就可以找到无序元素的边界，从而让排序算法只在无序元素当中处理。 这些优化方法，在大量数据都是有序的时候都是比较有用的(毕竟冒泡排序也只是在大量有序的情况下才会展示其优势嘛) 鸡尾酒排序鸡尾酒排序其实就是冒泡排序的一种优化，本质上还是冒泡排序。 他的算法思路就是从右往左进行了一次冒泡之后，我就从左往右再进行一次排序，这样最小和最大的元素实际上就已经分开完毕了。可能就是这在左往右倒，右往左倒的方式，和调酒有点相似吧，因此，这个算法就叫作鸡尾酒排序。 和上面的ver1,ver2一样，鸡尾酒排序其实也是为了解决一种在大量有序的情况下的性能比较低的场景而出现的，让我们看看以下的数组 12 3 4 5 6 7 8 1 按照，之前的冒泡排序，这个1要回到正确的位置，那可必须要跑完n*n的完整的算法才能回归到正确的位置。这自然是很不合算的。那么，鸡尾酒排序就展现了其优势了，先从左到右排好，然后右往左一下，1就回归了，再根据之前ver1,ver2的优化，这个数组就不用再排序了，算法就跳出来了。 12345678910111213141516171819202122232425262728293031323334353637bool sorted;int unorderLeftBorder = 0,unorderRightBorder = nums.size() - 1;int lastLeftExchange = 0,lastRightExchange = nums.size() - 1;for(int i = 0;i &lt; nums.size() / 2;i++)&#123; sorted = true; for(int j = unorderLeftBorder;j &lt; unorderRightBorder;j++) &#123; if(nums[j] &gt; nums[j + 1]) &#123; swap(nums[j],nums[j + 1]); sorted = false; lastRightExchange = j; &#125; &#125; if(sorted) break; sorted = true; unorderRightBorder = lastRightExchange; for(int j = unorderRightBorder;j &gt; unorderLeftBorder;j--) &#123; if(nums[j - 1] &gt; nums[j]) &#123; swap(nums[j - 1],nums[j]); sorted = false; lastLeftExchange = j; &#125; &#125; unorderLeftBorder = lastLeftExchange; if(sorted) break;&#125; 在大量数据有序的情况下，这个方式确实是比冒泡排序优良不少]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kmp algorithm]]></title>
    <url>%2Fposts%2F92c0c7ad%2F</url>
    <content type="text"><![CDATA[小题目引出大问题,kmp算法，简单的快速字符串匹配 本来只是在做leetcode的一个简单题，然后就发现了这个。 实现 strStr() 函数。 给定一个 haystack 字符串和一个 needle 字符串，在 haystack 字符串中找出 needle 字符串出现的第一个位置 (从0开始)。如果不存在，则返回 -1。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/implement-strstr著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 于是，就此可以去实现一下kmp算法了。 简述KMP首先，还是要简单的说明一下kmp算法到底是怎么样的算法。 首先，我们先回顾一下最最简单的子串匹配算法是怎么样的。 123456for(i = 0;i &lt; str.size();i++)&#123; for(j = 0;i + j != str.size() &amp;&amp; j != needle.size() &amp;&amp; str[i+j] == needle[j];j++); if(j == needle.size()) //match&#125; 十分暴力的破解方法，对于每一个匹配失败的情况，都要从开头重新匹配，也就是要消耗O(n*m)的时间去寻找子串。然而，最关键的是有一些回溯是完全没有必要的，比如，你的子串是”nano”,那么，当你匹配了”nan”的时候，而下一个不是”o”的情况下，其实是完全没有必要从头来过的。因为，”nan”是已知的信息，也就说无论回不回溯，n-&gt;a-&gt;n的顺序是不会变的，那么n-&gt;a的这两个地方的回溯是不需要的，直接从第二个n开始也是可以的。(进行了回溯后,a != “nano”的开头n，因此，回溯是不必要的) 因此，我们自然就想到了一种优化的方法，那就是不回溯指针i，因为，我们是知道串str[i...i+j]的所有信息的，那么，我们完全可以不回溯外面的循环，而是改变指针j的指向，从而实现对串str一次过的匹配就可以寻找到目的的方式来减少时间复杂度，这样我们就只需要遍历一次字符串就可以达到目的了时间复杂度当场变成了O(n+m)由于n&gt;=m因此，时间复杂度就是O(n) 那么接下来的问题就是，怎么样去确定指针j的去处了。 详解KMP还是使用”nano”作为needle作为例子。 1234567891011121314 0 1 2 3 4 5 6 7 8 9 10 11 T: b a n a n a n o b a n oi=0: Xi=1: Xi=2: n a n Xi=3: Xi=4: n a n oi=5: Xi=6: n Xi=7: Xi=8: Xi=9: n Xi=10: X 这是暴力法匹配的形式，但是，在i=2的时候遇见的失败，我们可以不去管i=3的时候的情况的，我们可以保持着当前匹配位置的指针i+j不变(因为，我们实际上已知了串str[i..i+j]的消息了，因此其实无需将指针i+j回溯成i的)，然后，修改j的值重新开始匹配，也就是说换成这种形式 12i=2: nani=4: nano 那么，我们要怎么去确定j所调节的位置呢？其实很简单，我们将已匹配过的串看作是x，needle串看作是y，那么，我们只需要以x的后缀与y的前缀之间重叠最多的部分作为调整j的根据。 还是使用”nano”举例子，当我匹配了任何一个”nan”之后，只要我下一个匹配的不是”o”，我都是需要重新进行匹配的，但是在我已知的位置当中，”nan”是已匹配的，也就是我知道了前面是”nan”，那么即使我不移动指针i+j，我也知道，当前如果是”nano”中的第一个字符”n”是匹配的，我是不需要再匹对他的。 换句话说，只要是被匹配的串的后缀与needle串的前缀所重合的地方，我们都是不需要再重新匹配的，因为，在之前是已经匹配过了。 让我们看一下这个到底是怎么匹配的 1234567step 1:nan nano =&gt; true :"n"step 2:nan nano =&gt; false 看得出来，”nan”与”nano”的前缀后缀最大重合的地方就只有”n”也就是说，当匹配成功”nan”后，假如匹配不成功，那么只需要将j回退到”n”的位置就可以了。至于为什么不是”nan”是最大重合的串，因为needle作为被匹配的串，肯定是会向后移动的阿，因此，这也是已匹配的串的后缀与needle串的前缀匹配的意思。 那么，我们现在就可以得出，kmp当中不需要回溯的匹配部分的写法了 123456789101112131415161718int j = 0;for(int i = 0;i &lt; haystack.size();i++)&#123; for(;;) &#123; if(haystack[i] == needle[j]) &#123; j++; if(j == needle.size()) return i - needle.size() + 1; break; &#125; else if(j == 0) break; else j = overlap[j]; &#125;&#125; 当匹配不成功的时候，就根据overlap的指示进行回退，其中overlap指的就是重合字符串的个数了。重合了多少个，就有多少个不需要重新匹对， 对于一个needle来说，有一点很幸运，那就是overlap完全可以只使用needle串就计算出来，也就是说与匹配字符串无关，这样做，可以使得我们能够在preprocessing阶段就完成了对overlap的设计 对于overlap[j]指的是，当匹配到j的时候，有多少个重复的字符串在子串当中，也就是说我们其实只需要对两个串所有重合的地方进行比对，找到最长的重合的串就可以了。 现在先定义两个方法:overlap(x,y)返回的是关于x的后缀与y的前缀的最长字符串(不一定要相等)，shorten(x)，返回的是x的前缀，但是少了首字符 那么，我们就可也完成overlap计算的方式了 1234567z = overlap(shorten(x),y)while(last char of x != y[length(z)-1])&#123; if(z == empty) return overlap(x,y) = empty else z = overlap(z,y)&#125;retrun overlap(x,y) = z 大概就是这种方式，不过，也可以看出来，在这里的计算，每一个overlap(x,y)的值都是依赖于先前一个的overlap(x,y)的值的(如果当前情况下匹对不成功，那么就返回上一次的overlap(z,y)，缩短匹配长度继续匹配)，我们可以将每一次计算的指保存下来，然后，就可以比较快的计算出最后的结果了。 那么我们就可也转化为下面这在方式 12345678910int *overlap = new int[needle.size() + 1];overlap[0] = -1;for(int i = 0;i &lt; needle.size();i++)&#123; overlap[i + 1] = overlap[i] + 1; while(overlap[i + 1] &gt; 0 &amp;&amp; needle[i] != needle[overlap[i + 1] - 1]) overlap[i + 1] = overlap[overlap[i + 1] - 1] + 1;&#125; 当然，其实在本质上，kmp的字符串匹配序列可以看作是一个有限自动机，根据不同的匹配结果跳到不同的状态下 strStr()顺便附上leetcode的解答12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution &#123;public: int strStr(string haystack, string needle) &#123; if(needle.empty()) return 0; int *overlap = new int[needle.size() + 1]; overlap[0] = -1; for(int i = 0;i &lt; needle.size();i++) &#123; overlap[i + 1] = overlap[i] + 1; while(overlap[i + 1] &gt; 0 &amp;&amp; needle[i] != needle[overlap[i + 1] - 1]) overlap[i + 1] = overlap[overlap[i + 1] - 1] + 1; &#125; int j = 0; for(int i = 0;i &lt; haystack.size();i++) &#123; for(;;) &#123; if(haystack[i] == needle[j]) &#123; j++; if(j == needle.size()) &#123; j = overlap[j]; return i - needle.size() + 1; &#125; break; &#125; else if(j == 0) break; else j = overlap[j]; &#125; &#125; return -1; &#125;&#125;; 参考资料: Knuth-Morris-Pratt string matching]]></content>
      <tags>
        <tag>leetcode</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[manacher's algorithm]]></title>
    <url>%2Fposts%2F589b7415%2F</url>
    <content type="text"><![CDATA[这是一个寻找回文子串的算法，时间复杂度为线性的。 首先，先介绍以下回文串，顾名思义，回文串就是一个无论正着读还是倒着读都是一模一样的串，比如”level”,”refer”这些。如果，我们使用暴力的方法来求一个字符串中最长回文串的话，那么，我们就需要对每一个子字符串都要进行回文的匹对，然后，对比所有的最后才能得知最长的那个在哪里。不过，既然都是回文了，那么，自然也可以从中心开始展开去寻找回文串到底在哪，但是，这又区分了偶数长度的回文串和奇数长度的回文串(偶数长度的回文串的中心点在两个中心字符中间)，就十分的麻烦，时间复杂度也是O(n^2)的 而这个算法，可以说是利用了巧妙的方式，去寻找回文串。 思路这个算法的思路就是，为输入的字符串的首尾以及每个字符的中间都添加一个独一无二的符号(我们这里就设定为”#”) 12input: "babad"output: "#b#a#b#a#d#" 这样，每一个原串的字符都可以组成一个奇数长度的回文串了，这首先就是省略了偶数回文串匹配时候出现的麻烦的事了。 然后，第二件事情就是建立一个len数组，这个数组所作的唯一的事情就是记录每一个字符，以其为中心的最长的回文串的半径(就是从自身开始，数到最右边的回文字符的长度)。 123input: "babad"output: "# b # a # b # a # d #"len: 1,2,1,4,1,4,1,2,1,2,1, 解释一下，那就是比如第一个”#”,他的回文串最长半径就是1，也就是只有他自己，然后b是2，因为他的最长回文串是”#b#”，因此，半径就是2了。 那么，只要找到len当中最长的数，自然就可以找到字符串当中最长的回文字符串了。这样，剩下的问题就只有一个了，那就是怎么去构建len数组了。 构建len数组 构建这个数组，首先我们需要知道两个东西，一个是maxPos，这个的意思就是，已经匹配到的最长的回文子串的最右边的位置,然后，另一个就是centerPos,这个的意义则是maxPos对应的子串的中心点的位置。 现在，让我们从左到右依次计算len[i]了 首先，我们现在面临了两种情况,第一种是i &lt; maxPos，也就是说，当前的位置在已经找到了的回文串的里面。由于回文串是根据中心点对称的，因此，我们可以依靠centerPos这个点来找到i的对称点j,当然i &gt;= j是一定的(这个之后解释),由于回文串是对称的那么我们就可以得知len[j]的大小，假如len[j] &lt; maxPos - i也就是说明，len[j]的最大回文串是在已经匹配了的最长回文串当中的，由于回文串是中心对称的，因此len[i] = len[j]是成立的。 然后，假如len[j] &gt; maxPos - i也就是说，回文串的大小应该是比已经找到的最大的回文串的长度还要远，因为，那已经超过了我们已经搜索的范围了，因此，我们自然不可能知道len[i]的长度，因此，这个时候我们就需要向外一个个匹对从而找到len[i]的长度了。 然后，第二个情况就是i &gt;= maxPos了，这个时候，同样超出了我们的匹对范围了，因此需要向外不断的探索从而找到len[i]的大小。 最后，我们只需要遍历一遍字符串就可以找到最长的回文子串的位置了。 寻找最长回文子串既然，已经有了思路和算法，那么寻找也不是难事了。 给定一个字符串 s，找到 s 中最长的回文子串。你可以假设 s 的最大长度为 1000。示例 1:123输入: "babad"输出: "bab"注意: "aba" 也是一个有效答案。 示例 2：12输入: "cbbd"输出: "bb" 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class Solution &#123;public: string longestPalindrome(string s) &#123; if(s.empty()) return ""; //init string temp; for(int i = 0;i &lt; s.size();i++) &#123; temp.append("#"); temp += s[i]; &#125; temp.append("#"); int *len = new int[temp.size()]; memset(len,0,sizeof(int) * temp.size()); int maxPos = 0,centerPos = 0,max = 0,pos = 0;; for(int i = 0;i &lt; temp.size();i++) &#123; if(maxPos &gt; i) len[i] = min(maxPos - i,len[2 * centerPos - i]); else len[i] = 1; //注意边界检查 while(i - len[i] &gt;= 0 &amp;&amp; i + len[i] &lt; temp.size() &amp;&amp; temp[i - len[i]] == temp[i + len[i]]) len[i]++; if(len[i] + i &gt; maxPos) &#123; maxPos = len[i] + i; centerPos = i; &#125; //记录最长的位置 if(len[i] &gt; max) &#123; max = len[i]; pos = i; &#125; &#125; //还原原字符串的位置，并输出 return s.substr((pos + 1) / 2 - len[pos] / 2,(len[pos] * 2 - 1) / 2); &#125;&#125;; 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/longest-palindromic-substring著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。]]></content>
      <tags>
        <tag>leetcode</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode:sudoku solver]]></title>
    <url>%2Fposts%2Fb6eeaa30%2F</url>
    <content type="text"><![CDATA[Write a program to solve a Sudoku puzzle by filling the empty cells. A sudoku solution must satisfy all of the following rules: Each of the digits 1-9 must occur exactly once in each row.Each of the digits 1-9 must occur exactly once in each column.Each of the the digits 1-9 must occur exactly once in each of the 9 3x3 sub-boxes of the grid.Empty cells are indicated by the character ‘.’ 解数独是一件很有意思的事情，因为，我自己根本不知道应该怎么解QAQ 不过，使用代码的话就完全不一样了。因为，计算机可以穷举啊。 思路其实，这个问题我感觉和搜索联通的路是一样的。我们不断向下一个点试探（填数字），当遇到不能前进的时候（数字不能再填了，不然会有重复）就回溯。因此，没有错了，dfs就是你。 有了思路就很简单了，当遇见一个已经填了的数字的时候，就下一个格子，当遇见可以填的格子的时候，就填1，然后下一个格子，假如下一个格子碰壁了，那么就回溯到这个格子，然后，这个格子改为2（也就是1到9一个个试辣），那么，当格子填满的时候，就不需要再填了。这也是，dfs结束的时候。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071class Solution &#123; //记录是否以及填满格子了 bool get = false; //用于判断这个格子可以填写哪些数字 bool row[9][9] = &#123;false&#125;,col[9][9] = &#123;false&#125;,block[9][9] = &#123;false&#125;;public: void solveSudoku(vector&lt;vector&lt;char&gt;&gt;&amp; board) &#123; //先将以及填上去的数字记录了 for(int i = 0;i &lt; 9;i++) &#123; for(int j = 0;j &lt; 9;j++) &#123; if(board[i][j] == '.') continue; int index = 3 * (i / 3) + j / 3; int num = board[i][j] - '0'; row[i][num - 1] = col[j][num - 1] = block[index][num - 1] = true; &#125; &#125; dfs(0,0,board); &#125; void dfs(int i,int j,vector&lt;vector&lt;char&gt;&gt;&amp; board) &#123; //填满了就结束了 if(i == 9) get = true; if(get) return; //如果这个格子已经被填了就下一个格子 if(board[i][j] != '.') &#123; if(get) return; if(j == 8) dfs(i + 1,0,board); else dfs(i,j + 1,board); &#125; else &#123; //从1到9的查找 for(int num = 1;num &lt;= 9;num++) &#123; int index = 3 * (i / 3) + j / 3; //可以填写就填写这个num if(!row[i][num - 1] &amp;&amp; !col[j][num - 1] &amp;&amp; !block[index][num - 1]) &#123; row[i][num - 1] = col[j][num - 1] = block[index][num - 1] = true; board[i][j] = num + '0'; if(j == 8) dfs(i + 1,0,board); else dfs(i,j + 1,board); //需要回溯了，自然要将填写的数字归还回去，从棋盘以及记录以及填写数字的row,col,block当中消除记录 if(!get) &#123; row[i][num - 1] = col[j][num - 1] = block[index][num - 1] = false; board[i][j] = '.'; &#125; &#125; &#125; &#125; &#125;&#125;; 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/sudoku-solver著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。]]></content>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode:ugly number III]]></title>
    <url>%2Fposts%2Fd658950c%2F</url>
    <content type="text"><![CDATA[Write a program to find the n-th ugly number. Ugly numbers are positive integers which are divisible by a or b or c. 12345Example 1:Input: n = 3, a = 2, b = 3, c = 5Output: 4Explanation: The ugly numbers are 2, 3, 4, 5, 6, 8, 9, 10... The 3rd is 4. 解题思路 对于这样的丑数，假设我们的目标数为tar，那么tar绝对是满足或被a整除，或被b整除，或被c整除，那么，其实他们的能被整除的count就有这样的关系 这就不难算出，某个数的count到底是多少了。 count = tar/a+tar/b+tar/c-tar/ab-tar/ac-tar/bc+tar/abc这就可以使用二分查找来寻找目的数 123456789101112131415161718int nthUglyNumber(int n, int a, int b, int c) &#123; long ab = ((long)a * b) /__gcd(a,b); long ac = ((long)a * c) / __gcd(a,c); long bc = ((long)b * c) / __gcd(b,c); long abc = (ab * c) / __gcd((int)ab,c); int left = 0,right = INT_MAX; while(left &lt; right) &#123; long long mid = (long long)left + (right - left) / 2; long long count = mid / a + mid / b + mid / c - mid / ab - mid / ac - mid / bc + mid / abc; if(count &lt; n) left = mid + 1; else right = mid; &#125; return left; &#125; 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/ugly-number-iii著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。]]></content>
      <tags>
        <tag>leetcode</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Implementing a Reliable Transport Protocol]]></title>
    <url>%2Fposts%2F6693b937%2F</url>
    <content type="text"><![CDATA[Computer Networking:A Top-Down approach chapter 3 lab 在这次的实验当中，需要实现一个简单的可靠数据传输协议。(即比特交换协议版本与GBN版本)这是实验的要求 比特交换协议(alternating bit protocol)比特交换协议简单来说，就是对于每个包都使用0和1来标记，一个一个包的确认可靠数据的传输。具体的操作就如同书中的状态机的表达那样。 这个协议的最大的缺点就是，当当前包的ACK确认收到之前，都是不能进行任何的操作的，大大的浪费了带宽。 在这里，我使用一个int标记以及switch的方式来实现这个自动机。如同书中的状态机一样，发送方发送seq而接受方根据seq来回馈确认的ack，最后，发送方依靠ack来切换自己的等待状态，使自己进入新的wait_call状态 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153#define ACK_0 0#define ACK_1 1#define SEQ_0 0#define SEQ_1 1#define SENDER_WAIE_CALLED_0 0#define SENDER_WAIT_ACK_0 1#define SENDER_WAIT_CALLED_1 2#define SENDER_WAIT_ACK_1 3#define TIMER_WAIT 5.0f#define RECV_WAIT_0 0#define RECV_WAIT_1 1int sender_state;struct pkt waitting_ack_pkt;int recv_state;int corrupt(struct pkt *pkt) &#123; int sum = pkt-&gt;acknum + pkt-&gt;seqnum; for (int i = 0; i &lt; 20; i++) &#123; sum += (int)pkt-&gt;payload[i]; &#125; return sum != pkt-&gt;checksum;&#125;void build_pkt(struct pkt *pkt, int ack, int seq, char *data) &#123; pkt-&gt;seqnum = seq; pkt-&gt;acknum = ack; pkt-&gt;checksum = (pkt-&gt;seqnum + pkt-&gt;acknum); for (int i = 0; i &lt; 20; i++) &#123; pkt-&gt;payload[i] = data[i]; &#125; for (int i = 0; i &lt; 20; i++) &#123; pkt-&gt;checksum += (int)pkt-&gt;payload[i]; &#125;&#125;/* called from layer 5, passed the data to be sent to other side */A_output(message) struct msg message;&#123; struct pkt send_pkt; switch (sender_state) &#123; case SENDER_WAIE_CALLED_0: build_pkt(&amp;send_pkt, -1, SEQ_0, message.data); sender_state = SENDER_WAIT_ACK_0; break; case SENDER_WAIT_CALLED_1: build_pkt(&amp;send_pkt, -1, SEQ_1, message.data); sender_state = SENDER_WAIT_ACK_1; break; default: return 0; &#125; waitting_ack_pkt = send_pkt; tolayer3(0, send_pkt); starttimer(0, TIMER_WAIT);&#125;B_output(message) /* need be completed only for extra credit */ struct msg message;&#123;&#125;/* called from layer 3, when a packet arrives for layer 4 */A_input(packet) struct pkt packet;&#123; int c = corrupt(&amp;packet); if (c) return 0; switch (sender_state) &#123; case SENDER_WAIT_ACK_0: if (packet.acknum == ACK_0) &#123; stoptimer(0); sender_state = SENDER_WAIT_CALLED_1; &#125; break; case SENDER_WAIT_ACK_1: if (packet.acknum == ACK_1) &#123; stoptimer(0); sender_state = SENDER_WAIE_CALLED_0; &#125; break; default: break; &#125;&#125;/* called when A's timer goes off */A_timerinterrupt() &#123; tolayer3(0, waitting_ack_pkt); starttimer(0, TIMER_WAIT);&#125;/* the following routine will be called once (only) before any other *//* entity A routines are called. You can use it to do any initialization */A_init() &#123; sender_state = SENDER_WAIE_CALLED_0; &#125;/* Note that with simplex transfer from a-to-B, there is no B_output() *//* called from layer 3, when a packet arrives for layer 4 at B*/B_input(packet) struct pkt packet;&#123; struct pkt recv_pkt; int c = corrupt(&amp;packet); if (c) &#123; build_pkt(&amp;recv_pkt, recv_state == RECV_WAIT_0 ? ACK_1 : ACK_0, -1, packet.payload); tolayer3(1, recv_pkt); return -1; &#125; switch (recv_state) &#123; case RECV_WAIT_0: if (packet.seqnum == SEQ_0) &#123; build_pkt(&amp;recv_pkt, ACK_0, -1, packet.payload); tolayer3(1, recv_pkt); tolayer5(1, packet.payload); recv_state = RECV_WAIT_1; &#125; else &#123; build_pkt(&amp;recv_pkt, ACK_1, -1, packet.payload); tolayer3(1, recv_pkt); &#125; break; case RECV_WAIT_1: if (packet.seqnum == SEQ_1) &#123; build_pkt(&amp;recv_pkt, ACK_1, -1, packet.payload); tolayer3(1, recv_pkt); tolayer5(1, packet.payload); recv_state = RECV_WAIT_0; &#125; else &#123; build_pkt(&amp;recv_pkt, ACK_0, -1, packet.payload); tolayer3(1, recv_pkt); &#125; break; default: break; &#125;&#125;/* called when B's timer goes off */B_timerinterrupt() &#123;&#125;/* the following rouytine will be called once (only) before any other *//* entity B routines are called. You can use it to do any initialization */B_init() &#123; recv_state = RECV_WAIT_0; &#125; GBN(go back n)GBN与比特交换协议相比，多了一个滑动窗口，这样，在窗口内，都可以发送包，而不必一定要等到相应的ack应答。这样做大大改进了比特交换协议的浪费带宽的缺点。 不过，GBN也有一个问题，那就是，当超时(丢包，拥塞发生时)就会重传所有以发送但是未确认的包。但是，其中有些包可能是乱序到达了，从而导致了链路资源的浪费。(这个问题在TCP有优秀的解决方法) 首先，我先指定了一个64大小的窗口，由于GBN协议是不需要接收方也维护一个接受窗口的，因此，只需要依靠接收方回复的ACK来确认以接受的包的位置。然后，根据课本上的状态机的图，以及，处理ACK &lt; base,base &lt; ACK &lt; nextSeqNum,ACK &gt; nextSeqNum的时候的操作，就可以了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131#define N 64#define WAIT_TIME 10.0fstruct pkt sndpkt[N];int base,nextSeqNum;int expectedSeqNum;make_pkt(pkt,ack,seq,data) struct pkt *pkt;int ack;int seq;char *data;&#123; pkt-&gt;acknum = ack; pkt-&gt;seqnum = seq; pkt-&gt;checksum = ack + seq; for(int i = 0;i &lt; 20;i++) &#123; pkt-&gt;payload[i] = data[i]; &#125; for(int i = 0;i &lt; 20;i++) &#123; pkt-&gt;checksum += (int)pkt-&gt;payload[i]; &#125;&#125;corrupt(rcvpkt)struct pkt rcvpkt;&#123; int sum = rcvpkt.acknum + rcvpkt.seqnum; for(int i = 0;i &lt; 20;i++) &#123; sum += (int)rcvpkt.payload[i]; &#125; return sum != rcvpkt.checksum;&#125;/* called from layer 5, passed the data to be sent to other side */A_output(message) struct msg message;&#123; struct pkt send_pkt; if(nextSeqNum &lt; base + N) &#123; make_pkt(&amp;send_pkt,0,nextSeqNum,message.data); sndpkt[nextSeqNum - base] = send_pkt; tolayer3(0,send_pkt); if(base == nextSeqNum) &#123; starttimer(0,WAIT_TIME); &#125; nextSeqNum++; &#125;&#125;B_output(message) /* need be completed only for extra credit */ struct msg message;&#123;&#125;/* called from layer 3, when a packet arrives for layer 4 */A_input(packet) struct pkt packet;&#123; if(corrupt(packet)) return 0; int newBase = packet.acknum + 1; if(newBase &lt; base) return 0; if(newBase == nextSeqNum) stoptimer(0); else &#123; stoptimer(0); starttimer(0,WAIT_TIME); &#125; memmove(&amp;sndpkt,&amp;sndpkt[newBase - base],N - (newBase - base)); base = newBase;&#125;/* called when A's timer goes off */A_timerinterrupt()&#123; starttimer(0,WAIT_TIME); for(int i = 0;i &lt; nextSeqNum - base;i++) &#123; tolayer3(0,sndpkt[i]); &#125;&#125; /* the following routine will be called once (only) before any other *//* entity A routines are called. You can use it to do any initialization */A_init()&#123; base = 1; nextSeqNum = 1;&#125;/* Note that with simplex transfer from a-to-B, there is no B_output() *//* called from layer 3, when a packet arrives for layer 4 at B*/B_input(packet) struct pkt packet;&#123; struct pkt ack_pkt; if(corrupt(packet) || packet.seqnum != expectedSeqNum) &#123; make_pkt(&amp;ack_pkt,expectedSeqNum - 1,0,packet.payload); tolayer3(1,ack_pkt); return 0; &#125; make_pkt(&amp;ack_pkt,expectedSeqNum,0,packet.payload); tolayer3(1,ack_pkt); tolayer5(1,packet.payload); expectedSeqNum++;&#125;/* called when B's timer goes off */B_timerinterrupt()&#123;&#125;/* the following rouytine will be called once (only) before any other *//* entity B routines are called. You can use it to do any initialization */B_init()&#123; expectedSeqNum = 1;&#125; 总结总的来说，这个LAB并不难，但是挺有趣的，让我更加好的理解了这些协议，同时也感受到了TCP协议的优秀。]]></content>
      <tags>
        <tag>computer network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode:populating next rightpointersin each node II]]></title>
    <url>%2Fposts%2Fa88ed812%2F</url>
    <content type="text"><![CDATA[Given a binary tree 123456struct Node &#123; int val; Node *left; Node *right; Node *next;&#125; Populate each next pointer to point to its next right node. If there is no next right node, the next pointer should be set to NULL. Initially, all next pointers are set to NULL. 题目的大致要求就是这样，使用next指针指向右边的兄弟节点。 Note: You may only use constant extra space.Recursive approach is fine, implicit stack space does not count as extra space for this problem. 思路其实，这个题就是将所有兄弟从左到右连接在一起的意思，所以，可以使用层次遍历的形式去完成。 同时，由于他也说了，使用栈的这种形式其实是不算是额外空间的，因此，使用递归也是可以的。递归也就是使用深度优先的方式去连接兄弟节点，不过，值得一提的是，因为，这是从左到右连接的兄弟节点，因此，递归的时候，要从右往左去建立连接，不然，是会出错的。 首先，有一点是需要统一的，无论是递归还是迭代，建立next节点都是需要依赖父节点的，也即是说，在遍历到父节点的时候，就需要为他的所有子节点建立好next的关系了。 1234567891011121314151617// Definition for a Node.class Node &#123;public: int val; Node* left; Node* right; Node* next; Node() &#123;&#125; Node(int _val, Node* _left, Node* _right, Node* _next) &#123; val = _val; left = _left; right = _right; next = _next; &#125;&#125;; 不使用额外空间的层次遍历其实，我们可以将树的每一层都看作是一个链表，而这个链表的头部则是一个存在于树之外的root节点。当我们要建立这个层次的关系的时候，其实就是，不断从这个链表的next节点插入新的值。 而root-&gt;next则总是指向当前层的第一个节点。那么，我们自然就可以得到一个从上往下，从左往右的层次遍历的关系了。 123456789101112131415161718192021222324252627282930313233 Node* connect(Node* root) &#123;//总是指向当前层的root节点 Node *p = new Node(0,nullptr,nullptr,nullptr); Node *cur = root; while(cur) &#123; //从第一层开始 Node *l = p; while(cur) &#123; //根据父节点的信息为子节点建立next的联系 if(cur-&gt;left) &#123; l-&gt;next = cur-&gt;left; l = l-&gt;next; &#125; if(cur-&gt;right) &#123; l-&gt;next = cur-&gt;right; l = l-&gt;next; &#125; cur = cur-&gt;next; &#125; //因为cur和p-&gt;next总是相差一层，因此，就可以实现向下一层的遍历 cur = p-&gt;next; p-&gt;next = nullptr; &#125; return root; &#125; 使用栈其实，使用栈的话，就比较简单明了了。 其实就是列举所有的方式，然后，去按情况连接next。 首先，假如父节点存在左孩子，若右孩子存在，则直接左右连接，否则，向node-&gt;next寻找，直到找到一个离他最近的节点，然后连接起来。 然后，就是加入存在右孩子，就向node-&gt;next找到离他最近的一个节点连接。 从右子树往左子树遍历，即可完成了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465 Node* connect(Node* root) &#123; setNext(root); return root; &#125; void setNext(Node *n) &#123; if(!n) return; //左孩子的情况 if(n-&gt;left) &#123; if(n-&gt;right) n-&gt;left-&gt;next = n-&gt;right; else &#123; Node *p = n; while(p-&gt;next) &#123; if(p-&gt;next-&gt;left) &#123; n-&gt;left-&gt;next = p-&gt;next-&gt;left; break; &#125; else if(p-&gt;next-&gt;right) &#123; n-&gt;left-&gt;next = p-&gt;next-&gt;right; break; &#125; p = p-&gt;next; &#125; &#125; &#125; //右孩子的情况 if(n-&gt;right) &#123; Node *p = n; while(p-&gt;next) &#123; if(p-&gt;next-&gt;left) &#123; n-&gt;right-&gt;next = p-&gt;next-&gt;left; break; &#125; else if(p-&gt;next-&gt;right) &#123; n-&gt;right-&gt;next = p-&gt;next-&gt;right; break; &#125; p = p-&gt;next; &#125; &#125; //从右往左 setNext(n-&gt;right); setNext(n-&gt;left); &#125; 题目来源来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/populating-next-right-pointers-in-each-node-ii]]></content>
      <tags>
        <tag>leetcode</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode:find the duplicate number]]></title>
    <url>%2Fposts%2Fa02b6857%2F</url>
    <content type="text"><![CDATA[Given an array nums containing n + 1 integers where each integer is between 1 and n (inclusive), prove that at least one duplicate number must exist. Assume that there is only one duplicate number, find the duplicate one. Example 1: 12Input: [1,3,4,2,2]Output: 2 Example 2: 12Input: [3,1,3,4,2]Output: 3 Note: 1.You must not modify the array (assume the array is read only).2.You must use only constant, O(1) extra space.3.Your runtime complexity should be less than O(n^2).4.There is only one duplicate number in the array, but it could be repeated more than once. 解法 1，二分查找解题思路这道题从最直观上来看，或许是和二分查找是没有任何关系的，因为，给定的数组是一个乱序的数组，二分查找是没有办法从乱序的数组中找到答案的。 但是，有一点，给了我们可以使用二分查找的方式。那就是，数组一共有n+1项，而数组元素则是1-n之间。 根据抽屉原理不难看出，必有一个重复的项在数组里面。那么，我们自然可以换种方式去寻找答案。 既然，给定的数字是有范围的，那么，我们自然可以从n/2开始寻找。 有一点是比较重要的，那就是，你选择了中间的那个数字的时候，假如，比他小的数字中存在重复项，那么，小于等于这个数字的数的总数应该是大于大于这个数的总数的。反之亦然。 因此我们就可以利用这种方式去构建我们的二分查找 12345678910111213141516171819202122232425262728293031int findDuplicate(vector&lt;int&gt;&amp; nums) &#123; //数字是1-n之间的 int left = 1,right = nums.size()-1; int r_count=0,l_count=0; while(left &lt; right) &#123; //选出中间的数 int mid=left+(right-left)/ 2; //找到比这个数大的数和比这个数小的数的总数 for(int i=0;i&lt;nums.size();i++)&#123; //要注意的一点是要限定对比的空间 //因为当mid进行左移或者右移的时候，被抛弃的区间是不应该来影响计数的 if(nums[i] &gt; mid &amp;&amp; nums[i] &lt;= right) r_count++; else if(nums[i] &lt;= mid &amp;&amp; nums[i] &gt;= left) l_count++; &#125; if(r_count &lt; l_count) right=mid; else left=mid + 1; r_count=0; l_count=0; &#125; //此时left = right，也就是结果 return left; &#125; 在这里使用了他所提供的模板二，使用模板二的原因就是在于，模板二可以使得右指针一直保留在被重复的数当中，这样也可以避免n的奇偶带来的判断的差别。 思考其实这道题挺有意思的。因为，本身一个乱序的数组是不支持二分查找的。但是，当发现了这个题目暗藏的数据区间的信息之后，这个数据区间又可以看作是一个有序的数组，然后找到我想要的数的形式了。 最重要的，还是要开放思维，不要被乱序的数组所局限到。 解法二 循环链表解题思路其实这个方法算是一个比较巧妙的方法。 还是从题目出发，n+1长的数组当中包含1-n的数字。那么，我们是不是可以将这个数组看作是一个循环链表？ 比如nums[0] = 1指的是，下一项为num[1]，那么，数字必然小于n的数组是不可能越界的。而必有重复项则说明，这个链表是比成环的。那么，不就能够将这个问题简化为，寻找循环链表的循环处的问题了呢？ 相比二分查找的O(nlogn)的时间复杂度，这样的时间复杂度显然更低O(n),而且，即使是使用了额外空间，使用hashmap来解决这个题目的问题，时间复杂度也不会变得更低。 12345678910111213141516171819202122int findDuplicate(vector&lt;int&gt;&amp; nums) &#123; //使用快慢指针寻找环的位置 int fast = 0,slow = 0; fast = nums[nums[fast]]; slow = nums[slow]; while(nums[fast] != nums[slow]) &#123; fast = nums[nums[fast]]; slow = nums[slow]; &#125; //改为两个慢指针寻找交汇点 slow = 0; while(nums[fast] != nums[slow]) &#123; fast = nums[fast]; slow = nums[slow]; &#125; return nums[slow]; &#125; 思考所以说，这个题目限定了数字大小的区间真的太好了。能够用很多奇怪的方法实现这个问题。 顺便一提，这个方法在leetcode中叫做弗洛伊德的兔子和乌龟 题目来源 力扣（LeetCode）链接：https://leetcode-cn.com/problems/find-the-duplicate-number]]></content>
      <tags>
        <tag>leetcode</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[csapp:malloclab]]></title>
    <url>%2Fposts%2F4a69870f%2F</url>
    <content type="text"><![CDATA[建立一个动态内存分配器。 内存的组织形式大致有三种。隐式空闲链表，显式空闲链表，以及分离的空闲链表。而内存的分配策略也大致分为三种，最先分配，下一次分配和最优分配。而内存的合并策略则是立即合并和延迟合并。 合并策略就很直观，当你归还内存的时候，我将我前后的空闲块合并起来变成一个大的空闲块，这样，就可以让我的内存碎片变少。立即合并就是立即做这件事，而推迟合并就是在合适的时候才做这件事。至于合适的时候是什么时候，就是仁者见仁了。 最先分配就是最先遇到的合适的内存块就分配出去，下一次分配就是从上一次分配的地方开始寻找，而最优分配就是遍历整个堆空间，找到最合适的空闲块分配出去。 隐式空闲链表 + 首次分配 + 立即合并隐式空闲链表就是，将分配的内存大小保存在内存块的头部，当你需要分配的时候，只需要遍历整个堆空间，找到相应大小的块，然后，按照分配策略就可也分配出想要的块出来了。其内存的组织形式大概是这样1234567struct block&#123; unsigned int header; char payload[N]; //负载元素 char extend[M]; //字节对齐 unsigned int footer;&#125; 书上有代码介绍的也是这种方式。 实现出来的效果其实也不差。 12345678910111213141516171819Using default tracefiles in traces/Measuring performance with gettimeofday().Results for mm malloc:trace valid util ops secs Kops 0 yes 99% 5694 0.006654 856 1 yes 99% 5848 0.006160 949 2 yes 99% 6648 0.010249 649 3 yes 100% 5380 0.007564 711 4 yes 66% 14400 0.000107135084 5 yes 93% 4800 0.006334 758 6 yes 92% 4800 0.006370 754 7 yes 55% 6000 0.030002 200 8 yes 51% 7200 0.023748 303 9 yes 27% 14401 0.127947 11310 yes 34% 14401 0.002625 5487Total 74% 89572 0.227759 393Perf index = 44 (util) + 26 (thru) = 71/100 可以看出，吞吐量虽然不高，不过内存利用率还是不错的。吞吐量不高的原因应该是因为每一次的内存的分配都要从堆的开头开始寻找，因此，当前面的内存都是以分配的时候，就会耗费大量的时间去分配内存了。 分离适配链表 + 首次适配 + 立即合并显式链表其实是对隐式链表的升级，在之前，由于隐式链表的存在，我们只知道分配块的大小而不知道空闲块的地址，因此，只能从堆开头去寻找合适的空闲块，因此，我们在这里，可以用链表的形式将所有的空闲块串在一起，那么，我们搜索空闲块就只需要从空闲块中寻找了。其形式大致是这样的。 123456789101112131415struct block&#123; unsigned int header; union&#123; struct pointer&#123; unsigned int * next; unsigned int * prev; &#125; struct alloc&#123; char payload[N]; char extend[M]; &#125; &#125;; unsigned int footer;&#125; 由于当内存被归还的时候，负载的内容都是不需要的，因此，我们就可以利用那里的内容去组织成指针，用来记录空闲块。 而分离适配链表就是显式链表的升级版。 分离适配链表，将不同大小的块分为不同的大小类，每一个大小类都维护着一块链表。比如，大小为16-32的块是一个大小类，那么当我要申请一个18大小的内存的时候，只需要从16-32的大小类开始寻找就可以了。可以避免去2-4之类的更小的类去寻找内容，节省了查找空闲块的时间。这样需要，在一开始，就为大小类们分配一个数组，数组的内容为他们的根结点，这样，就可以很轻松的组织这个大小类链表了。 其实代码方面和隐式分配链表是差不多的，就是在查找合适的块(find_fit)的时候是用链表去查找，以及合并，归还，分配块的时候，要对这个双向链表的指针进行一次调整而已。 123456789101112131415161718Measuring performance with gettimeofday().Results for mm malloc:trace valid util ops secs Kops 0 yes 99% 5694 0.000210 27114 1 yes 99% 5848 0.000192 30427 2 yes 99% 6648 0.000240 27677 3 yes 100% 5380 0.000207 25940 4 yes 66% 14400 0.000244 58992 5 yes 93% 4800 0.000986 4866 6 yes 91% 4800 0.000960 4999 7 yes 55% 6000 0.001979 3032 8 yes 51% 7200 0.002620 2748 9 yes 43% 14401 0.000562 2563810 yes 52% 14401 0.000248 58045Total 77% 89572 0.008449 10601Perf index = 46 (util) + 40 (thru) = 86/100 恩，良好的吞吐量和内存利用率 不过当你用./mdriver -t traces/ -v -l -a去对比libc的数据的话，发现，确实差距挺明显的orz;]]></content>
      <tags>
        <tag>csapp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cpp:引用与指针]]></title>
    <url>%2Fposts%2F1987fc9d%2F</url>
    <content type="text"><![CDATA[引用和指针，到底有什么不同呢？ 区别在c++当中，引用是别名，已经初始化就无法更改，而指针则是指向某一区域的内存的地址，是可以修改的。 而在函数当中，形参的传递分为值传递，引用传递和指针传递。其中，指针传递和引用传递都是可以避免复制数值的时候产生的不必要的复制花销。也拥有可以直接改变传入的参数的值的效果。那么，他们之间到底有没有什么区别呢？ 引用传递与指针传递首先，为了测试，我们先写了如下的代码。12345678910111213141516171819202122232425int global = 100;int &amp;refGlobal = global;int *ptrGlobal = &amp;global;void funcRef(int&amp; ref)&#123; ref++;&#125;void funcPtr(int *ptr)&#123; (*ptr)++;&#125;int main()&#123; int a = 1; funcRef(a); funcRef(global); funcRef(refGlobal); funcPtr(&amp;a); funcPtr(&amp;global); return 0;&#125; 然后，再看看其中翻译过后的汇编代码。 123456789101112131415161718192021222324252627//funcRef0000000000001135 &lt;_Z7funcRefRi&gt;: 1135: 55 push %rbp 1136: 48 89 e5 mov %rsp,%rbp 1139: 48 89 7d f8 mov %rdi,-0x8(%rbp) 113d: 48 8b 45 f8 mov -0x8(%rbp),%rax 1141: 8b 00 mov (%rax),%eax 1143: 8d 50 01 lea 0x1(%rax),%edx 1146: 48 8b 45 f8 mov -0x8(%rbp),%rax 114a: 89 10 mov %edx,(%rax) 114c: 90 nop 114d: 5d pop %rbp 114e: c3 retq //funcPtr000000000000114f &lt;_Z7funcPtrPi&gt;: 114f: 55 push %rbp 1150: 48 89 e5 mov %rsp,%rbp 1153: 48 89 7d f8 mov %rdi,-0x8(%rbp) 1157: 48 8b 45 f8 mov -0x8(%rbp),%rax 115b: 8b 00 mov (%rax),%eax 115d: 8d 50 01 lea 0x1(%rax),%edx 1160: 48 8b 45 f8 mov -0x8(%rbp),%rax 1164: 89 10 mov %edx,(%rax) 1166: 90 nop 1167: 5d pop %rbp 1168: c3 retq 不难看出，他们的操作是一样的，从%rdi中取出函数传递的值，然后，保存在自己的栈帧中，一顿操作后，再放回（%rax)所记录的内存当中(也就是值原本所在的内存位置) 那么，指针和引用的存储形式是一样的吗？ 指针与引用在汇编中的形式1234567891011121314151617181920212223242526272829303132330000000000001169 &lt;main&gt;: 1169: 55 push %rbp 116a: 48 89 e5 mov %rsp,%rbp 116d: 48 83 ec 10 sub $0x10,%rsp 1171: 64 48 8b 04 25 28 00 mov %fs:0x28,%rax 1178: 00 00 117a: 48 89 45 f8 mov %rax,-0x8(%rbp) 117e: 31 c0 xor %eax,%eax 1180: c7 45 f4 01 00 00 00 movl $0x1,-0xc(%rbp) 1187: 48 8d 45 f4 lea -0xc(%rbp),%rax 118b: 48 89 c7 mov %rax,%rdi 118e: e8 a2 ff ff ff callq 1135 &lt;_Z7funcRefRi&gt; 1193: 48 8d 3d 76 2e 00 00 lea 0x2e76(%rip),%rdi # 4010 &lt;global&gt; 0x2e76 + 0x119a = 0x4010 119a: e8 96 ff ff ff callq 1135 &lt;_Z7funcRefRi&gt; 119f: 48 8d 05 6a 2e 00 00 lea 0x2e6a(%rip),%rax # 4010 &lt;global&gt; 0x2e61 + 0x11a9 = 0x4010 11a6: 48 89 c7 mov %rax,%rdi 11a9: e8 87 ff ff ff callq 1135 &lt;_Z7funcRefRi&gt; 11ae: 48 8d 45 f4 lea -0xc(%rbp),%rax 11b2: 48 89 c7 mov %rax,%rdi 11b5: e8 95 ff ff ff callq 114f &lt;_Z7funcPtrPi&gt; 11ba: 48 8d 3d 4f 2e 00 00 lea 0x2e4f(%rip),%rdi # 4010 &lt;global&gt; 0x2e4f + 0x11c1 = 0x4010 11c1: e8 89 ff ff ff callq 114f &lt;_Z7funcPtrPi&gt; 11c6: b8 00 00 00 00 mov $0x0,%eax 11cb: 48 8b 55 f8 mov -0x8(%rbp),%rdx 11cf: 64 48 33 14 25 28 00 xor %fs:0x28,%rdx 11d6: 00 00 11d8: 74 05 je 11df &lt;main+0x76&gt; 11da: e8 51 fe ff ff callq 1030 &lt;__stack_chk_fail@plt&gt; 11df: c9 leaveq 11e0: c3 retq 11e1: 66 2e 0f 1f 84 00 00 nopw %cs:0x0(%rax,%rax,1) 11e8: 00 00 00 11eb: 0f 1f 44 00 00 nopl 0x0(%rax,%rax,1) 这是main刚刚的代码的main函数。可以看出，无论是不是局部变量，还是全局变量，指针和引用的本质都是使用了相对应的内存地址而已。可以说，本质来说，引用和指针都是一个指针而已。 所以，引用和指针的区别确实只是体现在是否可以改变这一点上而已(或许还有指针用-&gt;，引用只需要.?) 其实，我们可以打开elf文件当中的符号表看看他们之间的关系1234567846: 0000000000004018 8 OBJECT GLOBAL DEFAULT 24 ptrGlobal // [24]=&gt; .data47: 0000000000003dc0 8 OBJECT GLOBAL DEFAULT 21 refGlobal // [21]=&gt; .data.rel.ro48: 0000000000001135 26 FUNC GLOBAL DEFAULT 14 _Z7funcRefRi49: 0000000000000000 0 NOTYPE WEAK DEFAULT UND _ITM_deregisterTMCloneTab50: 0000000000004000 0 NOTYPE WEAK DEFAULT 24 data_start51: 0000000000004020 0 NOTYPE GLOBAL DEFAULT 24 _edata52: 0000000000001254 0 FUNC GLOBAL HIDDEN 15 _fini53: 0000000000004010 4 OBJECT GLOBAL DEFAULT 24 global // [24]=&gt; .data 其实不难看出，指针和原本的global都是存在.data条目当中的，也就是存在在内存当中的。而引用refGlobal却只是在只读可重定位条目当中，本身是不占有任何内存空间的。 因此，他们之间的区别虽然在汇编代码当中没有比较明确的体现出来，但是，在内存的占用上却是比较确切的体现了出来。 因此，当我们修改一下代码123456789101112131415161718192021222324252627int global = 100;int &amp;refGlobal = global;int *ptrGlobal = &amp;global;void funcRef(int&amp; ref)&#123; ref++;&#125;void funcPtr(int *ptr)&#123; (*ptr)++;&#125;int main()&#123; int a = 1; funcRef(a); funcRef(global); funcRef(refGlobal); //增加了这个，全局变量的指针 funcPtr(ptrGlobal); funcPtr(&amp;a); funcPtr(&amp;global); return 0;&#125; 不难推测，传递到%rax当中的绝对是全局变量prtGlobal的值。1234567891011121314151617181920212223242526272829303132330000000000001169 &lt;main&gt;: 1169: 55 push %rbp 116a: 48 89 e5 mov %rsp,%rbp 116d: 48 83 ec 10 sub $0x10,%rsp 1171: 64 48 8b 04 25 28 00 mov %fs:0x28,%rax 1178: 00 00 117a: 48 89 45 f8 mov %rax,-0x8(%rbp) 117e: 31 c0 xor %eax,%eax 1180: c7 45 f4 01 00 00 00 movl $0x1,-0xc(%rbp) 1187: 48 8d 45 f4 lea -0xc(%rbp),%rax 118b: 48 89 c7 mov %rax,%rdi 118e: e8 a2 ff ff ff callq 1135 &lt;_Z7funcRefRi&gt; 1193: 48 8d 3d 76 2e 00 00 lea 0x2e76(%rip),%rdi # 4010 &lt;global&gt; 119a: e8 96 ff ff ff callq 1135 &lt;_Z7funcRefRi&gt; 119f: 48 8d 05 6a 2e 00 00 lea 0x2e6a(%rip),%rax # 4010 &lt;global&gt; 11a6: 48 89 c7 mov %rax,%rdi 11a9: e8 87 ff ff ff callq 1135 &lt;_Z7funcRefRi&gt; 11ae: 48 8b 05 63 2e 00 00 mov 0x2e63(%rip),%rax # 4018 &lt;ptrGlobal&gt; 0x2e63 + 0x11b5 = 0x4018 11b5: 48 89 c7 mov %rax,%rdi 11b8: e8 92 ff ff ff callq 114f &lt;_Z7funcPtrPi&gt; 11bd: 48 8d 45 f4 lea -0xc(%rbp),%rax 11c1: 48 89 c7 mov %rax,%rdi 11c4: e8 86 ff ff ff callq 114f &lt;_Z7funcPtrPi&gt; 11c9: 48 8d 3d 40 2e 00 00 lea 0x2e40(%rip),%rdi # 4010 &lt;global&gt; 11d0: e8 7a ff ff ff callq 114f &lt;_Z7funcPtrPi&gt; 11d5: b8 00 00 00 00 mov $0x0,%eax 11da: 48 8b 55 f8 mov -0x8(%rbp),%rdx 11de: 64 48 33 14 25 28 00 xor %fs:0x28,%rdx 11e5: 00 00 11e7: 74 05 je 11ee &lt;main+0x85&gt; 11e9: e8 42 fe ff ff callq 1030 &lt;__stack_chk_fail@plt&gt; 11ee: c9 leaveq 11ef: c3 retq 事实确实如此。 因此，也可以看出，只有引用和指针在全局变量（或者静态变量）的时候会出现不同，因为，这些都是可以出现在符号表当中的内容。]]></content>
      <tags>
        <tag>cpp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[csapp:shlab]]></title>
    <url>%2Fposts%2Fcf79a2fc%2F</url>
    <content type="text"><![CDATA[shalab是csapp第八章，异常控制流的实验。 csapp:lab 关于SHLAB在这里，最重要的是实现这个shell的思路。 和书上说的一样，首先shell需要拥有两个功能，一个是内置的命令，另一个则是需要启动其他的程序。 内置的命令需要在shell自己的进程当中实现，而启动其他程序则是需要使用fork去产生新的子进程，然后，再使用exevc去替代子进程的内容，从而成功的执行其他程序。 而运行的其他程序的时候，最多只允许一个进程是运行在前台的，其他进程都只能够在后台运行。 于是，我们可以大致的得出这个shell的流程。 有了这个大概的思路，那么，最开始的eval就可以实现了。 剩下的就可以，也可以一边分析，一边进行实现了。 eval(char *cmdline)按照shell的思路，那么，大致的操作也就出来了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657void eval(char *cmdline) &#123; //step1: 解析字符串 pid_t pid; char* argv[MAXLINE]; char buf[MAXLINE]; strcpy(buf,cmdline); int bg = parseline(buf,argv); if(argv[0] == NULL) return; //step2: 根据是否为内置命令进行不同的操作 if(!builtin_cmd(argv)) &#123; sigset_t mask_all,mask_one,mask_prev; sigfillset(&amp;mask_all); sigemptyset(&amp;mask_one); sigaddset(&amp;mask_one,SIGCHLD); sigprocmask(SIG_BLOCK,&amp;mask_one,&amp;mask_prev); if((pid = fork()) == 0) &#123; sigprocmask(SIG_SETMASK,&amp;mask_prev,NULL); setpgid(0,0); if(execve(argv[0],argv,environ) &lt; 0) &#123; unix_error(argv[0]); _exit(1); &#125; &#125; sigprocmask(SIG_BLOCK,&amp;mask_all,NULL); addjob(jobs,pid,bg ? BG : FG,buf); sigprocmask(SIG_SETMASK,&amp;mask_prev,NULL); sigprocmask(SIG_BLOCK,&amp;mask_one,&amp;mask_prev); if(!bg) &#123; waitfg(pid); &#125; else &#123; printf("[%d] (%d) %s",pid2jid(pid),pid,cmdline); &#125; sigprocmask(SIG_SETMASK,&amp;mask_prev,NULL); &#125; return;&#125; 这里还有一点比较在重要的，因为jobs是全局变量，而且，还是会在子进程进行修改的局变量，因此，在修改，访问jobs的时候，一定要先将信号锁上，免得出现一些奇怪的问题。 还有一点就是，在fork新进程，在execve之前，需要对子进程进行分组，确保一个进程一个组。因为这样可以使得父进程接受到的信号不影响到子进程。 builtin_cmd(char **argv)按照步骤，第二步就是对内置命令进行处理了。 内置命令一共有4个，分别是quit,bg &lt; jobs &gt;,fg &lt; jobs &gt;,jobs,这个时候就要按照功能分别对其进行处理了。 首先是quit，这个是退出，没得说，直接exit(0)就可以了。子进程回收什么的在父进程终结之后，会由init进程处理的。 然后是bg和fg，这个因为在lab也是给了需要实现的函数，因此，在实现的时候再详解。 最后是jobs，这个直接调用listjobs就可以了。1234567891011121314151617181920212223242526int builtin_cmd(char **argv) &#123; if(strcmp(argv[0],"quit") == 0) exit(0); if(strcmp(argv[0],"jobs") == 0) &#123; sigset_t mask_all,prev; sigfillset(&amp;mask_all); sigprocmask(SIG_BLOCK,&amp;mask_all,&amp;prev); listjobs(jobs); sigprocmask(SIG_SETMASK,&amp;prev,NULL); return 1; &#125; if(strcmp(argv[0],"bg") == 0 || strcmp(argv[0],"fg") == 0) &#123; do_bgfg(argv); return 1; &#125; return 0; /* not a builtin command */&#125; do_bgfg(char **argv)同样，按照要求解析字符串，命令只有两个，数量不对的都丢弃。(报错提示就按照tshref里面的照抄就可以了) 然后，根据是否有%符号去判断得到的是job的组号还是pid，然后，根据pid/jid去jobs当中寻找目标job。 若找到的话，根据bg/fg的命令去将进程重启(发送SIGCONT信号)，bg就直接后台启动，fg就阻塞父进程从而达到前台运行的效果。 若没找到，按照tshref里的内容输出错误提示就可以了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869void do_bgfg(char **argv) &#123; if(argv[2] != NULL) return; pid_t pid; struct job_t *job; char *command = argv[1]; if(command == NULL) &#123; if(strcmp(argv[0],"bg") == 0) &#123; printf("bg: argument must be a PID or %%jobid\n"); &#125; else &#123; printf("fg: argument must be a PID or %%jobid\n"); &#125; return; &#125; sigset_t mask_all,mask_prev; sigfillset(&amp;mask_all); sigprocmask(SIG_BLOCK,&amp;mask_all,&amp;mask_prev); if(command[0] == '%') &#123; int jid = atoi(&amp;command[1]); job = getjobjid(jobs,jid); if(job == NULL) &#123; sigprocmask(SIG_SETMASK,&amp;mask_prev,NULL); printf("%%%d: No such job\n",jid); return; &#125; pid = job-&gt;pid; &#125; else &#123; pid = atoi(command); job= getjobpid(jobs,pid); if(job == NULL) &#123; sigprocmask(SIG_SETMASK,&amp;mask_prev,NULL); printf("(%d): No such process\n",pid); return; &#125; &#125; if(strcmp(argv[0],"bg") == 0) &#123; kill(-pid,SIGCONT); job-&gt;state = BG; printf("[%d] (%d) %s",job-&gt;jid,job-&gt;pid,job-&gt;cmdline); &#125; else &#123; kill(-pid,SIGCONT); job-&gt;state = FG; waitfg(pid); &#125; sigprocmask(SIG_SETMASK,&amp;mask_prev,NULL); &#125; waitfg(pid_t pid)下一个就是阻塞父进程的操作了，这个和书上的一样，先设置一个原子操作的全局变量，使得能够标记前台程序是否被操作完成，操作完成之后，将被挂起的父进程恢复 12345678910111213volatile sig_atomic_t fg_proc_running = 0;void waitfg(pid_t pid)&#123; sigset_t mask; sigemptyset(&amp;mask); fg_proc_running = 1; while(fg_proc_running) sigsuspend(&amp;mask); return;&#125; sigchld_handler(int sig)之后就是那几个重要的信号处理程序了。 首先就是SIGCHLD信号的程序。 这个信号是当子进程结束或者被挂起的时候会发送的。在这里，自然也其了一个很关键的作用。 首先，就是当这个信号被触发的时候，先检查一下是什么原因被触发的。若是因为程序完成，或者是因为信号的原因而被终止的话，就应该删除其在jobs当中的记录，若是被暂停了，就要将其记录在jobs当中转换为暂停。 当然，无论是因为什么原因，若这个进程是前台进程，那么他都不应该继续是前台运行了，需要取消对父进程的阻塞，这点，将全局变量修改一下就可以做到了。 当然，在操作的时候要打印出来的信息按照tshref那样打印就可以了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253void sigchld_handler(int sig) &#123; int oldErrno = errno; int status; sigset_t mask_all,prev_all; pid_t pid; int jid; sigfillset(&amp;mask_all); while((pid = waitpid(-1,&amp;status,WNOHANG | WUNTRACED)) &gt; 0) &#123; printf("reaped child process\n"); sigprocmask(SIG_BLOCK,&amp;mask_all,&amp;prev_all); jid = pid2jid(pid); if(fgpid(jobs) == pid) fg_proc_running = 0; if(WIFEXITED(status)) &#123; deletejob(jobs,pid); if(verbose) printf("sigchld_handler:JOBS[%d] (%d) terminate (status:%d)\n",jid,pid,status); &#125; if(WIFSIGNALED(status)) &#123; deletejob(jobs,pid); printf("Job [%d] (%d) terminated by signal %d\n",jid,pid,WTERMSIG(status)); if(verbose) printf("sigchld_handler:JOBS[%d] (%d) terminate by signal:%d\n",jid,pid,WTERMSIG(status)); &#125; if(WIFSTOPPED(status)) &#123; getjobpid(jobs,pid)-&gt;state = ST; printf("Job [%d] (%d) stopped by signal %d\n",jid,pid,WSTOPSIG(status)); if(verbose) printf("sigchld_handler:JOBS[%d] (%d) stopped by signal:%d\n",jid,pid,WSTOPSIG(status)); &#125; sigprocmask(SIG_SETMASK,&amp;prev_all,NULL); &#125; errno = oldErrno;&#125; sigint_handler(int sig)当接受到INT指令的时候，需要将前台进程中断，从jobs当中找到前台进程的pid，然后，发送SIGINT给他的进程组就可以了。剩下的会在SIGCHLD当中处理 12345678910void sigint_handler(int sig) &#123; sigset_t mask_all,mask_prev; sigfillset(&amp;mask_all); sigprocmask(SIG_BLOCK,&amp;mask_all,&amp;mask_prev); int pid = fgpid(jobs); kill(-pid,SIGINT); sigprocmask(SIG_SETMASK,&amp;mask_prev,NULL);&#125; sigtstp_handler(int sig)这个和SIGINT是一个道理的1234567891011void sigtstp_handler(int sig) &#123; sigset_t mask_all,mask_prev; sigfillset(&amp;mask_all); sigprocmask(SIG_BLOCK,&amp;mask_all,&amp;mask_prev); int pid = fgpid(jobs); kill(-pid,SIGTSTP); sigprocmask(SIG_SETMASK,&amp;mask_prev,NULL); return;&#125; 总结分开实现之后，就可以很快实现了shlab的实验了。 其实这里大部分代码在书上都能找到痕迹。]]></content>
      <tags>
        <tag>csapp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[游戏中的敏感词过滤？]]></title>
    <url>%2Fposts%2Fd2f8d746%2F</url>
    <content type="text"><![CDATA[在游戏当中，我们与他人对话的时候，当我们输入一些敏感词汇的时候，那些词语就会替换成号。例如要是敏感词是“ab”，那么你要是输入“doiensabbas”，就会变成了“doiens*bas” 这看上去只是一个比较简单的字符串匹配的算法，从一个字符串当中查看是否包含某个子串，若存在，就将这个子串变成*号。自然，我们就想到了大名鼎鼎的KMP算法了。 不过，除了KMP还是有不少的处理方法的。在这里，我就利用Trie树来实现字符串的匹配。 Trie树Trie树又名字典树或者前缀树，是一种有序树。在这里，他所保存的是单词的前缀。比如下图，展现的就是一个Trie 所有的单词都按照其前缀来组合成了一棵树，这样一来可以最大限度地利用了单词的相同的地方，减少所需要的空间，另一方面，在对于单词的匹配上，也只需要对树的节点进行查找就可以得到是否匹配的效用了。 因此，我们也可以看出了Trie树的特点 ​ 1，根节点不包含任何字符 ​ 2，从根节点到某一节点，路径上经过的字符连接起来，就是该节点对应的字符串 ​ 3，每个节点的所有子节点包含的字符互不相同 建立这颗树还有一个问题，那就是，比如单词in与inn，他们拥有相同的前缀in，但是，in到这里就终结了，而inn则是需要走到树的叶子节点才能知道是否匹配。那么，我们怎么知道当我走到第一个节点’n’时，就是我们所需要的单词’in’的匹配呢？ 其实我们只需要在节点当中加入一个bool变量，用于标志这个节点是否可以对应一个单词的节点做一个标记就好了。 比如上图的e不是单词的结尾，因此，标记为黑色的点，而n可以作为单词的终结，就是上图当中所标记的蓝色的点。 时间复杂度在这里，假如敏感词的长度为m，则每一个敏感词的查询时间为O(m),若字符串长度为n，在最坏的情况则是对于n的每一个字符都要进行完整的树的遍历，因此最坏复杂度为O(nm)，而最好的情况就是每一次非敏感词都不需要查询，那么假设有k个敏感词，复杂度则是O(n + k m) 实现在这里，我选择使用hashMap来实现Trie树，因为，树的子节点树是未知的，而且，hashMap可以动态的扩展长度，而查询的时间复杂度却只有O(1)。 首先是数据结构 123456struct TrieNode : std::enable_shared_from_this&lt;TrieNode&gt;&#123; bool isAKeyEnd&#123;&#125;; char key&#123;&#125;; std::map&lt;char, std::shared_ptr&lt;TrieNode&gt;&gt; next;&#125;; 然后是其分别的生成与插入方法 1234567891011121314151617181920212223242526272829303132static TrieNode* createNode(const char key)&#123; TrieNode* tn = new TrieNode; tn-&gt;isAKeyEnd = false; tn-&gt;key = key; return tn;&#125;inline void insert(const std::string&amp; word,TrieNode* root)&#123; TrieNode* node = root; for (unsigned int i = 0; i &lt; word.size(); ++i) &#123; //若该节点已存在就向下查找，否则，就生成节点 const auto iter = node-&gt;next.find(word[i]); if (iter != node-&gt;next.end()) &#123; node = node-&gt;next[word[i]].get(); &#125; else &#123; node-&gt;next[word[i]] = std::make_shared&lt;TrieNode&gt;(*createNode(word[i])); node = node-&gt;next[word[i]].get(); &#125; if (i == word.size() - 1) &#123; node-&gt;isAKeyEnd = true; &#125; &#125;&#125; 当然，最后的就是字符串屏蔽的简单的尝试的实现 12345678910111213141516171819202122232425262728293031323334353637auto root = createNode(' ');std::string keyWord[] = &#123;"to","tea","ted","ten","in","inn"&#125;;char dirtyWord[] = "i have a tea i want go home i am fine in house love ten thousand";for (const auto&amp; i : keyWord)&#123; insert(i,root);&#125;TrieNode *temp = root;for(unsigned int i = 0;i &lt; sizeof dirtyWord;i++)&#123; const unsigned int index = i; while(temp-&gt;next.find(dirtyWord[i]) != temp-&gt;next.end()) &#123; temp = temp-&gt;next[dirtyWord[i]].get(); i++; &#125; if(temp-&gt;isAKeyEnd) &#123; for(unsigned int j = index;j &lt; i;j++) &#123; dirtyWord[j] = '*'; &#125; &#125; else &#123; i = index; &#125; temp = root;&#125;std::cout &lt;&lt; dirtyWord &lt;&lt; std::endl; { % asset_img r.png 很明显成功了 %}]]></content>
      <tags>
        <tag>algorithm</tag>
        <tag>trie</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hough变换]]></title>
    <url>%2Fposts%2Fe9f2d7e8%2F</url>
    <content type="text"><![CDATA[源码在Github 霍夫变换实际上只是能够检测图像上的形状的一种手段。他的实现方式是将图像转换为霍夫空间，然后，再从霍夫空间当中的数据来得出所需要的形状是否在图像上存在，存在多少。 实际上，霍夫变换也只是一种类似穷举法的解决方案。 霍夫直线检测基本原理直线检测，正如其名，就是检测图片当中可能存在的直线。 就如同上图所示，一条直线，只能是对应于图像当中的一个唯一的一元一次方程$y=kx+b$，那么，想要计算图片是否存在这样的直线，那么我们只需要那一组唯一的一元一次方程即可。 这就是霍夫直线变换。 那么我们可以怎么算呢？我们可以这样，对于图片上每一个目标点都计算其所有可能的k与b，那么，只要当我们计算出来所有的目标点的所有的k与b，重合度最高的一组k与b就可以看作为一条直线了。(因为，只有组成直线的两个点之间的k与b是一样的，其他k与b都是离散的) 但是这样我们们会有一个问题，k与b的取值的范围怎么设定呢？理论上，k与b的取值范围都是无限的，而计算机注定是无法计算无限的数值的，因此，我们需要一种新的方式去代替k与b，使之拥有取值范围。 这个时候，极坐标公式就是我们的一个很好的选择了。 p=xcos\theta + ysin\theta \quad \theta\in(0,\pi),p\in(0,r)其中的$r$是图片半径（也就是对角线的长度） 拥有了取值范围，那么我们就很好的计算了，比较有了取值范围，剩下的问题就只是取值的精度而已。 极坐标公式所对应的直线方程可以理解为这样 y=-\frac{cos\theta}{sin\theta}x+\frac{p}{sin\theta}那么，我们只要将$\theta$从0到$\pi$都取一遍，就可以取到以这条直线为原点，绕其360度的所有的直线了。也就是我们之前所说的取k与b的所有的取值的一种替代方式了。 那么，我们就可以得出一个检测直线的累加数组了。而数组当中最多的位置，就可以看作是一条直线了。 霍夫的直线检测的检测路线可以总结为这样： 1，对图片进行滤波，取边缘点等预处理 2，将图片二值化，以便于计算 3，建立一个2 r 180长的霍夫空间（在这里取2 * r是因为，当theta取值大于90的时候，计算出来的r为负数，因此，需要对这个结果进行一下处理） 4，对于每一个目标点 123if f(x,y) == 1 p = x * cos(theta) + y * sin(theta) + r houghSpace[r][p]++ 5,对于霍夫空间当中的点，若其大于一定的阈值，就视为一条直线，然后，我们就可以将直线画出来了(在这里我是将其mark为255) 123p = x * cos(theta) + y * sin(theta) + rif houghSpace[r][p] &gt; threshold f(x,y) = 255 代码实现这里的数据结构有很多我自己所封装的东西，但是，具体的算法流程还是很清晰的在这里展示了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091ImageUtil::IMGDATA hough(ImageUtil::ImageData data, const double deltaSigma)&#123; typedef ImageUtil::ImageSize uint; const int r = std::sqrt(data.width * data.width + data.height * data.height); const int d = 2 * r; const int sigma = 181 / deltaSigma; uint *houghSpace = new uint[d * sigma]; memset(houghSpace, 0, d * sigma * sizeof(uint)); ImageUtil::ImageData cannyImg = ImageUtil::EdgeDetection::canny(data,40,80); ImageUtil::outputBlackWhiteImage(cannyImg, "bitmap/canny.bmp"); //ImageUtil::toTwoValueImage(cannyImg); ImageUtil::progressBar.reset(data.height * data.width, "生成HoughSpace"); for (uint i = 0; i &lt; data.height; i++) &#123; for (uint j = 0; j &lt; data.width; j++) &#123; if (cannyImg[i][j] &gt; 0) &#123; double s = 0; while (true) &#123; const int p = j * std::cos(ImageUtil::toRadian(static_cast&lt;double&gt;(s))) + i * std::sin(ImageUtil::toRadian(static_cast&lt;double&gt;(s))) + r; houghSpace[p * sigma + static_cast&lt;int&gt;(s / deltaSigma)]++; s += deltaSigma; if (s &gt; 180) break; &#125; &#125; ++ImageUtil::progressBar; &#125; &#125; uint max = 0; for(int i= 0;i &lt; r * sigma ;i++) &#123; if (houghSpace[i] &gt; max) max = houghSpace[i]; &#125; ImageUtil::progressBar.reset(data.height * data.width, "检测直线...."); for(uint i = 0;i &lt; data.height;i++) &#123; for(uint j = 0;j &lt; data.width;j++) &#123; double s = 0; while(true) &#123; const int p = j * std::cos(ImageUtil::toRadian(static_cast&lt;double&gt;(s))) + i * std::sin(ImageUtil::toRadian(static_cast&lt;double&gt;(s))) + r; if (houghSpace[p * sigma + static_cast&lt;int&gt;(s / deltaSigma)] &gt; max * 0.85) &#123; data[i][j] = static_cast&lt;byte&gt;(255); &#125; s += deltaSigma; if (s &gt; 180) break; &#125; ++ImageUtil::progressBar; &#125; &#125; BYTE* houghSpaceImg = new BYTE[d * sigma]; for (int i = 0; i &lt; d*sigma; i++) &#123; houghSpaceImg[i] = ImageUtil::clamp(static_cast&lt;double&gt;(houghSpace[i]) / max * 255); &#125; ImageUtil::outputImage(houghSpaceImg, sigma, d, 256, 8, data.rgbquad, "bitmap/houghSpace.bmp"); data.rgbquad[255].rgbBlue = 0; data.rgbquad[255].rgbGreen = 0; delete[] houghSpace; delete[] cannyImg.pImg; delete[] houghSpaceImg; return data;&#125; 霍夫圆检测]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二进制减法的实现]]></title>
    <url>%2Fposts%2F37270847%2F</url>
    <content type="text"><![CDATA[在这里，我们曾经实现了一个全加器，用于计算二进制的加法。 而有加法自然就会有减法。那么，减法又是怎么操作的呢？ 首先，我们还是可以看看十进制的减法是怎么计算的。比如541-141，从左到右依次相减，这样就可以计算出来了，如同加法一样。但是，这里有个问题，那就是借位的问题。 不过实际上，借位的问题与进位的问题是一致的，我们同样可以利用减法位与借位位来构建一个新的电路结构，实现全减器的效果。 不过，一般来说，计算机使用了另一种方式去实现减法的效果，从而避免了设计一个新的电路的情况，那就是利用全加器去实现减法的效果。 那么怎么实现呢？ 比如，我们可以这样 \begin{split}&873-637=236\\=>& 999-637=362\\=>&362+1=363\\=>&363+873=1236\end{split}先使用当前位数的最大值减去被减数，这样就可以完美的避免了借位操作，然后，再将被减数与减速相加，多出来的那个位舍弃掉（也就是1236舍弃1，变成236），就可以实现相减的效果了。 是不是很奇妙，其实这个公式调整一下顺序可以变成这样 \begin{split}&873-637+999+1-1000\\=&873+(-637+999)+1-1000\end{split}而在这里，999-637=362的操作中，这个362就被称之为补码。 所谓补码就是当前位的最大值减去当前位，比如2的补码就是7，对637求补码的操作实际上也就是每一位都是拿9去减去当前位就可以了。 而这样的操作在二进制中更是再简单不过了对吧？二进制当中的每一位都只有0与1，那么求补码也就是对当前位取反嘛（1的补码是0，0的补码是1，很简单就能算出来对吧:smile），因此，我们在这里，只要对输入的数每一位都使用反相器不就可以对其取反了。 而加一操作就更简单了。我们还记得全加器有一个进位位吧，只要在个位的进位位置为1，那么自然而然就会达到加一的效果啦。 总之，使用这种操作就可以完美的实现了不用重新构造一个全新的电路就完成减法操作的目的了。]]></content>
      <tags>
        <tag>CODE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二进制加法器]]></title>
    <url>%2Fposts%2F8075ab0a%2F</url>
    <content type="text"><![CDATA[加法计算是算术运算当中最基本的运算，我们如果想要构建一台计算机,那么首先就要构建出可以计算两个数的和的器件。当你真正面对他的时候，就会发现，原来加法运算是计算机要做的唯一的工作 ——《Code:The Hidden Language of Computer Hardware and Software》 计算二进制的加法，看上去很难。可是，实际上却是与十进制的加法如出一辙。 比如，在十进制当中，我们要计算124+531，那么，我们首先计算4+1，然后以此类推，因此，所有的十进制的加法，我们都可以依靠9-9加法表当中的值去计算。 那么二进制也是同样的道理 \begin{split}0+0&=0\\1+0&=1\\0+1&=1\\1+1&=10\end{split}我们可以将这个结果写成类似9-9加法表的形式 + 0 1 0 00 01 1 01 10 像这样的一对二进制数的加法数，他们的结果有两个数位，一个是加法位(sum bit)，一个叫进位位(carry bit)，比如1+1，他们的加法位就是0，进位就是1 我们可以将加法位与进位分别独立出来写成两个个新的表 表示加法位的表 +加法 0 1 0 0 1 1 1 0 表示进位位的表 +进位 0 1 0 0 0 1 0 1 用这种方式实现二进制加法就很简单了。因为这样，我们的加法器当中的加法位与进位位的计算是分别进行的，而得到这两者的答案就可以继续进行下一步的运算了。 比如计算111+110，从右到左计算，加法位即使当前位的答案，而进位位则表示下一位的计算是否需要进位，然后再利用同样的方式继续计算下去，就可以得出我们的最终答案了。 当然，从我们的脑子里自然可以实现无限位的运算，而计算机不行，我们实现的方式也只能够利用有限的位数去实现。在这里我们可以先实现8位的。 其实，8位还是有点多，首先我们先实现一位相加的加法器。也就是两个输入（两个加数）对应两个输出（加法位与进位位）。 其实从加法位的表和进位位的表当中，就可以发现进位是符合AND门电路的规则的，而加法表则是符合XOR门电路的规则的。因此，我们也就可以组建出一个加法器的电路实现 输入A，B两个数（其实就是0，或者1，或者说高电平或者低电平？毕竟只是1位的运算），根据XOR或者AND的电路分别输出了加法位和进位位的结果。假设我们再S与C上各连接一个电灯泡，我们就可以利用电灯泡是否点亮来确定我们的1位二进制加法的结果了。 为了避免重复画与门与异或门，我们可以使用这种简单的表达方式。 这种加法器我们称之为半加器。 之所以叫半加器是有原因的，因为，他将两个二进制数相加，得出一个加法位和进位位，但是，绝大多数的二进制数都是大于一位的。半加器没有做到将前一次的加法可能产生的进位位纳入下一次的加法当中去。 比如我们要使用两个二进制数相加111+111=1110，那么我们再计算完第一位1+1之后，第二个1+1实际上还要纳入一个进位，也就是实际上是1+1+1，是三个二进制数的相加。 而后面的每一列都需要将前一列的进位位纳入进来。因此，我们需要将半加器组合起来。 或者简单的画成这样 他的工作原理很简单，首先先将这个位的两个数相加，然后得出的加法位的结果再与进位输入相加。那么最终的结果就是加法位的结果。而当输入的两个数相加或者是两者之和和进位数相加之后，若得出了进位的结果，进位位就会输出1。 就比如之前的111+111的算式，当计算到第二列的时候，1+1=10，进位位输出1，加法位位0，然后，加法位再与上一次的进位结果相加0+1=01，进位位输出0，加法位输出1，那么我们也就正确的得到了第二列的加法位与进位位的计算结果了。 我们将这种加法器称之为全加器。 当我们将这些全加器连接起来，每一个输出都连接一个灯泡，$A_n,B_n$为二进制数的输入，$C_0$输入为0（因为第一位的运算不需要进位位）时，我们就构建了一个加法器了（这里是4位的），而当$C_4$输出位1的时候，则说明溢出了（超过能计算的最大值了） 这就是二进制的加法器。 而当你能够搭建4位的加法器的时候，8位，16位。。。对于你来说都是十分简单的。毕竟，我们只需要按照同样的方式去将他们连接在一起就可以了。 这种二进制的加法器被称之为行波进位(ripple carry)，每一个位的运算都是依赖于上一位的结果，加法器的总体速度等于数字的位数乘以全加器的器件速度。 更快的加法器运用了一个叫做“前置进位”的电路来提高运算速度。 在我们实现这个全加器的时候，我们使用的所有的逻辑门电路的实现原件都是再很多年前就已经出现了，甚至比计算机的出现时间还要早200年。 因此，16位的加法器甚至可以使用继电器来实现！]]></content>
      <tags>
        <tag>CODE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unity 多选框的实现]]></title>
    <url>%2Fposts%2F13ed8ac0%2F</url>
    <content type="text"><![CDATA[思路框选难点在与如何知道在世界坐标系的可选择物体与用在屏幕上框选的方框的的位置的对比. 因此,可以选择将所有可选择物体的世界坐标转化为屏幕上的坐标,然后,再与屏幕上的方框的位置进行对比,既可以得出在方框内的所有物体了. 实现首先,实现这个功能需要有三个步骤 步骤一:确定多选框的位置确定多选框的位置实现比较简单,就是利用鼠标点下的时候记录矩形的开始坐标,在鼠标抬起的时候记录矩形的结束坐标 在Update()当中可以轻松实现 \12345678910111213141516171819202122232425262728293031323334// Update is called once per frame void Update() &#123; ​ if (Input.GetMouseButtonDown(0)) ​ &#123; ​ mIsDrawRectangle = true; //开始绘制多选框 ​ mStartPos = Input.mousePosition; ​ &#125; ​ else if (Input.GetMouseButtonUp(0)) ​ &#123; ​ mIsDrawRectangle = false; //结束绘制多选框 ​ mEndPos = Input.mousePosition; ​ //检查被选中的物体 ​ CheckSelection(mStartPos, mEndPos); ​ &#125; &#125;\ 步骤二:框选框的实现在Unity当中,在屏幕上的绘图可以利用OpenGL的函数来实现. 在OnPostRender()函数当中也可以很轻松的实现框框的绘制(由于只是对屏幕的绘制,因此比放在Update()当中更加适合) \123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104private void OnPostRender() &#123; ​ if (mIsDrawRectangle) ​ &#123; ​ //实时获取需要绘制的矩形的大小 ​ mEndPos = Input.mousePosition; ​ GL.PushMatrix(); //将矩阵入栈 ​ //矩形框的颜色的材质 ​ if (rectMat == null) ​ &#123; ​ return; ​ &#125; ​ rectMat.SetPass(0); ​ GL.LoadPixelMatrix(); ​ //绘制一个半透明的矩形 ​ DrawRect(); ​ //绘制矩形的边 ​ DrawLine(); ​ //完成绘制,将矩阵出栈 ​ GL.PopMatrix(); ​ &#125; &#125; private void DrawLine() &#123; //绘制线条的模式 ​ GL.Begin(GL.LINES); ​ GL.Color(mRectColor); //将每一个点都输入进去,然后进行线条的绘制 ​ GL.Vertex3(mStartPos.x, mStartPos.y, 0); ​ GL.Vertex3(mEndPos.x, mStartPos.y, 0); ​ GL.Vertex3(mEndPos.x, mStartPos.y, 0); ​ GL.Vertex3(mEndPos.x, mEndPos.y, 0); ​ GL.Vertex3(mEndPos.x, mEndPos.y, 0); ​ GL.Vertex3(mStartPos.x, mEndPos.y, 0); ​ GL.Vertex3(mStartPos.x, mEndPos.y, 0); ​ GL.Vertex3(mStartPos.x, mStartPos.y, 0); ​ GL.End(); &#125; private void DrawRect() &#123; //绘制区域的模式 ​ GL.Begin(GL.QUADS); ​ GL.Color( ​ new Color(rectMat.color.r, rectMat.color.g, rectMat.color.b, 0.1f)); //绘制的时候要按照一定的路线进行绘制 ​ GL.Vertex3(mStartPos.x, mStartPos.y, 0); ​ GL.Vertex3(mEndPos.x, mStartPos.y, 0); ​ GL.Vertex3(mEndPos.x, mEndPos.y, 0); ​ GL.Vertex3(mStartPos.x, mEndPos.y, 0); ​ GL.End(); &#125; \ 步骤三:将可选择的物体与多选框进行位置上的对比将可选择物体的屏幕坐标与框框的大小进行对比即可 \12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394private void CheckSelection(Vector3 startPos, Vector3 endPos) &#123; ​ //p1为矩形x,y值的最小值 ​ //p2为矩形x,y值的最大值 ​ Vector3 p1 = Vector3.zero; ​ Vector3 p2 = Vector3.zero; ​ if (startPos.x &gt; endPos.x) ​ &#123; ​ p1.x = endPos.x; ​ p2.x = startPos.x; ​ &#125; ​ else ​ &#123; ​ p1.x = startPos.x; ​ p2.x = endPos.x; ​ &#125; ​ if (startPos.y &gt; endPos.y) ​ &#123; ​ p1.y = endPos.y; ​ p2.y = startPos.y; ​ &#125; ​ else ​ &#123; ​ p1.y = startPos.y; ​ p2.y = endPos.y; ​ &#125; ​ //寻找被选中的目标与没有被选中的目标 ​ foreach (var obj in characterList) ​ &#123; ​ //物体的位置 ​ Vector3 location = Camera.main.WorldToScreenPoint(obj.transform.position); //在方框内且没有被遮挡才可以被选中 ​ if (location.x &lt; p1.x || location.x &gt; p2.x || location.y &lt; p1.y || location.y &gt; p2.y || location.z &lt; Camera.main.nearClipPlane || location.z &gt; Camera.main.farClipPlane) ​ &#123; ​ //没选中 ​ obj.GetComponent&lt;MeshRenderer&gt;().material.color = Color.blue; ​ &#125; ​ else ​ &#123; ​ //选中 ​ obj.GetComponent&lt;MeshRenderer&gt;().material.color = Color.red; ​ &#125; ​ &#125; &#125; \ 从此就可以实现多选的效果了]]></content>
      <tags>
        <tag>Unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Exercise7--边缘检测]]></title>
    <url>%2Fposts%2F49b27d17%2F</url>
    <content type="text"><![CDATA[源码在Github 通常来说，边缘所在的位置，都是与其四周的像素颜色区别较大的地点的。 因此，边缘检测是基于灰度突变来分割图像的常用方法。 Prewittprewitt算子是一种比较简单的，基于一阶微分算子的边缘检测。 其原理即是，利用像素点的上下，左右邻点之间的灰度值之差，从而计算出他们的一阶导数，当导数达到极值点，即为边缘。 G_y =\begin{bmatrix}1&1&1\\0&0&0\\-1&-1&-1\end{bmatrix}\\G_x =\begin{bmatrix}1&0&-1\\1&0&-1\\1&0&-1\end{bmatrix}最终计算出来的值可以是 G=G_x+G_y也可以是 G=max(G_x,G_y)在我们计算出他们之间的一阶导数值之后，只需要指定一个阈值，既可以简单的分割出一个图片的边缘了。 f(i,j)=\begin{cases}G(i,j)>T&1\\G(i,j)\leq T&0\end{cases}这种方法的有点在于简单。而缺点也很明显，那就是对于噪点的抵挡能力比较弱，很容易就会被噪点所干扰，因为许多噪点的灰度值也是比较大的。 代码的简单实现123456789101112131415161718192021222324ImageUtil::IMGDATA prewitt(ImageUtil::IMGDATA data, const int threadhold)&#123; BYTE *img = new BYTE[data.width * data.height]; memset(img, 0, data.width * data.height); for (int i = 1; i &lt; data.height - 1; i++) &#123; for (int j = 1; j &lt; data.width - 1; j++) &#123; const int dx = data.pImg[(i + 1)*data.width + j - 1] + data.pImg[(i + 1)*data.width + j] + data.pImg[(i + 1)*data.width + j + 1] - (data.pImg[(i - 1)*data.width + j - 1] + data.pImg[(i - 1)*data.width + j] + data.pImg[(i - 1)*data.width + j + 1]); const int dy = data.pImg[(i - 1) *data.width + j + 1] + data.pImg[i*data.width + j + 1] + data.pImg[(i - 1)*data.width + j + 1] - (data.pImg[(i + 1) *data.width + j - 1] + data.pImg[i*data.width + j - 1] + data.pImg[(i - 1)*data.width + j - 1]); if (std::_Max_value(dx, dy) &gt; threadhold) &#123; img[i * data.width + j] = 1; &#125; &#125; &#125; data.pImg = img; return data;&#125; Sobel那么有没有比Prewitt更好的算子吗？ 那当然有，那就是Sobel算子。 这个算子同样是基于一阶偏导实现的，与Prewitt不同的是，Sobel对中间区域的像素加上了权值，从而降低了边缘模糊程度，从而达到了更好的效果 G_x=\begin{bmatrix}1&0&-1\\2&0&-2\\1&0&-1\end{bmatrix} \\G_y=\begin{bmatrix}1&2&1\\0&0&0\\-1&-2&-1\end{bmatrix}而最终的梯度大小为 G=\sqrt{G_x^2+G_y^2}同样是，根据阈值来确定边缘与非边缘 F(i,j)=\begin{cases}G(i,j)>T&1\\G(i,j)\leq T&0\end{cases}简单的实现1234567891011121314151617181920212223ImageUtil::IMGDATA sobel(ImageUtil::IMGDATA data, const int threadhold)&#123; BYTE *img = new BYTE[data.width * data.height]; memset(img, 0, data.width * data.height); for (int i = 1; i &lt; data.height - 1; i++) &#123; for (int j = 1; j &lt; data.width - 1; j++) &#123; const int gx = data[i - 1][j - 1] * -1 + data[i][j - 1] * -2 + data[i + 1][j - 1] * -1 + data[i - 1][j + 1] * 1 + data[i][j + 1] * 2 + data[i + 1][j + 1] * 1; const int gy = data[i + 1][j - 1] * -1 + data[i + 1][j] * -2 + data[i + 1][j + 1] * -1 + data[i - 1][j - 1] * 1 + data[i - 1][j] * 2 + data[i - 1][j + 1] * 1; const double g = std::sqrt(gx*gx + gy * gy); if (g &gt; threadhold) img[i*data.width + j] = 1; &#125; &#125; data.pImg = img; return data;&#125; LoG不过，Sobel算子虽然对于图像的噪声有所采取防范措施，但是，总的来说，他还是没有对图像进行滤波的操作。 因此，我们这里采用的方法则是更加高级的方法。 因此，LoG就应运诞生了。 LoG算法是指的是高斯拉普拉斯。简单来说就是，先对图像进行高斯滤波，从而计算出平滑的图像，然后再对图像进行拉普拉斯边缘检测，就可以得出一个比较好的图像了。 这个算法一个比较难的难点就是对图像取二阶高斯滤波。 G(x,y)=e^{-\frac{x^2+y^2}{2\sigma^2}}而结合拉普拉斯算子则是 \nabla^2G(x,y)=[\frac{x^2+y^2-2\sigma^2}{\sigma^4}]^{e^{-\frac{x^2+y^2}{2\sigma^2}}}只要我们根据输入的σ，以及卷积模板的大小，那么就可以计算出LoG算子的模板了。比较常用的近似的是这个 G = \begin{bmatrix}0&0&-1&0&0\\0&-1&-2&-1&0\\-1&-2&16&-2&-1\\0&-1&-2&-1&0\\0&0&-1&0&0\\\end{bmatrix}当然，常用的是这个的负模板。 LoG算法的详细步骤可以为 1，对图像取一个$n*n$的高斯低通滤波器对输入图像进行滤波 2，根据第一步取得的图像进行拉普拉斯算子卷积运算 3，根据得出的结果，使用阈值去取得边缘 实现这里没有直接使用模板去计算 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899//NxN高斯卷积模板double** getGaussianKernel(const int size,const double sqrSigma)&#123; double** gaus = new double*[size]; for (int i = 0; i &lt; size; i++) &#123; gaus[i] = new double[size]; &#125; const double pi = 4.0 * std::atan(1.0); const int center = size / 2; double sum = 0; for (int i = 0; i &lt; size; i++) &#123; for (int j = 0; j &lt; size; j++) &#123; gaus[i][j] = (1 / (2 * pi*sqrSigma))*exp(-((1 - center)*(1 - center) + (j - center)*(j - center)) / (2 * sqrSigma)); sum += gaus[i][j]; &#125; &#125; for (int i = 0; i &lt; size; i++) &#123; for (int j = 0; j &lt; size; j++) &#123; gaus[i][j] /= sum; &#125; &#125; return gaus;&#125;//LoGImageUtil::IMGDATA LOG(ImageUtil::IMGDATA data,double sqrSigma, const int threadhold)&#123; BYTE *img = new BYTE[data.width * data.height]; memset(img, 0, data.width * data.height); double** gaus = getGaussianKernel(5, sqrSigma); for (int i = 2; i &lt; data.height - 2; i++) &#123; for (int j = 2; j &lt; data.width - 2; j++) &#123; int sum = 0; for (int x = -2; x &lt;= 2; x++) &#123; for (int y = -2; y &lt;= 2; y++) &#123; sum += data[i + x][j + y] * gaus[4 - (x + 2)][y + 2]; &#125; &#125; img[i * data.width + j] = sum; &#125; &#125; for (int i = 0; i &lt; data.height; i++) &#123; for (int j = 0; j &lt; data.width; j++) &#123; int up, down, left, right; if (i == 0) up = 0; else up = i - 1; if (i == data.height - 1) down = data.height - 1; else down = i + 1; if (j == 0) left = 0; else left = j - 1; if (j == data.width - 1) right = data.width - 1; else right = j + 1; img[i * data.width + j] = ImageUtil::clamp( 1 * data.pImg[up * data.width + left] + 1 * data.pImg[up * data.width + j] + 1 * data.pImg[up * data.width + right] + 1 * data.pImg[i * data.width + left] + -8 * data.pImg[i * data.width + j] + 1 * data.pImg[i * data.width + right] + 1 * data.pImg[down * data.width + left] + 1 * data.pImg[down * data.width + j] + 1 * data.pImg[down * data.width + right]); &#125; &#125; for(int i = 0;i &lt; data.width * data.height;i++) &#123; if (img[i] &gt; threadhold) img[i] = 1; else img[i] = 0; &#125; data.pImg = img; return data;&#125; Canny最后要介绍的，就是这个Canny检测器了。这是这四个检测器当中最优秀的一个。Canny方法有三个最基本的目标 1，低错误率。所有边缘都被找到，并且没有伪相应。 2，边缘点被很好地定位。已定位的边缘尽可能的接近真实边缘。 3，单一响应点。对于真实的边缘点，探测器只返回一个点。 Canny的本质工作就是对以上三个准则进行数学公式化并求其最优解。这通常来说是很困难的。然而，对由加性高斯白噪音污染的一阶台阶边缘使用数字最佳化很好近似高斯一阶导数的。 而把结果推广到二维也同样适用。 那么，我们开始实现Canny方法吧。 降噪第一步，自然是绕不开降噪的。使用如同LoG算子当中的高斯滤波即可实现降噪的效果了。 寻找图像当中的亮度梯度第二步，分为两个步骤，首先是求得降噪后的图像的梯度幅度。由于，我们需要知道图像的梯度方向，所以，我们必须将图像的x与y方向的梯度都求出来 \theta(i,j)=arctan[\frac{g_y}{g_x}]在这里，我是用的是sobel算子去求得图像的x方向与y方向的梯度。 第二个步骤，就是对梯度求出来的值进行抑制了。 由于，使用梯度产生的边缘，$M(x,y)$通常在局部最大值当中包含了一个更宽的范围（图像的一阶导数并非只有突变点才是突变值） 因此，我们需要对其中的非最大值进行抑制。 那么我们需要做的就是 1，寻找点$\theta(i,j)$的方向$d_k$ 2，若$M(x,y)$的值是沿$d_k$方向上的两个邻居当中的最大值，那就不进行操作。否则，置为0 这样，每一个边缘点就都只剩下最大值的那个了，也符合了Canny的目的之一，单一响应点 在图像当中追踪边缘在得出了非最大值抑制的边缘之后，我们就需要对图像进行阈值处理，来减少其中的伪边缘点了。 在之前，我们的算法都是使用单阈值点去处理这个问题。但是，这会导致一个问题，那就是，阈值过低会使得伪边缘点过多，而阈值过高却会导致有效边缘点被误删。 因此，我们这里通过使用滞后阈值来试图改变这个状况。 这里使用了两个阈值$T_L,T_H$，根据Canny的建议，这两个阈值的比应该是1：2或者1：3。 首先我们分别对图像进行阈值处理 G_H(x,y) = M(x,y)>T_H G_L(x,y) = M(x,y) > T_L在阈值处理之后，我们就得出了由两个阈值所得出的两张处理过后的图片。而此时，$G_L$是包含着我们使用较高阈值处理的图片的，因此，我们再对$G_L$进行处理 G_L(x,y)=G_L(x,y)-G_H(x,y)那么得出得就是一个是强阈值的图案，一个是弱阈值的图案。此时，我们可以以此为基础检测真正的边缘了。 1，首先将所有的$G_H$设定为有效的边缘边 2，从$G_H$当中取得一个还没有访问过的像素点p 3，从$G_L$当中与p相邻的点也被纳入到有效边缘边当中,并从这个点出发，用8联通的方式将其周围的点连接在一起,最后将这个点从$G_L$加入到$G_H$当中 4，若$G_H$遍历完成，结束遍历 那么此时标记出来的所有有效边就是真正的边缘了。 整个Canny方法可以总结为如下的操作 1，使用高斯滤波器平滑图像 2，计算图像的梯度值和角度 3，对梯度值使用非最大值抑制 4，使用双阈值处理以及连接分析来检测并连接边缘 代码的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207//只用于记录像素点的位置struct Pixel&#123; int x = 0, y = 0; BYTE pix = 0; Pixel(const int x, const int y, const BYTE p) :x(x),y(y),pix(p) &#123; &#125; Pixel() = default;&#125;;//canny算法ImageUtil::IMGDATA canny(ImageUtil::IMGDATA data, const int minVal,const int maxVal)&#123; //步骤一，高斯滤波 double** gaus = getGaussianKernel(5,0.01); for (int i = 2; i &lt; data.height - 2; i++) &#123; for (int j = 2; j &lt; data.width - 2; j++) &#123; int sum = 0; for (int x = -2; x &lt;= 2; x++) &#123; for (int y = -2; y &lt;= 2; y++) &#123; sum += data[i + x][j + y] * gaus[4 - (x + 2)][y + 2]; &#125; &#125; data[i][j] = sum; &#125; &#125; //步骤二，计算梯度与角度 BYTE *sobelImg = new BYTE[data.width * data.height]; int *gxArr = new int[data.width * data.height]; int *gyArr = new int[data.width * data.height]; memset(sobelImg, 0, data.width * data.height); memset(gxArr, 0, data.width * data.height); memset(gyArr, 0, data.width * data.height); for (int i = 1; i &lt; data.height - 1; i++) &#123; for (int j = 1; j &lt; data.width - 1; j++) &#123; const int gx = data[i - 1][j - 1] * -1 + data[i][j - 1] * -2 + data[i + 1][j - 1] * -1 + data[i - 1][j + 1] * 1 + data[i][j + 1] * 2 + data[i + 1][j + 1] * 1; const int gy = data[i + 1][j - 1] * -1 + data[i + 1][j] * -2 + data[i + 1][j + 1] * -1 + data[i - 1][j - 1] * 1 + data[i - 1][j] * 2 + data[i - 1][j + 1] * 1; gxArr[i*data.width + j] = gx; gyArr[i*data.width + j] = gy; const double g = std::sqrt(gx*gx + gy * gy); sobelImg[i*data.width + j] = g; &#125; &#125; //步骤三：非最大值抑制(从计算出来的梯度方向的法线方向才是边缘宽的方向) BYTE *temp = new BYTE[data.width * data.height]; for(int i = 0;i &lt; data.width * data.height;i++) &#123; temp[i] = sobelImg[i]; &#125; for (int i = 1; i &lt; data.height - 1; i++) &#123; for (int j = 1; j &lt; data.width - 1; j++) &#123; double dir; if (gxArr[i*data.width + j] == 0) dir = 90; else dir = (std::atan(gyArr[i*data.width + j] / gxArr[i*data.width + j])) * 180 / ImageUtil::pi; //水平 if ((dir &gt;= 157.5 || dir &lt;= -157.5) || (dir &lt;= 22.5 &amp;&amp; dir &gt;= -22.5)) &#123; if (sobelImg[i * data.width + j] &lt; sobelImg[i * data.width + j + 1] || sobelImg[i * data.width + j] &lt; sobelImg[i * data.width + j - 1]) &#123; temp[i * data.width + j] = 0; &#125; &#125; //-45度 else if ((dir &lt;= -112.5 &amp;&amp; dir &gt;= -157.5) || (dir &lt;= 67.5 &amp;&amp; dir &gt;= 22.5)) &#123; if (sobelImg[i * data.width + j] &lt; sobelImg[(i + 1) * data.width + j - 1] || sobelImg[i * data.width + j] &lt; sobelImg[(i - 1) * data.width + j + 1]) &#123; temp[i * data.width + j] = 0; &#125; &#125; //垂直 else if ((dir &gt;= -112.5 &amp;&amp; dir &lt;= -67.5) || (dir &lt;= 112.5 &amp;&amp; dir &gt;= 67.5)) &#123; if (sobelImg[i * data.width + j] &lt; sobelImg[(i + 1) * data.width + j] || sobelImg[i * data.width + j] &lt; sobelImg[(i - 1) * data.width + j]) &#123; temp[i * data.width + j] = 0; &#125; &#125; //+45度 else if ((dir &gt;= -67.5 &amp;&amp; dir &lt;= -22.5) || (dir &lt;= 157.5 &amp;&amp; dir &gt;= 112.5)) &#123; if (sobelImg[i * data.width + j] &lt; sobelImg[(i + 1) * data.width + j + 1] || sobelImg[i * data.width + j] &lt; sobelImg[(i - 1) * data.width + j - 1]) &#123; temp[i * data.width + j] = 0; &#125; &#125; &#125; &#125; for (int i = 0; i &lt; data.width * data.height; i++) &#123; sobelImg[i] = temp[i]; &#125; delete[] temp; delete[] gxArr; delete[] gyArr; std::queue&lt;Pixel&gt; highPixQue; BYTE *lowPix = new BYTE[data.width * data.height]; //步骤四，双阈值处理 for (int i = 0; i &lt; data.height; i++) &#123; for (int j = 0; j &lt; data.width; j++) &#123; if (sobelImg[i * data.width + j] &gt; maxVal) &#123; const Pixel p(j, i, 1); highPixQue.push(p); &#125; if (sobelImg[i * data.width + j] &gt; minVal &amp;&amp; sobelImg[i * data.width + j] &lt;= maxVal) &#123; lowPix[i * data.width + j] = 1; &#125; else &#123; lowPix[i * data.width + j] = 0; &#125; &#125; &#125; //步骤五，分析并联通边缘 memset(sobelImg, 0, data.width*data.height); while (!highPixQue.empty()) &#123; const Pixel p = highPixQue.front(); highPixQue.pop(); sobelImg[p.y * data.width + p.x] = 1; for(int i = -1;i &lt;= 1;i++) &#123; for(int j = -1;j &lt;= 1;j++) &#123; if(p.y + i &lt; 0 || p.y + i &gt;= data.height || p.x + j &lt; 0 || p.x + j &gt;= data.width) continue; if (i == 0 &amp;&amp; j == 0) continue; if(lowPix[(p.y + i) * data.width + p.x + j] == 1) &#123; //8联通合并 for (int x = -1; x &lt;= 1; x++) &#123; for (int y = -1; y &lt;= 1; y++) &#123; if (p.y + i + y &lt; 0 || p.y + i + y &gt;= data.height || p.x + j + x &lt; 0 || p.x + j + x &gt;= data.width) continue; if (lowPix[(p.y + i + y) * data.width + p.x + j + x] == 1) &#123; highPixQue.push(Pixel(p.x + j, p.y + i, 1)); &#125; &#125; &#125; lowPix[(p.y + i) * data.width + p.x + j] = 0; &#125; &#125; &#125; &#125; delete[] lowPix; data.pImg = sobelImg; for (int i = 0; i &lt; 5; i++) delete[] gaus[i]; delete[] gaus; return data;&#125;]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Exercise6--基于区域的分割]]></title>
    <url>%2Fposts%2Ff25a7903%2F</url>
    <content type="text"><![CDATA[源码 之前的阈值分割是通过像素的特性分布为基础的阈值处理来完成的。而现在我们就来实现基于区域的分割。 区域增长区域增长是指，根据预先定义的生长准则，将符合规则的像素组合为大区域的过程。 基本方法就是取一组“种子”点开始，从种子点四周开始检索，将符合生长准则的点都纳入种子点当中，直到种子四周都没有符合条件的像素点为止。 比如，生长准则为 T=1那么，只要种子点四周的点与种子点的像素值相差在1以内，即纳入种子点之中。 那么计算方法就很简单了。 1，提取出图像$S(x,y)$的连通分量（即边界），然后，将所有属于边界的地方标记为1。 2，对输入的图像$f(x,y)$，根据输入的种子点的位置，进行8-联通种子点搜索，若符合条件$Q$，则纳入种子点当中，并标记。 3，根据标记出的值进行图像的输出。 在这里，我实现的例子 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485int main()&#123; std::string path; std::cin &gt;&gt; path; auto data = ImageUtil::loadImageToGray(path); auto seed = ImageUtil::loadImageToGray("bitmap/6.bmp"); BYTE *unRegion = new BYTE[data.width * data.height]; int *growQueX = new int[data.width * data.height]; int *growQueY = new int[data.width * data.height]; for (int i = 0; i &lt; data.width * data.height; i++) unRegion[i] = 0; regionGrowWithSeed(seed, unRegion, growQueX, growQueY, 3, 0, 0, 1); regionGrowWithSeed(seed, unRegion, growQueX, growQueY, 2, seed.width / 2, seed.height / 2, 2); regionGrowWithSeed(seed, unRegion, growQueX, growQueY, 10, 328, 283 - 45, 3); ImageUtil::IMGDATA newImg = seed; newImg.rgbquad[1].rgbBlue = 255; newImg.rgbquad[1].rgbGreen = 0; newImg.rgbquad[1].rgbRed = 0; newImg.rgbquad[2].rgbBlue = 0; newImg.rgbquad[2].rgbGreen = 255; newImg.rgbquad[2].rgbRed = 0; newImg.rgbquad[3].rgbBlue = 0; newImg.rgbquad[3].rgbGreen = 0; newImg.rgbquad[3].rgbRed = 255; data.fileHeader.bfOffBits = sizeof(BITMAPINFOHEADER) + sizeof(BITMAPFILEHEADER) + sizeof(RGBQUAD) * 4; data.fileHeader.bfSize = sizeof(BITMAPINFOHEADER) + sizeof(BITMAPFILEHEADER) + sizeof(RGBQUAD) * 4 + data.infoHeader.biSizeImage; data.infoHeader.biClrUsed = 4; newImg.pImg = unRegion; ImageUtil::outputImage(newImg, "bitmap/region_grow_with_seed.bmp"); return 0;&#125;//采取8-联通的方式的广度优先搜索void regionGrowWithSeed(const ImageUtil::IMGDATA&amp; data,BYTE * unRegion,int *growQueX,int *growQueY, int threshold, int seedX, int seedY,int color)&#123; int nDx[8] = &#123; 0, 0,1,-1, 1,1,-1,-1 &#125;; int nDy[8] = &#123; 1,-1,0, 0,-1,1, 1,-1 &#125;; int start = 0, end = 0; growQueX[end] = seedX; growQueY[end] = seedY; while(start &lt;= end) &#123; const int currX = growQueX[start]; const int currY = growQueY[start]; for (int k = 0; k &lt; 8; k++) &#123; const int xx = currX + nDx[k]; const int yy = currY + nDy[k]; if(xx &lt; data.width &amp;&amp; xx &gt;= 0 &amp;&amp; yy &lt; data.height &amp;&amp; yy &gt;= 0 &amp;&amp; unRegion[yy * data.width + xx] == 0 &amp;&amp; std::abs(data.pImg[yy * data.width + xx] - data.pImg[currY * data.width + currX]) &lt; threshold) &#123; end++; growQueX[end] = xx; growQueY[end] = yy; unRegion[yy * data.width + xx] = color; &#125; &#125; start++; &#125;&#125; 区域分裂与聚合这种方法则是，不利用种子值，而是直接分裂一幅图像，然后再对合适的区域进行聚合得到合适的区域。 1，对图片进行分裂，分裂为左上，左下，右上，右下的四等分的区域 2，对图片的区域进行判断，求其平均灰度值，若灰度值不符合规则，则对该区域继续分裂（回到步骤一），否则，标记为true 3，对分裂完成的图片进行聚合，遍历分裂区域 4，若两个分裂区域是相邻的，则合并之 这样，就可以完成对一个图片的分裂了。 代码实现这里的实现方式与上面的区域增长其实是差不多的。只是多出了一个对分裂出来的区域进行标记的数据结构而已。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113struct Region&#123; int wBeginIndex = 0, wEndIndex = 0, hBeginIndex = 0, hEndIndex = 0; bool Q = false;&#125;;ImageUtil::IMGDATA reginGrowWithoutSeed(ImageUtil::IMGDATA data,int threadhold)&#123; Region origin; origin.wBeginIndex = 0; origin.wEndIndex = data.width; origin.hBeginIndex = 0; origin.hEndIndex = data.height; std::vector&lt;Region&gt; qTList; std::queue&lt;Region&gt; queRegion; Region * rList = new Region[4]; queRegion.push(origin); int start = 0, end = 0; while(start &lt;= end) &#123; const Region curRegion = queRegion.front(); queRegion.pop(); //if (!curRegion.Q) Region * rQList = splitRegion(curRegion, rList); for(int i =0;i &lt; 4;i++) &#123; if(rQList != nullptr) &#123; if (getAver(data, rList[i]) &gt; threadhold) &#123; queRegion.push(rList[i]); end++; &#125; else qTList.push_back(rList[i]); &#125; &#125; start++; &#125; delete[] rList; BYTE *byte = new BYTE[data.width * data.height]; memset(byte, 0, data.width * data.height); for(auto&amp; r : qTList) &#123; for (int i = r.hBeginIndex; i &lt; r.hEndIndex; i++) &#123; for (int j = r.wBeginIndex; j &lt; r.wEndIndex; j++) &#123; byte[i * data.width + j] = 1; &#125; &#125; &#125; data.pImg = byte; return data;&#125;//分裂区域Region* splitRegion(const Region&amp; r,Region *alloc)&#123; if (r.wEndIndex - r.wBeginIndex &lt;= 1 || r.hEndIndex - r.hBeginIndex &lt;= 1) return nullptr; alloc[0].wBeginIndex = r.wBeginIndex; alloc[0].wEndIndex = r.wBeginIndex + (r.wEndIndex - r.wBeginIndex) / 2; alloc[0].hBeginIndex = r.hBeginIndex; alloc[0].hEndIndex = r.hBeginIndex + (r.hEndIndex - r.hBeginIndex) / 2; alloc[1].wBeginIndex = r.wBeginIndex + (r.wEndIndex - r.wBeginIndex) / 2; alloc[1].wEndIndex = r.wEndIndex; alloc[1].hBeginIndex = r.hBeginIndex; alloc[1].hEndIndex = r.hBeginIndex + (r.hEndIndex - r.hBeginIndex) / 2; alloc[2].wBeginIndex = r.wBeginIndex; alloc[2].wEndIndex = r.wBeginIndex + (r.wEndIndex - r.wBeginIndex) / 2; alloc[2].hBeginIndex = r.hBeginIndex + (r.hEndIndex - r.hBeginIndex) / 2; alloc[2].hEndIndex = r.hEndIndex; alloc[3].wBeginIndex = r.wBeginIndex + (r.wEndIndex - r.wBeginIndex) / 2; alloc[3].wEndIndex = r.wEndIndex; alloc[3].hBeginIndex = r.hBeginIndex + (r.hEndIndex - r.hBeginIndex) / 2; alloc[3].hEndIndex = r.hEndIndex; return alloc;&#125;//计算区域的平均灰度值double getAver(const ImageUtil::IMGDATA&amp; data, const Region&amp; r)&#123; int count = 0, result = 0; for(int i = r.hBeginIndex;i &lt; r.hEndIndex;i++) &#123; for(int j = r.wBeginIndex;j&lt;r.wEndIndex;j++) &#123; result += data[i][j]; count++; &#125; &#125; return static_cast&lt;double&gt;(result) / count;&#125;]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Exercise5--阈值分割]]></title>
    <url>%2Fposts%2F6fb12389%2F</url>
    <content type="text"><![CDATA[由于阈值处理直观，实现简单且计算速度快，因此阈值处理再图像分割应用处于核心地位 假设一个图像的灰度直方图对应于图像的$f(x,y)$,而该图像由暗色背景上的较亮物体组成，那么，就可以设置一个全局阈值T，然后对于每一个$f(x,y)&gt;T$的点称之为对象点，其余的称之为背景点，从而达到了分割图像的目的。 g(x,y)=\begin{cases}1,&f(x,y)>T\\0,&f(x,y)\leq T\end{cases}基本的全局阈值处理当物体的背景像素的灰度分布十分明显时，可以用适用于整个图像的单个（全局）阈值。通常图像之间有较大的变化，使用手动设置的全局阈值是一种方法，当然也有着对图像进行自动阈值估算的算法 迭代法1，为全局阈值$T_{0}$选择一个初始估计值(一般为中位数) 2，使用 T_{0}把图像分割成两个部分 R_{1}和R_{2},并计算其平均灰度 m_{1}和$m_{2}$ m_{1} = \frac{\sum_{i=0}^{T_{0}}i*n_{i}}{\sum_{i=0}^{T_{0}}n_{i}},m_{2} = \frac{\sum_{i=T_{0}}^{L-1}i*n_{i}}{\sum_{i=T_{0}}^{L-1}n_{i}}3,计算新阈值 T_{0}=\frac{m_{1}+m_{2}}{2}4,重复步骤2到4，直到$T_{0} &lt;\Delta T$ 这样就可以计算出一个比较合适的阈值$T_{0}$ 实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061void thresholdByIterate(const ImageUtil::ImageData&amp; data)&#123; ImageUtil::GrayHistogram histogram = ImageUtil::getHistogram(data); histogram.normalize(); //开始阈值设置为中位数，因此需要计算 std::vector&lt;int&gt; his(data.width * data.height); for (int i = 0; i &lt; data.width * data.height; i++) &#123; his[i] = data.pImg[i]; &#125; std::sort(his.begin(), his.end()); double t0 = 0,t1 = his[his.size() / 2]; //不断计算阈值左右的平均灰度，从而达到左右比较平衡的目的 while (std::abs(t0 - t1) &gt; 10) &#123; double a0 = 0,n0 = 0, a1 = 0,n1 = 0; for (int i = 0; i &lt; t1; i++) &#123; a0 += histogram.gray[i] * i; &#125; for (int i = 0; i &lt; t1; i++) &#123; n0 += histogram.gray[i]; &#125; for (int i = t1; i &lt; 255; i++) &#123; a1 += histogram.gray[i] * i; &#125; for (int i = t1; i &lt; 255; i++) &#123; n1 += histogram.gray[i]; &#125; t0 = t1; t1 = (a0 / n0 + a1 / n1) * 0.5; &#125; //根据阈值重新设置图像 ImageUtil::ImageData img = data; BYTE *imgData = new BYTE[data.width * data.height]; for (int i = 0; i &lt; data.width * data.height; i++) &#123; imgData[i] = data.pImg[i] &gt; t1 ? 1 : 0; &#125; //输出黑白图 std::string name("bitmap/threshold_by_iterate"); name.append("_") .append(std::to_string(t1)) .append(".bmp"); img.pImg = imgData; ImageUtil::outputBlackWhiteImage(img, name); delete[] imgData;&#125; Otsu法阈值处理可以视为一种统计决策理论问题。其目的在于把像素分为两个或多个组，使得分组的时候引入的平均误差最小。 而Otsu法则是一种很好的方案，他的思想在于，使得分组之间的类间方差最大化，这么，也就是相当于每一个类里面的方差是最小的，从而达成了一个比较好的分割的目的。 Otsu方法还有一个特性，就是他可以完全在一个图片上的直方图进行运算。 由于Otsu方法的思想在于取得最大的类间方差，那么，我们需要做的就是计算出每一个类里的平均灰度值m，以及他们之间的方差即可。 证明以下证明来自于冈萨雷斯的《数字图像处理（第三版）》 首先，我们选择一个阈值T(k)=k,(0]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Use const whenever possible]]></title>
    <url>%2Fposts%2F80c2e52%2F</url>
    <content type="text"><![CDATA[Effective CPP Chapter 1 Use Const Whenever Possible ​ ——- effective cpp 最近在Effective Cpp一书当中看到了一些关于const的用法，深有体会。 Const基本操作首先还是介绍一下一些关于const的基本操作 1234const char *p = greeting //non-const pointer,const datachar* const p = greeting //const pointer,non-const dataconst char* const p = greeting //both 简单来说就是在星号左边的const表示修饰指针所指的为常量，而星号右边的const修饰的就是指针本身 除此之外还有些有基本的关于const的STL操作，比如 12const std::vector&lt;int&gt;::iterator iter // like T* conststd::vector&lt;int&gt;::const_iterator iter // like const T* 不过，让我比较深刻的还是将const应用在函数身上的操作 Const Member Functionoperator * …首先就是例如这样的 12class Rational&#123;...&#125;;const Rational operator *(const Rational&amp; r,const Rational&amp; l); 使用const可以有效的避免了一些诸如 1234Rational a,b,c;(a + b) = c;if(a + b = c)&#123;...&#125; 之类的看上去就很蠢的错误。因此当你这样写的时候，编译器是会报错的，那样你就可以很快的发现问题所在，而若那个乘法的返回值没有const的话，那么，他将会默认调用了operator =的操作（假如有的话），而这个时候，编译器是不会报错的，那么这些很蠢的问题可能要在很久之后才能发现。 operator[] …现在我有一个类TextBlock 12345678910111213141516171819202122class TextBlock&#123; std::string text;public: explicit TextBlock(const char* t) &#123; text = std::string(t); &#125; const char&amp;operator[](size_t p) const &#123; return text[p]; &#125; char &amp;operator[](size_t p) &#123; return text[p]; &#125;&#125;;...... TextBlock tb("hello");const TextBlock ctb("hi");cout &lt;&lt; tb[0];cout &lt;&lt; ctb[0]; 在这里，带有const的ctb调用的是带有const的operator[],而没带const的tb调用的则是没有const的operator[],因此，tb[0]是可以赋值的而ctb[0]是不可以的。 在这里，effective cpp讨论了一些关于const的问题，即是，bitwise constness与logical constness bitwise constness位常量性，指的是对形如const char&amp; operator[](size_t p) const这些常量函数的描述。 在c++当中，当函数被声明了常量之后，那么这个函数意味着不会对成员变量进行修改，而这些不修改在c++编译器当中即是代表着，一个位都不会有变化，从编译器的角度来说，这是一件很容易确定的事，因此他只需要注意在函数内对成员变量没有任何一个位的修改就可以了。 而c++里面对常量的定义确实就是位常量。 但是，这并不代表成员变量一定是无法被修改的。例如 12345678910111213141516171819202122class C_TextBlock&#123; char* pText;public: explicit C_TextBlock(const char* t) &#123; pText = new char[10]; strcpy(pText, t); &#125; char&amp;operator[](size_t p) const &#123; return pText[p]; &#125;&#125;;........ const C_TextBlock cctb("Hello");char *pc = &amp;cctb[0];*pc = 'J'; 这样，cctb[0]里面的字母就被替代成了J了。 因此，这里虽然声明了const变量但是调用的函数仅仅是const 成员函数，返回值并不是const的，因此，这里的变量仍然可以被修改。 logical constness逻辑常量性，我们可以认为，我们是可以修改成员变量的，但是，对于客户端来说，无法察觉到这些变化，因此，从逻辑上来说，这是常量。 在effective cpp当中举了一个例子 12345678910111213141516171819202122232425262728class C_TextBlock&#123; char* pText; size_t textLength; bool lengthValid;public: explicit C_TextBlock(const char* t) &#123; pText = new char[10]; strcpy(pText, t); &#125; size_t length() const &#123; if(!lengthValid) &#123; textLength = strlen(pText); lengthValid = true; &#125; return textLength; &#125; char&amp;operator[](size_t p) const &#123; return pText[p]; &#125;&#125;; 但是length()修改了成员函数，也就是违背了位常量性，那么这个代码将不会被编译了，那应该怎么解决呢？在c++当中有一个很简单的解决方案。那就是关键字mutable，这个关键字让一个非静态的变量免于位常量性的约束 12size_t textLength; -&gt; mutable size_t textLength;bool lengthValid; -&gt; mutable bool lengthValid; avoding duplication in const and non-const最后一点则是对const与non-const之间的函数的封装。 由于为了保持变量的常量的属性，那么在一些地方自然就要写上const与non-const的版本，但是这些版本的代码都是相似的。要是使用大量的复制的方法，那么也就有点蠢蠢的感觉（当代码重复变多的时候），这个时候我们是可以使用复用方法的。 1234567891011121314151617181920class C_TextBlock&#123; char* pText;public: const char&amp;operator[](size_t p) const &#123; //假如里面要加入边界检测之类的乱七八糟的东西 //那么这里将会多很多内容 ....... return text[p]; &#125; char&amp;operator[](size_t p) const &#123; //这里也会多很多相似的内容 ....... return pText[p]; &#125;&#125;; 当然我们可以用封装的方法，将相似的内容封装出来，然后，分别调用方法，但是，这也是需要复制一行的，那么有没有不需要复制的方法呢？当然有啦。 123456789101112131415class TextBlock&#123; std::string text;public: explicit TextBlock(const char* t) &#123; text = std::string(t); &#125; const char&amp;operator[](size_t p) const &#123; return text[p]; &#125; char &amp;operator[](size_t p) &#123; return const_cast&lt;char &amp;&gt;( static_cast&lt;const TextBlock&amp;&gt;(*this)[p]); &#125;&#125;; 总所周知，想要调用带有const返回参数的方法就需要const的变量，那么我们可以将*this转化为const的，而从non-const转换为const是一种安全的转换，我们完全不用担心问题，而得到的结果自然是调用了const char&amp; operator[](size_t p) const，因此我们需要使用const_cast&lt;char&amp;&gt;去消除const，这样，我们复用的目的就达成了。 当然，像是例子这样的函数不去使用这种方法也是没有关系的，毕竟都是很简单的，但是知道这种方法还是很重要的。 当然，知晓这种方法的好处自然不单纯是在于写const与non-const版本的时候减少代码的复制量。 这里的核心思想在于，const变量承诺了成员变量的不变性，而non-const则是不会有这种承诺的。那么，如果我们想要从non-const方法中获取const变量，则需要自己承担不改变对象的风险，这也是为什么直接调用non-const方法赋值到const变量会出现错误的原因。因此我们只能使用const_cast去为其赋予const属性。 而相反的操作却是安全的，因此non-const方法并没有对变量进行约束，因此我们从const方法中获取的东西是没有任何问题的。 这也是operator[]方法当中为什么可以使用static_cast与const_cast方法进行转换从而达成复用的原因。（毕竟是安全的转换） Thing to Remember]]></content>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Exercise4.5--图像处理当中的数学(矩阵运算的封装)]]></title>
    <url>%2Fposts%2Fb1deaac3%2F</url>
    <content type="text"><![CDATA[前言图像处理当中涉及了各种各样的数学。而其中在之前，我做的Exercise4当中，就运用了大量的线性代数的知识，于是，在这里我就简单的封装一下矩阵运算的操作。 矩阵运算矩阵运算的规则比较简单，大概就是这样 \begin{bmatrix}a_{00}&a_{01}\end{bmatrix} * \begin{bmatrix}b_{00}\\b_{10}\end{bmatrix}=\begin{bmatrix}a_{00}*b_{00}+a_{01}b_{10}\end{bmatrix}当然这里说的比较简单，更具体的可以参考维基百科 开始封装首先一个矩阵也就是一个行列式，可以看作是若干个行组成的。因此，可以将一个Matrix里面包含若干的Vector的形式去组成一个矩阵 在这里我的所有的封装都是在namespace ImageUtil之下的 Vector行自然要用数组来存啦，因此，我们可以利用泛型来进行一个比较灵活的封装 123456789101112131415161718192021222324252627282930313233template&lt;typename T,int Col = 3&gt; struct Vector &#123; T column[Col]; Vector() = default; T&amp; operator[](int index) &#123; assert(index &gt;= 0 &amp;&amp; index &lt; Col); return column[index]; &#125; Vector&lt;T,Col&gt;&amp; operator*(Vector&lt;T,Col&gt; v) &#123; for(int i = 0;i &lt; Col;i++) &#123; column[i] *= v[i]; &#125; return *this; &#125; void logThis() &#123; for (T e : column) &#123; std::cout &lt;&lt; e &lt;&lt; " "; &#125; std::cout &lt;&lt; std::endl; &#125; &#125;; Matrix封装完Vector自然就是将他们组成矩阵了。用同样的方法就可以了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748template&lt;typename T,int Col,int Row&gt; struct Matrix &#123; Vector&lt;T, Row&gt; row[Col]; Matrix() = default; explicit Matrix(std::initializer_list&lt;T&gt; args) &#123; reset(args); &#125; void reset(std::initializer_list&lt;T&gt; args) &#123; const int length = args.size(); int index = -1; for (int i = 0; i &lt; Col; i++) &#123; for (int j = 0; j &lt; Row; j++) &#123; if (index &lt; length - 1) ++index; row[i][j] = *(args.begin() + index); &#125; &#125; &#125; Vector&lt;T,Row&gt;&amp; operator[](int index) &#123; assert(index &lt; Col &amp;&amp; index &gt;= 0); return row[index]; &#125; void logThis() &#123; for (Vector&lt;T,Col&gt;&amp; e : row) &#123; e.logThis(); &#125; std::cout &lt;&lt; std::endl; &#125; &#125;; operator*最后，就是矩阵的关键操作，矩阵相乘了。由于矩阵相乘左边的列数应该等于右边的行数，因此，我们也要进行约束，当然，用泛型来约束就可以了。 1234567891011121314151617template&lt;int _Row&gt;Matrix&lt;T,Col,_Row&gt; operator*(Matrix&lt;T,Row,_Row&gt;&amp; o)&#123; Matrix&lt;T, Col, _Row&gt; result; for (int i = 0; i &lt; Col; i++) &#123; for (int j = 0; j &lt; _Row; j++) &#123; result[i][j] = 0; for (int r = 0; r &lt; Row; r++) &#123; result[i][j] += row[i][r] * o[r][j]; &#125; &#125; &#125; return result;&#125; typedef最后，将几个常用的类型提取出来方便使用就完事 123456typedef Matrix&lt;int, 3, 3&gt; Matrix3x3i;typedef Matrix&lt;double, 3, 3&gt;Matrix3x3d;typedef Matrix&lt;int, 3, 1&gt; Matrix3x1i;typedef Matrix&lt;double, 3, 1&gt; Matrix3x1d; 于是乎，一个简单的封装就完成了。]]></content>
      <tags>
        <tag>图像处理</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Exercise4--图像变换]]></title>
    <url>%2Fposts%2F41300e37%2F</url>
    <content type="text"><![CDATA[写在前面图像变换，指的就是对一张图片进行各种各样的位置变化的处理。通常来说，想要对一个图片进行各式各样的变化，其本质其实就是对图像的像素点进行坐标的变化(缩放就是对图片点的坐标的扩大与减少，平移就是移动其坐标点等等) 因此，在这里很多变化的本质工作就是进行坐标处理。 说到坐标处理，最方便的方法那就是应用变化矩阵了。 所谓的变化矩阵，实际上就是对图片坐标[x,y]进行升阶，引入第三个元素，从而使用3x3的变化矩阵去进行坐标的运算。比如下面这个平移的运算 \begin{bmatrix}1&0&\Delta x\\0&1&\Delta y\\0&0&1\end{bmatrix}*\begin{bmatrix}x_0\\y_0\\1\end{bmatrix}=\begin{bmatrix}x_0+\Delta x\\y_0+\Delta y\\1\end{bmatrix}\\(x_0,y_0均为变换前的坐标)这样，很方便就可以计算出新的坐标了 同样我们还有旋转的矩阵(当然还有原公式) \begin{cases}x=rcos(\alpha-\theta)=rcos\alpha cos\theta+rsin\alpha cos\theta=x_0cos\theta+y_0sin\theta\\y=rsin(\alpha-\theta)=rsin\alpha cos\theta-rcos\alpha sin\theta=-x_0sin\theta+y_0cos\theta\end{cases}\\\begin{bmatrix}cos\theta&sin\theta&0\\-sin\theta&cos\theta&0\\0&0&1\end{bmatrix}*\begin{bmatrix}x_0\\y_0\\1\end{bmatrix} \\(x_0,y_0均为变换前的坐标)以及缩放矩阵 \begin{bmatrix}f_x&0&0\\0&f_y&0\\0&0&1\end{bmatrix}*\begin{bmatrix}x_0\\y_0\\1\end{bmatrix}\\(x_0,y_0均为变换前的坐标)当然，如果只是实现单个功能，其实是不需要使用矩阵也是可以实现的。但是，一旦要进行多重变换的时候，矩阵就会方便很多了。因为，若多次变换，只需要将这些矩阵依次连乘起来，然后使用结果对图像的坐标进行变化就可以得出答案了。 而要是使用非矩阵的实现方式，则是要每一步都要进行一次复杂的运算才可以得出答案 下面，就是我实现的图像变化方式(包含矩阵与非矩阵的两种方式）。 里面所使用的所有矩阵操作都在矩阵运算的封装这里 缩放缩放指的是对图片的大小进行按照一定比例的变化。 这种缩放使用之前所说的缩放矩阵就可以了 12345ImageUtil::Matrix3x3d mat(&#123; 1/xScale, 0, 0, 0, 1/yScale,0, 0, 0, 1 &#125;); 至于为什么要使用逆矩阵呢，那是因为我是以变化后的图像坐标为参数，因此需要使用逆矩阵来计算出原来所对应的x，y值 图片的影响但是这种变化直接影响了图片的宽和高，因此，当实现缩放操作的时候，新图像的像素点未必能够找到原图像的点的映射 举个例子，就是当一个10x10的图片扩大到15x15的时候，那么15x15的图片当中在$(1,1)$时候的点在10x10的图片上是找不到对应的映射的(15x15图像当中的$(1,1)$的点对应10x10图像当中的$(0.67,0.67)$的点) 因此，在对图像进行缩放时，填充颜色就需要进行插值来对没有映射的点进行填充 而在各种各样的插值处理当中，双线性插值处理算是其中运用的较广的。 双线性插值 所谓的双线性插值，简单来说就是，当这个点找不到任何能够在原图有直接映射的坐标时，取离其最近的4个点，然后分别按照一定的权重去为这个点的颜色赋值就如图片当中的点p，他的颜色就取决于点a，b，c，d的取值了。 至于如何去取这个权重，那只需要根据点p与点a，b，c，d的距离去取值就可以了。 当然，这个方法实际上是取ab与cd两个颜色的变化函数，然后计算出与点p横坐标相同的点（假设为点e，f）的颜色，最后，根据点e，f计算出其颜色变化的函数，最终就可以求出点p的颜色了。 由于这三条方程都是线性变化的，因此着也就是双线性插值了(取了ab与cd两条函数来求值) 实现方式也很简单 12345678910111213141516171819202122232425262728const double originX = result[0][0]; /*static_cast&lt;double&gt;(j) / xScale;*/ const double originY = result[1][0]; /*static_cast&lt;double&gt;(i) / yScale;*/ const int originPixelX = originX; const int originPixelY = originY; const double distanceOriginPixelX = originX - originPixelX; const double distanceOriginPixelY = originY - originPixelY; int originPixelXNext = originPixelX + 1; int originPixelYNext = originPixelY + 1; if (originPixelXNext &gt;= data.width) originPixelXNext = data.width - 1; if (originPixelYNext &gt;= data.height) originPixelYNext = data.height - 1; //兼容灰度图，24位图，32位图 pixelPoint += k; for (int biCount = 0; biCount &lt; k; biCount++) &#123; newData[pixelPoint + biCount] = ImageUtil::clamp( data.pImg[originPixelY * data.width * k + originPixelX * k + biCount] * (1 - distanceOriginPixelX) * (1 - distanceOriginPixelY) + data.pImg[originPixelY * data.width * k + originPixelXNext * k + biCount] * (distanceOriginPixelX) * (1 - distanceOriginPixelY) + data.pImg[originPixelYNext * data.width * k + originPixelX * k + biCount] * (distanceOriginPixelY) * (1 - distanceOriginPixelX) + data.pImg[originPixelYNext * data.width * k + originPixelXNext * k + biCount] * distanceOriginPixelY * distanceOriginPixelX); &#125; （真正的算法在for循环里面哦） 实现这是全部的实现，大概就是分为4个步骤。 1，建立新的大小的图片 2，利用矩阵（或者不利用）计算出原始坐标与新坐标的关系，在这里面注释了的两行x，y的取值就是不使用矩阵的取值方式 3，双线性插值，为新图建立设置颜色 4，输出新图像 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172ImageUtil::IMGDATA scale(ImageUtil::IMGDATA data)&#123; float xScale, yScale; std::cout &lt;&lt; "x轴的缩放" &lt;&lt; std::endl; std::cin &gt;&gt; xScale; std::cout &lt;&lt; "y轴的缩放" &lt;&lt; std::endl; std::cin &gt;&gt; yScale; const int k = data.infoHeader.biBitCount / 8; IMGDATA newImg = data; newImg.width = xScale * data.width; newImg.height = yScale * data.height; newImg.infoHeader.biWidth = newImg.width; newImg.infoHeader.biHeight = newImg.height; const int byteWidth = (newImg.width * k + 3) / 4 * 4; newImg.infoHeader.biSizeImage = byteWidth * newImg.height; newImg.fileHeader.bfSize = newImg.infoHeader.biSizeImage + sizeof(BITMAPINFOHEADER) + sizeof(BITMAPFILEHEADER) + newImg.infoHeader.biClrUsed * sizeof(RGBQUAD); ImageUtil::Matrix3x3d mat(&#123; 1/xScale, 0, 0, 0, 1/yScale,0, 0, 0, 1 &#125;); ImageUtil::Matrix3x1d xyMat(&#123; 0,0,0 &#125;); //兼容灰度图，24位图，32位图 BYTE *newData = new BYTE[newImg.width * k * newImg.height]; int pixelPoint = -k; for (int i = 0; i &lt; newImg.height; i++) &#123; for (int j = 0; j &lt; newImg.width ; j++) &#123; xyMat.reset(&#123; static_cast&lt;double&gt;(j),static_cast&lt;double&gt;(i),1 &#125;); auto result = mat * xyMat; const double originX = result[0][0]; /*static_cast&lt;double&gt;(j) / xScale;*/ const double originY = result[1][0]; /*static_cast&lt;double&gt;(i) / yScale;*/ const int originPixelX = originX; const int originPixelY = originY; const double distanceOriginPixelX = originX - originPixelX; const double distanceOriginPixelY = originY - originPixelY; int originPixelXNext = originPixelX + 1; int originPixelYNext = originPixelY + 1; if (originPixelXNext &gt;= data.width) originPixelXNext = data.width - 1; if (originPixelYNext &gt;= data.height) originPixelYNext = data.height - 1; //兼容灰度图，24位图，32位图 pixelPoint += k; for (int biCount = 0; biCount &lt; k; biCount++) &#123; newData[pixelPoint + biCount] = ImageUtil::clamp( data.pImg[originPixelY * data.width * k + originPixelX * k + biCount] * (1 - distanceOriginPixelX) * (1 - distanceOriginPixelY) + data.pImg[originPixelY * data.width * k + originPixelXNext * k + biCount] * (distanceOriginPixelX) * (1 - distanceOriginPixelY) + data.pImg[originPixelYNext * data.width * k + originPixelX * k + biCount] * (distanceOriginPixelY) * (1 - distanceOriginPixelX) + data.pImg[originPixelYNext * data.width * k + originPixelXNext * k + biCount] * distanceOriginPixelY * distanceOriginPixelX); &#125; &#125; &#125; newImg.pImg = newData; return newImg;&#125; 平移平移就很简单了，因为平移操作当中，新图像与原图像的点的映射关系是一一对应的，因此，计算也就很简单了。 在这里同样可以使用矩阵（或者逆矩阵）的方式，使用矩阵或者逆矩阵的方式取决于你的x，y点的取值是从旧图片计算新图片的映射还是相反的情况。 实现同样，x与y所注释的部分就是不使用矩阵的计算方式。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849IMGDATA translate(IMGDATA data)&#123; int xTrans, yTrans; std::cout &lt;&lt; "x轴的位移" &lt;&lt; std::endl; std::cin &gt;&gt; xTrans; std::cout &lt;&lt; "y轴的位移" &lt;&lt; std::endl; std::cin &gt;&gt; yTrans; int k = data.infoHeader.biBitCount / 8; ImageUtil::Matrix3x3i mat(&#123; 1,0,-xTrans, 0,1,-yTrans, 0,0,1 &#125;); ImageUtil::Matrix3x1i xyMat(&#123; 0,0,0 &#125;); BYTE *newData = new BYTE[data.width * data.height * k]; for (int i = 0; i &lt; data.width * data.height * k; i++) &#123; newData[i] = 0; &#125; int point = -k; for(int i = 0;i &lt; data.height;i++) &#123; for(int j = 0;j &lt; data.width;j++) &#123; xyMat.reset(&#123; j,i,1 &#125;); auto result = mat * xyMat; int x = result[0][0]; /*j + xTrans;*/ int y = result[1][0]; /*i + yTrans;*/ point += k; //越界的点丢弃掉 if (x &lt; 0 || x &gt;= data.width || y &lt; 0 || y &gt;= data.height) continue; for(int biCount = 0;biCount &lt; k;biCount++) &#123; newData[point + biCount] = data.pImg[y * data.width * k + x * k + biCount]; &#125; &#125; &#125; IMGDATA img = data; img.pImg = newData; return img;&#125; 镜像镜像操作就是对像素进行对称的取值，在矩阵当中为 \begin{bmatrix}x\\y\\1\end{bmatrix}=\begin{bmatrix}-1&0&w(0)\\0&1&0(h)\\0&0&1\end{bmatrix}*\begin{bmatrix}x_0\\y_0\\1\end{bmatrix}其中$x_0,y_0$为原图的坐标$x,y$为新图的坐标，$w,h$分别为宽和高，这个就取决于你想要以那边为重心点进行对称了，这里我选择的是左右镜像，因此，我就是用了w而没有使用h 实现1234567891011121314151617181920212223242526272829303132IMGDATA mirror(IMGDATA data)&#123; ImageUtil::Matrix3x3i mat(&#123; -1, 0, data.width, 0, 1, 0, 0, 0, 1 &#125;); const int k = data.infoHeader.biBitCount / 8; BYTE *newData = new BYTE[data.length]; int point = -k; for (int i = 0; i &lt; data.height; i++) &#123; for (int j = 0; j &lt; data.width; j++) &#123; ImageUtil::Matrix3x1i xyMat(&#123; j,i,1 &#125;); ImageUtil::Matrix3x1i result = mat * xyMat; point += k; for(int b = 0;b &lt; k;b++) &#123; //这个部分为不使用矩阵的计算的部分 //newData[point + b] = data.pImg[i * data.width * k + (data.width * k - 1 - j - (k - 1 - b))]; newData[point + b] = data.pImg[result[1][0] * data.width * k + result[0][0] * k + b]; &#125; &#125; &#125; IMGDATA newImg = data; newImg.pImg = newData; return newImg;&#125; 旋转旋转同样是套用公式，在一开始我的旋转矩阵当中就给出两种计算方式的公式了，第一种为非矩阵的，第二种为矩阵的，简单的套用公式就可以计算出来了。 而公式的推导其实就是设了两个不同的点，而他们的角度分别为$\alpha \theta$然后，我们就可以利用三角函数将两者的坐标关系计算出来了，从而得到了上面的结果 当中，在这里，由于使用了三角函数，因此，计算出来的坐标的映射未必能够完美的映射到新图当中，所以，若想要对新图有比较高的要求，需要对新图的像素点进行插值 实现在这里同样，x，y的取值的地方所注释掉的内容为不使用矩阵的内容。 在这里，我实现的旋转是绕中点的旋转。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657IMGDATA rotate(IMGDATA data)&#123; int rotateAngle; std::cout &lt;&lt; "旋转的角度" &lt;&lt; std::endl; std::cin &gt;&gt; rotateAngle; int k = data.infoHeader.biBitCount / 8; BYTE *newData = new BYTE[data.width * data.height * k]; for(int i =0;i &lt; data.width * data.height * k;i++) &#123; newData[i] = 0; &#125; //弧度制的角度 double angle = 1.0 * rotateAngle * PI / 180; int point = -k; int midY = static_cast&lt;float&gt;(data.height) / 2, midX = static_cast&lt;float&gt;(data.width) / 2; ImageUtil::Matrix3x3d mat(&#123; std::cos(angle),-std::sin(angle),0, std::sin(angle),std::cos(angle), 0, 0, 0, 1 &#125;); for (int i = 0; i &lt; data.height; i++) &#123; for (int j = 0; j &lt; data.width; j++) &#123; int aftX = j - midX; int aftY = i - midY; ImageUtil::Matrix3x1d xyMat(&#123; static_cast&lt;double&gt;(aftX),static_cast&lt;double&gt;(aftY),1 &#125;); auto result = mat * xyMat; int x = result[0][0] + midX; /* (aftX * std::cos(angle) + aftY * std::sin(angle)) + midX; */ int y = result[1][0] + midY; /* (-aftX * std::sin(angle) + aftY * std::cos(angle)) + midY;*/ point += k; //越界的点丢弃掉 if (x &lt; 0 || x &gt;= data.width || y &lt; 0 || y &gt;= data.height) continue; for(int biCount = 0;biCount &lt; k;biCount++) &#123; newData[point + biCount] = data.pImg[y * data.width * k + x * k + biCount]; &#125; &#125; &#125; IMGDATA img = data; img.pImg = newData; return img;&#125; 加入双线性插值双线性插值的原理不必再说了，在这里加入了插值可以避免新的图像出现一些由于没有得到精准映射的点而导致的出现的小色块的问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354for (int i = 0; i &lt; data.height; i++) &#123; for (int j = 0; j &lt; data.width; j++) &#123; int aftX = j - midX; int aftY = i - midY; ImageUtil::Matrix3x1d xyMat(&#123; static_cast&lt;double&gt;(aftX),static_cast&lt;double&gt;(aftY),1 &#125;); auto result = mat * xyMat; double originX = result[0][0] + midX; /* (aftX * std::cos(angle) + aftY * std::sin(angle)) + midX; */ double originY = result[1][0] + midY; /* (-aftX * std::sin(angle) + aftY * std::cos(angle)) + midY;*/ //加入插值系统 pixelPoint += k; if (originX &lt; 0 || originX &gt;= data.width || originY &lt; 0 || originY &gt;= data.height) continue; const int originPixelX = originX; const int originPixelY = originY; const double distanceOriginPixelX = originX - originPixelX; const double distanceOriginPixelY = originY - originPixelY; int originPixelXNext = originPixelX + 1; int originPixelYNext = originPixelY + 1; if (originPixelXNext &gt;= data.width) originPixelXNext = data.width - 1; if (originPixelYNext &gt;= data.height) originPixelYNext = data.height - 1; //兼容灰度图，24位图，32位图 for (int biCount = 0; biCount &lt; k; biCount++) &#123; newData[pixelPoint + biCount] = ImageUtil::clamp( data.pImg[originPixelY * data.width * k + originPixelX * k + biCount] * (1 - distanceOriginPixelX) * (1 - distanceOriginPixelY) + data.pImg[originPixelY * data.width * k + originPixelXNext * k + biCount] * (distanceOriginPixelX) * (1 - distanceOriginPixelY) + data.pImg[originPixelYNext * data.width * k + originPixelX * k + biCount] * (distanceOriginPixelY) * (1 - distanceOriginPixelX) + data.pImg[originPixelYNext * data.width * k + originPixelXNext * k + biCount] * distanceOriginPixelY * distanceOriginPixelX); &#125; //最初的方法 // pixelPoint += k; // if (originX &lt; 0 || originX &gt;= data.width || originY &lt; 0 || originY &gt;= data.height) // continue; // // for(int biCount = 0;biCount &lt; k;biCount++) // &#123; // newData[pixelPoint + biCount] = data.pImg[static_cast&lt;int&gt;(originY) * data.width * k + static_cast&lt;int&gt;(originX) * k + biCount]; // &#125; &#125; &#125; 透视透视变换本质上是将一个图投影到一个新的平面上去 \begin{bmatrix}x\\y\\z\end{bmatrix}=\begin{bmatrix}a_{00}&a_{01}&a_{02}\\a_{10}&a_{11}&a_{12}\\a_{20}&a_{21}&a_{22}\end{bmatrix}*\begin{bmatrix}u\\v\\1\end{bmatrix}整理一下可得 x'=\frac{x}{z}=\frac{a_{11}u+a_{12}v+a_{13}}{a_{31}u+a_{32}v+a_{33}}=\frac{k_{11}u+k_{12}v+k_{13}}{k_{31}u+k_{32}v+1}\\y'=\frac{y}{z}=\frac{a_{21}u+a_{22}v+a_{23}}{a_{31}u+a_{32}v+a_{33}}=\frac{k_{21}u+k_{22}v+k_{23}}{k_{31}u+k_{32}v+1}在这个公式当中，有8个未知量，因此，我们可以对参数输入原图的4个角的坐标点以及新图的四个角的坐标点，从而形成8个方程，这样就可以解出这个方程组了。 这样，我们就可以利用这个公式来计算出图片的透视变换之后的所有坐标，从而计算出新的图片了]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Exercise3.5--封装图片操作]]></title>
    <url>%2Fposts%2Fd7efe202%2F</url>
    <content type="text"><![CDATA[三个练习过后，我感觉，最基础的图片操作，载入，写出，画直方图这些操作千篇一律，是时候将他们封装在一起了 封装的东西大致分为两类，图片的加载与输出以及直方图的建立与输出。 于是我将所有的操作都置于namespace ImageUtil下 基本类型123456789101112131415161718192021222324252627282930//色彩typedef struct ImageColor&#123; BYTE r, g, b, a;&#125;RGBA;//图片的信息typedef struct ImageData&#123; BITMAPFILEHEADER fileHeader; BITMAPINFOHEADER infoHeader; RGBQUAD rgbquad[256]; BYTE * pImg; int length; int width, height; ImageData&amp; operator+(ImageData&amp; d0); ImageData&amp; operator*(float k);&#125;IMGDATA;//直方图的信息typedef struct GrayHistogram&#123; double gray[256] = &#123; 0 &#125;; int pixelCount = 0; void normalize();private: bool isNormalize = false;&#125;GRAYHISTOGRAM; 读写操作在这里，我将读写操作从Exercise1当中的fwrite，fread改为了cpp当中的iofstream，个人感觉更加方便123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171//读取图片ImageData ImageUtil::loadImage(const std::string&amp; path)&#123; std::ifstream ifstream; ifstream.open(path, std::ios::binary); if (!ifstream.is_open()) return &#123;&#125;; BITMAPFILEHEADER fileHeader; BITMAPINFOHEADER infoHeader; RGBQUAD rgbquad[256]; ifstream.read(reinterpret_cast&lt;char *&gt;(&amp;fileHeader), sizeof(BITMAPFILEHEADER)); ifstream.read(reinterpret_cast&lt;char *&gt;(&amp;infoHeader), sizeof(BITMAPINFOHEADER)); ifstream.read(reinterpret_cast&lt;char *&gt;(&amp;rgbquad), sizeof(RGBQUAD) * infoHeader.biClrUsed); BYTE *img = new BYTE[infoHeader.biSizeImage]; ifstream.read(reinterpret_cast&lt;char*&gt;(img), infoHeader.biSizeImage); IMGDATA imgdate; imgdate.infoHeader = infoHeader; imgdate.fileHeader = fileHeader; for (int i = 0; i &lt; 256; i++) &#123; imgdate.rgbquad[i] = rgbquad[i]; &#125; BYTE *imgWithoutError = new BYTE[(infoHeader.biWidth * infoHeader.biBitCount / 8) * infoHeader.biHeight]; //int byteWidth = (infoHeader.biWidth * (infoHeader.biClrUsed / 8) + 3) / 4 * 4; int point = -1; for(int i = 0;i &lt; infoHeader.biHeight;i++) &#123; for(int j = 0;j &lt; (infoHeader.biWidth * infoHeader.biBitCount / 8);j++) &#123; imgWithoutError[i * (infoHeader.biWidth * infoHeader.biBitCount / 8) + j] = img[++point]; &#125; //索引值与真实值的区别 while ((point + 1) % 4 != 0) point++; &#125; delete[] img; imgdate.pImg = imgWithoutError; imgdate.length = infoHeader.biSizeImage; imgdate.width = infoHeader.biWidth; imgdate.height = infoHeader.biHeight; ifstream.close(); return imgdate;&#125;//输出图片void ImageUtil::outputImage(ImageData data, const int clrUsed, const std::string&amp; path)&#123; std::ofstream out; out.open(path, std::ios::out | std::ios::trunc | std::ios::binary); if (!out.is_open()) return; BYTE *img = new BYTE[data.infoHeader.biSizeImage]; int byteWidth = (infoHeader.biWidth * infoHeader.biBitCount / 8); int point = -1; for(int i = 0;i &lt; data.height;i++) &#123; for(int j = 0;j &lt; byteWidth;j++) &#123; img[++point] = data.pImg[i * byteWidth + j]; &#125; //点在数组当中的索引值与宽度正好相差1 while ((point + 1) % 4 != 0) img[++point] = 0; &#125; std::cout &lt;&lt; "output " &lt;&lt; path &lt;&lt; "...." &lt;&lt; std::endl; out.write(reinterpret_cast&lt;char *&gt;(&amp;data.fileHeader), sizeof(BITMAPFILEHEADER)); out.write(reinterpret_cast&lt;char *&gt;(&amp;data.infoHeader), sizeof(BITMAPINFOHEADER)); out.write(reinterpret_cast&lt;char *&gt;(&amp;data.rgbquad), clrUsed * sizeof(RGBQUAD)); out.write(reinterpret_cast&lt;char *&gt;(img), data.infoHeader.biSizeImage); out.close(); delete[] img;&#125;//得到图片的直方图信息GRAYHISTOGRAM ImageUtil::getHistogram(const IMGDATA data)&#123; GRAYHISTOGRAM grayhistogram; int point = 0; for (int i = 0; i &lt; data.height; i++) &#123; for (int j = 0; j &lt; data.width; j++) &#123; grayhistogram.gray[data.pImg[point++]]++; &#125; while (point % 4 != 0) point++; &#125; grayhistogram.pixelCount = data.width * data.height; return grayhistogram;&#125;//输出直方图void ImageUtil::outputHistogram(const IMGDATA data, const std::string&amp; path)&#123; IMGDATA newData = data; GRAYHISTOGRAM histogram = ImageUtil::getHistogram(data); // newData.fileHeader.bfType = 0x4d42; // newData.fileHeader.bfReserved1 = 0; // newData.fileHeader.bfReserved2 = 0; newData.fileHeader.bfSize = sizeof(BITMAPINFOHEADER) + sizeof(BITMAPINFOHEADER) + sizeof(RGBQUAD) * 2 + 256 * 256; newData.fileHeader.bfOffBits = sizeof(BITMAPFILEHEADER) + sizeof(BITMAPINFOHEADER) + sizeof(RGBQUAD) * 2; // // newData.infoHeader.biSize = sizeof(BITMAPINFOHEADER); // newData.infoHeader.biPlanes = 1; newData.infoHeader.biBitCount = 8; newData.infoHeader.biClrUsed = 2; //newData.infoHeader.biCompression = BI_RGB; newData.infoHeader.biSizeImage = 256 * 256; newData.infoHeader.biHeight = 256; newData.infoHeader.biWidth = 256; // newData.infoHeader.biClrImportant = data.infoHeader.biClrImportant; // newData.infoHeader.biXPelsPerMeter = data.infoHeader.biXPelsPerMeter; // newData.infoHeader.biYPelsPerMeter = data.infoHeader.biYPelsPerMeter; newData.pImg = new BYTE[256 * 256]; for(int i = 0;i &lt; 256 * 256;i++) &#123; newData.pImg[i] = 0; &#125; histogram.normalize(); RGBQUAD white; white.rgbReserved = 0; white.rgbRed = 255; white.rgbBlue = 255; white.rgbGreen = 255; RGBQUAD black; black.rgbReserved = 0; black.rgbRed = 0; black.rgbBlue = 0; black.rgbGreen = 0; newData.rgbquad[0] = black; newData.rgbquad[1] = white; for (int i = 0; i &lt; 256; i++) &#123; int length = histogram.gray[i] * 255 * 20; if (length &gt; 255) length = 255; for (int j = 0; j &lt; length; j++) &#123; newData.pImg[j * 256 + i] = 1; &#125; &#125; newData.length = 256 * 256; newData.width = 256; newData.height = 256; outputImage(newData, 2, path);&#125; 由于和之前Exercise1与Exercise2的操作是一样的，因此也就不再赘述了。 转灰度图操作而由于大部分的图片处理都是基于灰度图的，因此这里也封装了将24/32位图片输入然后直接输出8位图的操作，以便于之后的练习（这样可以直接输入24/32位图，而不是先使用Exercise1的代码操作改为8位图再使用） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106ImageUtil::ImageData ImageUtil::loadImageToGray(const std::string &amp; path)&#123; ImageData data = loadImage(path); if (data.infoHeader.biBitCount != 8) &#123; RGBA *rgba = new RGBA[data.width * data.height]; switch (static_cast&lt;int&gt;(data.infoHeader.biBitCount)) &#123; case 16: std::cout &lt;&lt; "无法转换16位图(太麻烦，懒癌发作)" &lt;&lt; std::endl; break; case 24: &#123; int point = 0; for (int i = 0; i &lt; data.height; i++) &#123; for (int j = 0; j &lt; data.width; j++) &#123; rgba[i * data.width + j].b = data.pImg[point++]; rgba[i * data.width + j].g = data.pImg[point++]; rgba[i * data.width + j].r = data.pImg[point++]; &#125; &#125; data.infoHeader.biBitCount = 8; data.infoHeader.biClrUsed = 256; data.fileHeader.bfOffBits = 54 + 4 * 256; int byteLine = (data.width * data.infoHeader.biBitCount / 8 + 3) / 4 * 4; data.infoHeader.biSizeImage = byteLine * data.height; data.fileHeader.bfSize = 54 + byteLine * data.height + 4 * 256; for (int i = 0; i &lt; 256; i++) &#123; data.rgbquad[i].rgbRed = i; data.rgbquad[i].rgbGreen = i; data.rgbquad[i].rgbBlue = i; data.rgbquad[i].rgbReserved = 0; &#125; BYTE * newData = new BYTE[data.width * data.height]; point = 0; for (int i = 0; i &lt; data.height; i++) &#123; for (int j = 0; j &lt; data.width; j++) &#123; newData[point++] = rgba[i * data.width + j].r * 0.299 + rgba[i * data.width + j].g * 0.587 + rgba[i * data.width + j].b * 0.114; &#125; &#125; delete[] data.pImg; data.pImg = newData; break; &#125; case 32: &#123; int point = 0; for (int i = 0; i &lt; data.height; i++) &#123; for (int j = 0; j &lt; data.width; j++) &#123; rgba[i * data.width + j].b = data.pImg[point++]; rgba[i * data.width + j].g = data.pImg[point++]; rgba[i * data.width + j].r = data.pImg[point++]; rgba[i * data.width + j].a = data.pImg[point++]; &#125; &#125; data.infoHeader.biBitCount = 8; data.infoHeader.biClrUsed = 256; data.fileHeader.bfOffBits = 54 + 4 * 256; int byteLine = (data.width * data.infoHeader.biBitCount / 8 + 3) / 4 * 4; data.infoHeader.biSizeImage = byteLine * data.height; data.fileHeader.bfSize = 54 + byteLine * data.height + 4 * 256; for (int i = 0; i &lt; 256; i++) &#123; data.rgbquad[i].rgbRed = i; data.rgbquad[i].rgbGreen = i; data.rgbquad[i].rgbBlue = i; data.rgbquad[i].rgbReserved = 0; &#125; BYTE * newData = new BYTE[data.width * data.height]; point = 0; for (int i = 0; i &lt; data.height; i++) &#123; for (int j = 0; j &lt; data.width; j++) &#123; newData[point++] = rgba[i * data.width + j].r * 0.299 + rgba[i * data.width + j].g * 0.587 + rgba[i * data.width + j].b * 0.114; &#125; &#125; delete[] data.pImg; data.pImg = newData; break; &#125; default: break; &#125; delete[] rgba; &#125; return data;&#125; 其他封装其实也就是一些比较常用的数学操作，目前我封装了3个，分别是对灰度值的约束函数clamp以及ImageData的加与乘操作 12345678910111213141516171819202122232425262728293031323334353637int ImageUtil::clamp(const int c)&#123; if (c &gt; 255) return 255; if (c &lt; 0) return 0; return c;&#125;//加ImageUtil::ImageData &amp; ImageUtil::ImageData::operator+(ImageData&amp; d0)&#123; for(int i = 0;i &lt; height;i++) &#123; for(int j = 0;j &lt; width;j++) &#123; pImg[i * width + j] = ImageUtil::clamp(pImg[i * width + j] + d0.pImg[i * width + j]); &#125; &#125; return *this;&#125;//乘ImageUtil::ImageData &amp; ImageUtil::ImageData::operator*(const float k)&#123; for(int i =0;i &lt; height;i++) &#123; for(int j = 0;j &lt; width;j++) &#123; pImg[i * width + j] = ImageUtil::clamp(pImg[i * width + j] * k); &#125; &#125; return *this;&#125; 至于还有没有后续的封装就看后面的练习所总结了。 源码https://github.com/DearSummer/DigitalImageProcessing]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Exercise3——空间域滤波]]></title>
    <url>%2Fposts%2F12b12cb9%2F</url>
    <content type="text"><![CDATA[前言在图片处理当中，总会遇到一些图片拥有各种各样的噪点，这些东西细微，但是却又无时无刻的影响着你去处理这张图片。因此，我们就拥有了图片平滑的操作。 图片平滑图片平滑主要是去除噪音或者模糊图像，也就是去除图片当中的细小的细节或弥合目标之间的间隙。 从信号频率来讲，信号变化缓慢的地方为低频，信号变化剧烈的地方为高频。（比如图片的边缘，灰度的跳跃，噪声的变化，这些都可能造成灰度的剧烈变化，也就是信号的剧烈变化） 那么，只要我们在空间域或者信号域将低频的信号通过，高频的信号滤走，既可以实现图片的平滑了。 噪声何为噪声呢，噪声可以理解为影响我们看图片的理解其信息的因素。 噪声的出现一般都是因为图片在获取，存储，处理和传输过程当中受到的电气系统或者外界的影响出现的。 因此，我们也可以将噪声理解为不可预测的随机误差，可以看作是一个随机过程，因此，我们可以用概率论与数理统计的方法将其描述出来，同样，也给了我们消除噪声的可能。 噪声的分类噪声的分类有很多种，可以根据其产生原因，统计特性，幅度分布，噪声频率，噪声与信号的关系等等来分类。 而噪声与信号的分类可以分为乘性噪声和加性噪声 假设信号为$S(t)$,噪声为$N(t)$,那么 S(t) * (1+N(t))为乘性噪音 S(t) + N(t)为加性噪音 而由于加性噪音与信号不相关，因此，大多情况我们都是将乘性噪音近似为加性来处理的。 卷积模板卷积模板是一种领域运算的方式，主要有卷积和相关两种，可以实现图片的平滑，锐化，边缘检测等等功能 一般是用矩阵表示,用于定义参与了领域运算的相对位置与相关系数 G(x,y) = \sum_{s=-a}^a\sum_{t=-b}^bw(s,t)f(x+s,y+t)\\a=(m-1)/2\\b=(n-2)/2看上去很复杂，实际是这条公式也相当于（假设这是一个3x3的邻域运算） G(x,y)=\begin{bmatrix}w_{x-1,y-1}*f_{x-1,y-1}&w_{x,y-1}*f_{x,y-1}&w_{x+1,y-1}*f_{x+1,y-1}\\w_{x-1,y}*f_{x-1,y}&w_{x,y}*f_{x,y}&w_{x+1,y}*f_{x+1,y}\\w_{x-1,y+1}*f_{x-1,y+1}&w_{x,y+1}*f_{x,y+1}&w_{x+1,y+1}*f_{x+1,y+1}\end{bmatrix}注意，虽然写成了矩阵的形式，但实际上不是矩阵运算，而是将每一个数值的结果相加。而$w(x,y)$与$f(x,y)$分别表示运算的因子与对应点上的灰度级别。 边界问题由于领域运算使用了一个像素点以及其周围的点来运算，因此，会出现一些边界上的问题，比如在第一行的时候就没有第零行给他去运算了。 一般来说，在这个时候可以将第一行的值当作第零行去运算，也就是扩充图像，复制图像的边界的像素值来扩充边界使得在边界时仍然可算 也可以直接忽视第一行，直接对第二行开始进行运算从而避免边界问题。也就是对边界像素不处理 矩阵的大小一边来说，领域运算的窗口大小为3x3，但是取5x5或者2x2等等的其他值也不是不可以。 运算复杂度卷积运算的复杂度是很高的，因为对于每一个像素点，都要取其领域进行一次运算。以3x3的窗口为例，一个像素点就要进行9次乘法，8次加法以及一次除法，那么对于一个NxN的图片来说时间复杂度就是o(n^2) 图片平滑平均滤波说了这么多，我们现在就来开始利用卷积模板来对图像进行平均滤波。 平均滤波是一种线性低通的滤波器。 他的滤波模板是对领域的像素进行加权平均，最终取平均值作为中间像素的输出结果，这样可以在一定程度上避免突变像素的影响 公式 G(x,y) = \begin{bmatrix}1&1&1\\ 1&1&1\\1&1&1\end{bmatrix} * \frac{1}{9}或者是 G(x,y) = \begin{bmatrix}1&2&1\\2&4&2\\1&2&1\end{bmatrix}*\frac{1}{16}代码实现至于里面的各种自定义的数据结构，可以看我的另一篇博客。 1234567891011121314151617181920212223242526272829303132333435363738394041IMGDATA advenage(IMGDATA data)&#123; BYTE * newData = new BYTE[data.length]; for (int i = 0; i &lt; data.height; i++) &#123; for (int j = 0; j &lt; data.width; j++) &#123; int up, down,left,right; if (i == 0) up = 0; else up = i - 1; if (i == data.height - 1) down = data.height - 1; else down = i + 1; if (j == 0) left = 0; else left = j - 1; if (j == data.width - 1) right = data.width - 1; else right = j + 1; //领域计算 newData[i * data.width + j] = clamp( (data.pImg[up * data.width + left] + 2 * data.pImg[up * data.width + j] + data.pImg[up * data.width + right] + 2 * data.pImg[i * data.width + left] + 4 * data.pImg[i * data.width + j] + 2 * data.pImg[i * data.width + right] + data.pImg[down * data.width + left] + 2 * data.pImg[down * data.width + j] + data.pImg[down * data.width + right]) / 16); &#125; &#125; delete[] data.pImg; data.pImg = newData; return data;&#125; 中值滤波中值滤波与平均滤波的原理差不多，都是用于除去突变像素的。 中值滤波是统计排序滤波器的一种。 他的思路则是先获取一个像素点的领域的所有的点，然后，再对其进行排序，当取中值为输出值时则是中值滤波，当取最大值时为最大值滤波，取最小值时为最小值滤波。 现在是中值滤波，自然要取中间值了。 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041//这里取的是3x3的领域IMGDATA mid(IMGDATA data)&#123; BYTE *newData = new BYTE[data.length]; for(int i = 1;i &lt; data.height - 1;i++) &#123; for(int j = 1;j &lt; data.width - 1;j++) &#123; int arr[9] = &#123; data.pImg[(i - 1) * data.width + j - 1],data.pImg[(i - 1) * data.width + j],data.pImg[(i - 1)*data.width + j + 1], data.pImg[(i)* data.width + j - 1],data.pImg[(i)* data.width + j],data.pImg[(i)*data.width + j + 1], data.pImg[(i + 1) * data.width + j - 1],data.pImg[(i + 1) * data.width + j],data.pImg[(i + 1)*data.width + j + 1] &#125;; newData[i * data.width + j] = getMid(arr); //delete[] arr; &#125; &#125; IMGDATA newImg = data; newImg.pImg = newData; return newImg;&#125;int getMid(int arr[9])&#123; for(int i = 0;i &lt; 9;i++) &#123; for(int j = 0 ;j &lt; 8;j++) &#123; if(arr[j] &gt; arr[j + 1]) &#123; const int temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; &#125; &#125; &#125; return arr[4];&#125; 总结当然，这两个滤波器想要实现比较好的效果都是要进行多次滤波的。不过，当滤波的次数一多，就会出现图像比较模糊的现象，毕竟这两种滤波本质上都是对图片进行平滑化处理嘛，自然会模糊图片了。 图片锐化图片锐化，指的是增强图片当中的细节或者是被模糊的了的细节。 锐化的处理可以用空间微分解决，因为，微分算子的强度与当前的图像点的突变强度有关，而突变强度强的地方也就是图片当中的细节。 在图片处理当中，一般有两种微分方法，一阶与二阶 \frac{\partial f}{\partial x}=f(x+1)-f(x)\\\frac{\partial^2 f}{\partial x^2} = f(x+1) + f(x-1)-2f(x)对于大部分图像增强来说，二阶微分比一阶要好，因为二阶微分展现的细节比较强，而一阶微分通常用于提取图像边缘 拉普拉斯算子对于二阶图像函数$f(x,y)$，拉普拉斯变换定义为 \Delta^2f = \frac{\partial^2f}{\partial x^2}+\frac{\partial^2f}{\partial y^2}换作算子的矩阵形式就是 f(x)=\begin{bmatrix}0&1&0\\1&-4&1\\0&1&0\end{bmatrix}或者是其扩展版，也就是包含了对角线领域的版本 f(x)=\begin{bmatrix}1&1&1\\1&-8&1\\1&1&1\end{bmatrix}有了公式实现也就很简单了 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142IMGDATA laplace(IMGDATA data)&#123; BYTE * newData = new BYTE[data.length]; for (int i = 0; i &lt; data.height; i++) &#123; for (int j = 0; j &lt; data.width; j++) &#123; int up, down, left, right; if (i == 0) up = 0; else up = i - 1; if (i == data.height - 1) down = data.height - 1; else down = i + 1; if (j == 0) left = 0; else left = j - 1; if (j == data.width - 1) right = data.width - 1; else right = j + 1; newData[i * data.width + j] = clamp( 1 * data.pImg[up * data.width + left] + 1 * data.pImg[up * data.width + j] + 1 * data.pImg[up * data.width + right] + 1 * data.pImg[i * data.width + left] + -8 * data.pImg[i * data.width + j] + 1 * data.pImg[i * data.width + right] + 1 * data.pImg[down * data.width + left] + 1 * data.pImg[down * data.width + j] + 1 *data.pImg[down * data.width + right]); &#125; &#125; IMGDATA imgData = data; imgData.pImg = newData; return imgData;&#125; 效果大致就是这样 当然这样还不算完，这只是提取出图片的细节地方而已。然后就是对细节的增强了。 g(x,y)=\begin{cases}f(x,y) - \Delta^2f(x,y) &拉普拉斯算子中间系数为负\\f(x,y)+\Delta^2f(x,y)&拉普拉斯算子中间系数为正\end{cases}只是简单的相加而已 12//我的中间系数为负laplaceIMG = data + (laplaceIMG * -1);]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Exercise2--直方图处理]]></title>
    <url>%2Fposts%2F75ff8234%2F</url>
    <content type="text"><![CDATA[前言图片增强主要是处理目标图片，从而达到处理结果的图片比原图片更适合特定的应用。 而在各种各样的图片处理当中，就有一些是专门处理灰度图的。 我们可以利用图片的像素亮度（灰度级别）看成是一个随机变量，其分布的情况就反应了图片的特征。我们可以使用Probability Density Function（PDF）来刻画与描述，表现为灰度直方图 直方图统计灰度直方图是灰度级函数，他表现为图像当中某种灰度的像素个数，反应了图像中每种灰度的出现频率 S_r = P(r)其中S为第r级灰度的灰度频率 算法假定图像有L级灰度，大小为P = M x N，各像素的灰度为f(x,y),pBuffer[k]为各像素的灰度的量 12345step1(初始化) : pBuffer[k] = 0 (k = 0,1,2....,M×N)step2(统计) : pBuffer[f(x,y)]++ step3(归一化) : pBuffer[k] /= MxN(k = 0,1,2,....,MxN) 第三步归一化操作是可选的。 实现实现这个直方图统计并不复杂，操作也一样是读取BITMAP文件（注意跳字节），提取出自己有用的部分，然后再进行统计 在这里我先定义了两个数据结构以便于之后的操作 1234567891011121314151617181920typedef struct ImageData&#123; BITMAPFILEHEADER fileHeader; BITMAPINFOHEADER infoHeader; RGBQUAD rgbquad[256]; BYTE * img; int length; int width, height;&#125;IMGDATA;typedef struct GrayHistogram&#123; float gray[256] = &#123;0&#125;; int pixelCount = 0; void normalize(); void draw();private : bool isNormalize = false;&#125;GRAYHISTOGRAM; 然后就是对BITMAP文件的读取 12345678910111213141516171819202122232425262728293031323334IMGDATA loadImage(const std::string&amp; path)&#123; std::ifstream ifstream; ifstream.open(path, std::ios::binary); if (!ifstream.is_open()) return &#123;&#125;; BITMAPFILEHEADER fileHeader; BITMAPINFOHEADER infoHeader; RGBQUAD rgbquad[256]; ifstream.read(reinterpret_cast&lt;char*&gt;(&amp;fileHeader), sizeof(BITMAPFILEHEADER)); ifstream.read(reinterpret_cast&lt;char *&gt;(&amp;infoHeader), sizeof(BITMAPINFOHEADER)); ifstream.read(reinterpret_cast&lt;char *&gt;(&amp;rgbquad), sizeof(RGBQUAD) * infoHeader.biClrUsed); BYTE *img = new BYTE[infoHeader.biSizeImage]; ifstream.read(reinterpret_cast&lt;char*&gt;(img), infoHeader.biSizeImage); IMGDATA imgdate; imgdate.infoHeader = infoHeader; imgdate.fileHeader = fileHeader; for(int i = 0;i &lt; 256;i++) &#123; imgdate.rgbquad[i] = rgbquad[i]; &#125; imgdate.pImg = img; imgdate.length = infoHeader.biSizeImage; imgdate.width = infoHeader.biWidth; imgdate.height = infoHeader.biHeight; ifstream.close(); return imgdate;&#125; 解析读取到的信息，并进行分析，最后保存到GrayHistogram当中 123456789101112131415161718GRAYHISTOGRAM getHistogram(const IMGDATA data)&#123; GRAYHISTOGRAM grayhistogram; int point = 0; for (int i = 0; i &lt; data.height; i++) &#123; for(int j = 0;j &lt; data.width;j++) &#123; grayhistogram.gray[data.img[point++]]++; &#125; while (point % 4 != 0) point++; &#125; grayhistogram.pixelCount = data.width * data.height; return grayhistogram;&#125; 最后一步就是归一化以及画出来了，由于归一化是可选的，因此这个也可以不进行归一化，当然，无论有没有归一化都是可以表现图片的特征的 12345678910111213//归一化void GrayHistogram::normalize()&#123; if(isNormalize) return; for (float&amp; i : gray) &#123; i = i / pixelCount; &#125; isNormalize = true;&#125; 输出直方图之后，我们就需要输出直方图了。由于直方图是一个在图像处理当中比较重要的环节，因此，我们需要输出一个比较好看的直方图，因此，我选择将直方图输出到图片当中。 这个图片的大小为256 x 256，因此图片的u轴就是相当于横坐标，v轴相当于纵坐标，然后，由白色的像素组成直方图，其余部分用黑色像素显示，从而达到了输出一张好看的直方图的目的。 因此，我们需要利用数据源的图片构建一个直方图信息以及一张新的图片。 构建一张新的图片并不难，只要将信息按照BITMAP的格式输入就可以了，而直方图信息的建立刚刚也说了，因此，我们现在就可以建立一个输出直方图的图片了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576//由于可以使用原图本身的信息，因此可以省略一些填写void outputHistogram(const IMGDATA data,const std::string&amp; path)&#123; IMGDATA newData = data; GRAYHISTOGRAM histogram = getHistogram(data); // newData.fileHeader.bfType = 0x4d42; // newData.fileHeader.bfReserved1 = 0; // newData.fileHeader.bfReserved2 = 0; newData.fileHeader.bfSize = sizeof(BITMAPINFOHEADER) + sizeof(BITMAPINFOHEADER) + sizeof(RGBQUAD) * 2 + 256 * 256; newData.fileHeader.bfOffBits = sizeof(BITMAPFILEHEADER) + sizeof(BITMAPINFOHEADER) + sizeof(RGBQUAD) * 2; // // newData.infoHeader.biSize = sizeof(BITMAPINFOHEADER); // newData.infoHeader.biPlanes = 1; newData.infoHeader.biBitCount = 8; newData.infoHeader.biClrUsed = 2; //newData.infoHeader.biCompression = BI_RGB; newData.infoHeader.biSizeImage = 256 * 256; newData.infoHeader.biHeight = 256; newData.infoHeader.biWidth = 256; // newData.infoHeader.biClrImportant = data.infoHeader.biClrImportant; // newData.infoHeader.biXPelsPerMeter = data.infoHeader.biXPelsPerMeter; // newData.infoHeader.biYPelsPerMeter = data.infoHeader.biYPelsPerMeter; newData.pImg = new BYTE[256 * 256]&#123; 0 &#125;; histogram.normalize(); RGBQUAD white; white.rgbReserved = 0; white.rgbRed = 255; white.rgbBlue = 255; white.rgbGreen = 255; RGBQUAD black; black.rgbReserved = 0; black.rgbRed = 0; black.rgbBlue = 0; black.rgbGreen = 0; newData.rgbquad[0] = black; newData.rgbquad[1] = white; for(int i = 0 ;i &lt; 256;i++) &#123; int length = histogram.gray[i] * 255 * 25; if (length &gt; 255) length = 255; for(int j = 0;j &lt; length;j++) &#123; newData.pImg[j * 256 + i] = 1; &#125; &#125; newData.length = 256 * 256; newData.width = 256; newData.height = 256; output(newData, 2, path);&#125;void output(IMGDATA data,int clrUsed,const std::string&amp; path)&#123; std::ofstream out; out.open(path, std::ios::out | std::ios::trunc | std::ios::binary); if (!out.is_open()) return; std::cout &lt;&lt; "output " &lt;&lt; path &lt;&lt; "...." &lt;&lt; std::endl; out.write(reinterpret_cast&lt;char *&gt;(&amp;data.fileHeader), sizeof(BITMAPFILEHEADER)); out.write(reinterpret_cast&lt;char *&gt;(&amp;data.infoHeader), sizeof(BITMAPINFOHEADER)); out.write(reinterpret_cast&lt;char *&gt;(&amp;data.rgbquad), clrUsed * sizeof(RGBQUAD)); out.write(reinterpret_cast&lt;char *&gt;(data.pImg), data.length); out.close();&#125; 此时，直方图的信息统计就完成了。就可以进行下一步的操作了。 直方图均衡化直方图均衡化，指的是，对图片的直方图进行均衡化处理，也就是对图片的灰度级数进行均衡，直观的从图片上来说，就是图片的对比度更加的明显。因为，在这种情况下，原图片的灰度级数摊到了其他的级数上去了。 在直方图均衡化当中，均衡化函数满足以下特点 s = T(r)\qquad 0\leq r\leq1，0\leq T(r)\leq 1且T(r)在区间内为单值且单调递增 累积函数分布方法（DCF)累积函数分布方法是一种比较经典的直方图均衡化方法，他的公式表现为 s = T(r) = \int_0^rp_r(w)dw也就是对于每一处的灰度分布概率都进行积分，由于概率总和为1，因此，T(r)自然也是在0与1之间了，而且也必然是单调递增且单值的。 利用这个函数，可以将直方图当中的灰度信息进行均衡，灰度集中的地方自然会更加显眼，而本身没什么刻画的地方也会更加的白，因此对比度自然提上来了。 当然，由于我们的图片的灰度级别是离散的，因此，这个函数应该也是离散的，所以他的离散形式为 S_k = T(r_k)=\sum_{j=0}^kp_r(r_j)=\sum_{j=0}^k\frac{n_j}{n}均衡化之后，每一个点的灰度级别都是自己的灰度级数的概率的积分。 算法实现算法的实现比较简单，按照之前写出的公式即可 1234567891011121314151617181920212223//均衡化 IMGDATA balance(const GRAYHISTOGRAM histogram,const IMGDATA data)&#123; const IMGDATA newData = data; for(int i = 0;i &lt; data.length;i++) &#123; newData.pImg[i] = calculate(data.pImg[i], histogram) * 255; &#125; return newData;&#125;//对灰度级别积分float calculate(int index, const GRAYHISTOGRAM histogram)&#123; float result = 0; for(int i = 0;i &lt; index + 1;i++) &#123; result += histogram.gray[i]; &#125; if (result &gt; 1) result = 1; return result;&#125; 此时，我们的直方图处理也总算是完成了。 效果图 源码https://github.com/DearSummer/DigitalImageProcessing]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Exercise1--BMP文件处理]]></title>
    <url>%2Fposts%2Ff3fe5f17%2F</url>
    <content type="text"><![CDATA[BITMAP位图在进行BITMAP图片进行处理的时候，首先要先对BITMAP的数据结构进行分析。 BITMAP位图的结构分为四个部分 文件头 BITMAPFILEHEADER123456789typedef struct tagBITMAPFILEHEADER&#123;WORD bfType; //文件类型，必须是“BM”DWORD bfSize; //文件大小，包含文件头的大小WORD bfReserved1; //保留字WORD bfReserved2; //保留字DWORD bfOffBits; //从文件头到实际位图数据的偏移字节数 &#125; BITMAPFILEHEADER; sizeof(BITMAPFILEHEADER) = 14 信息头 BITMAPINFOHEADER123456789101112131415typedef struct tagBITMAPINFOHEADER&#123;DWORD biSize; //该结构的长度，为40LONG biWidth; //图像宽度LONG biHeight; //图像高度WORD biPlanes; //位平面数，必须为1WORD biBitCount; //颜色位数，DWORD biCompression; //是否压缩DWORD biSizeImage; //实际位图数据占用的字节数LONG biXPelsPerMeter;//目标设备水平分辨率LONG biYPelsPerMeter;//目标设备垂直分辨率DWORD biClrUsed;//实际使用的颜色数DWORD biClrImportant;//图像中重要的颜色数&#125; BITMAPINFOHEADER; sizeof(BITMAPINFOHEADER) = 40 在这当中，若biClrUsed为0，则说明用到的颜色为2的biBitCount次方（也就无需用到调色板了） 在这当中，biSizeImage为实际的字节数，其中，要求 biSizeImage = （（biWidth * （biBitCount / 8） + 3） / 4 * 4 ) * biHeight也就是说，在位图当中的宽的字节数一定要是4的倍数，不是4的倍数将要对其中的字节进行补齐 举个例子，假如当前的图片是一个24位的宽度为13的图片，那么此时一行的存储模型应该是 13 * （BGR) + 1 * BYTE也就是在末尾补了一个字节，从而达到了一行40字节（4的倍数）的目的。 调色板 RGBQUAD（内容可为空)12345678typedef struct tagRGBQUAD&#123; BYTE rgbBlue; //该颜色的蓝色分量 BYTE rgbGreen; //该颜色的绿色分量 BYTE rgbRed; //该颜色的红色分量 BYTE rgbReserved; //保留值&#125; RGBQUAD; sizeof(RGBQUAD) = 4 调色板是BITMAP当中的可选项，只有需要的时候才会出现，而在有调色板的场合中，一共有biBitCount项 (RGBQUAD[biBitCount]) 实际位图信息在这里存放的是实际的位图的数据，其中数据量在BITMAPINFOHEADER有记录，在这里记录的一般是颜色的信息（比如RGB信息）又或者是有调色板的时候，记录调色板的索引值。 当然值得一提的是，这里的行的字节数一定是要4的倍数的 24位图像对R，G，B三个分量进行分离，产生3幅新的图像在基本了解了BITMAP的内存结构之后，就可以根据其中的信息去读取图片，并分理出其中的RGB分量了。值得注意的在于，若图片的宽度不是4的倍数的时候，读取的时候要跳过行末尾的无意义的字节，否则读取出来的rgb值是错误的，而写入成新的图片的时候，同样的，要手动对行末尾进行补齐 具体实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124//用于存储RGBtypedef struct&#123; BYTE b; BYTE g; BYTE r;&#125;RGB;void bitmapTo3SignalColorBitmap()&#123; BITMAPFILEHEADER fileHeader; BITMAPINFOHEADER infoHeader; FILE * pfin = fopen("bitmap/n4x.bmp", "rb"); FILE * pfoutR = fopen("bitmap/r.bmp", "wb"); FILE * pfoutG = fopen("bitmap/g.bmp", "wb"); FILE * pfoutB = fopen("bitmap/b.bmp", "wb"); fread(&amp;fileHeader, sizeof(BITMAPFILEHEADER), 1, pfin); fread(&amp;infoHeader, sizeof(BITMAPINFOHEADER), 1, pfin); int height = infoHeader.biHeight, width = infoHeader.biWidth; //方便，偷懒的做法（只处理24位） if (infoHeader.biBitCount == 24) &#123; //获取补齐后的宽度 int byteWidth = (width * infoHeader.biBitCount / 8 + 3) / 4 * 4; int size = byteWidth * height; BYTE *img = new BYTE[size]; RGB *imgRGB = new RGB[width * height]; fseek(pfin, fileHeader.bfOffBits, 0); fread(img, sizeof(BYTE), size, pfin); //跳过无用的字节 int point = 0; for (int i = 0; i &lt; height; i++) &#123; for (int j = 0; j &lt; width; j++) &#123; imgRGB[i * width + j].b = img[point++]; imgRGB[i * width + j].g = img[point++]; imgRGB[i * width + j].r = img[point++]; &#125; while (point % 4 != 0) point++; &#125; writeImg(&amp;fileHeader, &amp;infoHeader, toByte(imgRGB, width, height, infoHeader.biSizeImage, RGBTAG::R), infoHeader.biSizeImage, pfoutR); writeImg(&amp;fileHeader, &amp;infoHeader, toByte(imgRGB, width, height, infoHeader.biSizeImage, RGBTAG::G), infoHeader.biSizeImage, pfoutG); writeImg(&amp;fileHeader, &amp;infoHeader, toByte(imgRGB, width, height, infoHeader.biSizeImage, RGBTAG::B), infoHeader.biSizeImage, pfoutB); &#125; fclose(pfin); fclose(pfoutR); fclose(pfoutG); fclose(pfoutB);&#125;//写入到文件当中void writeImg(BITMAPFILEHEADER *header,BITMAPINFOHEADER *info,BYTE *rgb,int size,FILE * pf)&#123; fwrite(header, sizeof (BITMAPFILEHEADER), 1, pf); fwrite(info, sizeof (BITMAPINFOHEADER), 1, pf); fwrite(rgb, sizeof(BYTE), size, pf);&#125;//将RGB格式转化为byte（注意RGB的排列方式），以及补齐无用字节BYTE* toByte(RGB *rgb,int width,int height,int biSize,RGBTAG tag)&#123; BYTE *byte = new BYTE[biSize]; int point = 0; for(int i = 0;i &lt; height;i++) &#123; for(int j = 0;j &lt; width;j++) &#123; switch (tag) &#123; case R: byte[point++] = 0; byte[point++] = 0; byte[point++] = rgb[i * width + j].r; break; case G: byte[point++] = 0; byte[point++] = rgb[i * width + j].g; byte[point++] = 0; break; case B: byte[point++] = rgb[i * width + j].b; byte[point++] = 0; byte[point++] = 0; break; case ALL: byte[point++] = rgb[i * width + j].r; byte[point++] = rgb[i * width + j].g; byte[point++] = rgb[i * width + j].b; break; &#125; &#125; while (point % 4 != 0) byte[point++] = 0; &#125; return byte;&#125; 对24彩色图像灰度化灰度图实际上是一个利用心理学灰度公式来得出的一个适合人眼的灰度图片的图 GRAY = B * 0.114 + R * 0.299 + G * 0.587在这个图片当中，由于RGB三个分量的值都是一样的（灰色的特性）因此，可以将这个图片从24位图变成一个8位的图 当我们将一个图片从24位转化为8位的时候，有几点是值得注意的 改变BITMAPFILEHEADER与BITMAPINFOHEADER这是当然的，首先要改的就是BITMAPINFOHEADER当中的biBitCount了，毕竟这是标志了这是几位图的信息，其次，还要添加biClrUsed的信息，因为，当图片是8位图的时候，自然而然的就要用到了调色板了。 既然添加了调色板，那么就需要改变BITMAPFILEHEADER当中的biOffBits了，毕竟当中添加了一个调色板，那么图片数据的位置自然会产生变化了 最后，还要分别对BITMAPFILEHEADER当中的bfSize与BITMAPINFOHEADER当中的biSizeImage进行修改，从而使得这些数据指向的内容是符合这张图片的 添加调色板8位图用到的颜色只有256位，因此，添加256个调色板就足够了 123456789RGBQUAD rgbQuad[256];for(int i = 0;i &lt; 256;i++)&#123; rgbQuad[i].rgbRed = i; rgbQuad[i].rgbGreen = i; rgbQuad[i].rgbBlue = i; rgbQuad[i].rgbReserved = 0;&#125; 具体实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283void bitmap2Gray()&#123; BITMAPFILEHEADER fileHeader; BITMAPINFOHEADER infoHeader; FILE * pfin = fopen("bitmap/n4x.bmp", "rb"); FILE * pfout = fopen("bitmap/gray.bmp", "wb"); fread(&amp;fileHeader, sizeof(BITMAPFILEHEADER), 1, pfin); fread(&amp;infoHeader, sizeof(BITMAPINFOHEADER), 1, pfin); int height = infoHeader.biHeight, width = infoHeader.biWidth; if (infoHeader.biBitCount == 24) &#123; int byteWidth = (width * infoHeader.biBitCount / 8 + 3) / 4 * 4; int size = byteWidth * height; BYTE *img = new BYTE[size]; RGB *imgRGB = new RGB[width * height]; fseek(pfin, fileHeader.bfOffBits, 0); fread(img, sizeof(BYTE), size, pfin); //读取信息 int point = 0; for (int i = 0; i &lt; height; i++) &#123; for (int j = 0; j &lt; width; j++) &#123; imgRGB[i * width + j].b = img[point++]; imgRGB[i * width + j].g = img[point++]; imgRGB[i * width + j].r = img[point++]; &#125; while (point % 4 != 0) point++; &#125; infoHeader.biBitCount = 8; infoHeader.biClrUsed = 256; //建立调色板 RGBQUAD rgbQuad[256]; for(int i = 0;i &lt; 256;i++) &#123; rgbQuad[i].rgbRed = i; rgbQuad[i].rgbGreen = i; rgbQuad[i].rgbBlue = i; rgbQuad[i].rgbReserved = 0; &#125; fileHeader.bfOffBits = 54 + 4 * 256; int byteLine = (width * infoHeader.biBitCount / 8 + 3) / 4 * 4; BYTE *newIMG = new BYTE[byteLine * height]; infoHeader.biSizeImage = byteLine * height; fileHeader.bfSize = 54 + byteLine * height + 4 * 256; //重新写回BMP当中 point = 0; for (int i = 0; i &lt; height; i++) &#123; for (int j = 0; j &lt; width; j++) &#123; newIMG[point++] = imgRGB[i * width + j].b * 0.114 + imgRGB[i * width + j].g * 0.587 + imgRGB[i * width + j].r * 0.299; &#125; while (point % 4 != 0) newIMG[point++] = 0; &#125; fwrite(&amp;fileHeader, sizeof(BITMAPFILEHEADER), 1, pfout); fwrite(&amp;infoHeader, sizeof(BITMAPINFOHEADER), 1, pfout); fwrite(&amp;rgbQuad, 4 * 256, 1, pfout); fwrite(newIMG, sizeof(BYTE), byteLine * height, pfout); &#125; fclose(pfin); fclose(pfout);&#125; 对8位灰度图进行反色对图片进行反色是十分简单的一件事了，公式也十分的简单 antiColor = abs(color - 255)具体实现和之前的是基本一致的。 当然，由于有灰度图（8位图）有调色板的存在，因此，需要在读取之前跳过调色板的内存块 1fseek(pfin, fileHeader.bfOffBits, 0); 具体实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849void gray2Anticolor()&#123; BITMAPFILEHEADER fileHeader; BITMAPINFOHEADER infoHeader; FILE * pfin = fopen("bitmap/gray.bmp", "rb"); FILE * pfout = fopen("bitmap/anti_color.bmp", "wb"); fread(&amp;fileHeader, sizeof(BITMAPFILEHEADER), 1, pfin); fread(&amp;infoHeader, sizeof(BITMAPINFOHEADER), 1, pfin); int height = infoHeader.biHeight, width = infoHeader.biWidth; if (infoHeader.biBitCount == 8) &#123; int byteWidth = (width * infoHeader.biBitCount / 8 + 3) / 4 * 4; int size = byteWidth * height; BYTE *img = new BYTE[size]; BYTE *imgAnticolor = new BYTE[size]; RGBQUAD rgbquad[256]; fread(rgbquad, sizeof(RGBQUAD), 256, pfin); fread(img, sizeof(BYTE), size, pfin); int point1 =0, point = 0; for (int i = 0; i &lt; height; i++) &#123; for (int j = 0; j &lt; width; j++) &#123; imgAnticolor[point++] = std::abs(img[point1++] - static_cast&lt;byte&gt;(255)); &#125; while (point % 4 != 0) &#123; imgAnticolor[point++] = 0; point1++; &#125; &#125; fwrite(&amp;fileHeader, sizeof(BITMAPFILEHEADER), 1, pfout); fwrite(&amp;infoHeader, sizeof(BITMAPINFOHEADER), 1, pfout); fwrite(&amp;rgbquad, 4 * 256, 1, pfout); fwrite(imgAnticolor, sizeof(BYTE), size, pfout); &#125; fclose(pfin); fclose(pfout);&#125;]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
</search>
